{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASCI 315, Group Work 8: Convolutional Neural Networks with CIFAR-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries\n",
    "\n",
    "First, we'll import necessary libraries such as PyTorch and torchvision, along with matplotlib for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Normalize CIFAR-10\n",
    "\n",
    "We'll use torchvision to download the CIFAR-10 dataset. The dataset consists of 60,000 32x32 color images in 10 classes, with 6,000 images per class. We'll also apply normalization during data transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=batch_size, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=batch_size, shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "classes = (\n",
    "    \"plane\",\n",
    "    \"car\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background: Convolutional and Pooling Layers\n",
    "\n",
    "**Convolutional Layer**: For a `nn.Conv2d` layer, the input is expected to have shape $(N, C, H, W)$ where $N$ is the batch size, $C$ is the number of channels (e.g., 3 for color images, 1 for grayscale), and $H, W$ are the height and width of each sample image. The output from this layer has shape $(N, C', H', W')$.\n",
    "\n",
    "The `Conv2d` constructor takes many parameters. The most important ones are:\n",
    "1. `in_channels` - this is $C$\n",
    "2. `out_channels` - this is the number of filters (this equals $C'$)\n",
    "3. `kernel_size` - this is the size of the filter. It can be an integer $K$ (then the filters have shape $(K, K, C)$), or a tuple $(K_1, K_2)$\n",
    "4. `padding` - controls the amount of padding around the original image. It can be an integer, tuple, or string (\"valid\" for no padding, \"same\" to preserve dimensions when stride=1). Default is 0.\n",
    "5. `stride` - stride of the filter horizontally and vertically. It can be an integer or tuple. Default is 1.\n",
    "\n",
    "The output has shape $(N, C', H', W')$ where the new number of channels equals the number of filters (i.e., `out_channels`) and new height and width $H', W'$ are computed as:\n",
    "\n",
    "$$H' = \\Big\\lfloor\\frac{H + 2p - K}{s} + 1\\Big\\rfloor$$\n",
    "\n",
    "where $p$ is padding along that axis, $K$ is the kernel size along that axis, and $s$ is the stride along that axis (similarly for width).\n",
    "\n",
    "**Pooling Layer**: We use the `nn.MaxPool2d` layer with these parameters:\n",
    "1. `kernel_size`\n",
    "2. `stride` - defaults to `kernel_size` (ensuring no overlap)\n",
    "3. `padding` - default is 0\n",
    "\n",
    "The input is again of shape $(N, C, H, W)$ and output $(N, C, H', W')$ where the number of channels stays the same but the height and width change according to the equation above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_model = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5),\n",
    "    nn.MaxPool2d(kernel_size=2),\n",
    ")\n",
    "\n",
    "# Show model architecture\n",
    "print(example_model)\n",
    "\n",
    "# Show output shape with a sample input\n",
    "sample_input = torch.randn(1, 3, 32, 32)\n",
    "sample_output = example_model(sample_input)\n",
    "print(f\"\\nInput shape:  {tuple(sample_input.shape)}\")\n",
    "print(f\"Output shape: {tuple(sample_output.shape)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the convolutional layer, the input is $(-1, C=3, H=32, W=32)$. Using the formula, the output number of channels is 6 and the new height and width are:\n",
    "\n",
    "$$H' = \\lfloor(32 + 2 \\times 0 - 5)/1 + 1\\rfloor = 28$$\n",
    "\n",
    "which matches the summary shown above (note that the kernel size is 5). The number of parameters is:\n",
    "\n",
    "$$\\underbrace{6}_{\\text{\\# filters}} \\times \\underbrace{5 \\times 5 \\times 3}_{\\text{kernel size}} + \\underbrace{6}_{\\text{bias}} = 456$$\n",
    "\n",
    "For the pooling layer, the input shape is $(-1, C=6, H=28, W=28)$, with no padding and stride equal to the kernel size (2). Then:\n",
    "\n",
    "$$H' = \\lfloor (28 + 0 - 2)/2 + 1 \\rfloor = 14$$\n",
    "\n",
    "Hence, the output shape is $(-1, 6, 14, 14)$.\n",
    "\n",
    "It is important to keep track of how the image shape evolves through your network, since at the end you need fully connected layers (`nn.Linear`) and you must specify the correct `in_features` when using them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Define a Convolutional Neural Network\n",
    "\n",
    "Implement a simple convolutional neural network for image classification. Your network should have the architecture shown in the following diagram:\n",
    "\n",
    "![CNN Architecture](https://i0.wp.com/developersbreach.com/wp-content/uploads/2020/08/cnn_banner.png)\n",
    "\n",
    "Documentation links:\n",
    "- [Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)\n",
    "- [MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html)\n",
    "\n",
    "Your network should have:\n",
    "- Two convolutional layers followed by max pooling\n",
    "- Three fully connected layers\n",
    "- Flatten the output after convolution to feed it to the fully connected layers\n",
    "\n",
    "Use the following sizes for the convolutional layers:\n",
    "- Conv 1: `(in_channels=3, out_channels=6, kernel_size=5)`\n",
    "- Conv 2: `(in_channels=6, out_channels=16, kernel_size=5)`\n",
    "\n",
    "**Note:** The `CrossEntropyLoss` function includes the softmax internally, so you don't need to add a softmax layer at the end of your network (contrary to what the figure shows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # BEGIN SOLUTION\n",
    "        # Two conv layers with max pooling, then three fully connected layers\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # After conv1 + pool: 32 -> 28 -> 14\n",
    "        # After conv2 + pool: 14 -> 10 -> 5\n",
    "        # Final size: 16 channels * 5 * 5 = 400\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        # END SOLUTION\n",
    "\n",
    "    def forward(self, x):\n",
    "        # BEGIN SOLUTION\n",
    "        # Apply conv -> relu -> pool twice, then flatten and pass through FC layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "        # END SOLUTION\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "# Test that net is defined and is an nn.Module\n",
    "assert isinstance(net, nn.Module), \"net should be an nn.Module\"\n",
    "# Test forward pass with sample input\n",
    "sample = torch.randn(1, 3, 32, 32)\n",
    "with torch.no_grad():\n",
    "    output = net(sample)\n",
    "assert output.shape == (1, 10), f\"Expected output shape (1, 10), got {output.shape}\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "# Verify the network has convolutional and linear layers\n",
    "has_conv = any(isinstance(m, nn.Conv2d) for m in net.modules())\n",
    "has_linear = any(isinstance(m, nn.Linear) for m in net.modules())\n",
    "assert has_conv, \"Network should have Conv2d layers\"\n",
    "assert has_linear, \"Network should have Linear layers\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Select a Loss Function and Optimizer\n",
    "\n",
    "We'll use cross-entropy as our loss function and stochastic gradient descent (SGD) as our optimization algorithm. Instantiate both a `criterion` object and an `optimizer` object.\n",
    "\n",
    "Any choice of learning rate is fine for now, but you may need to modify it subsequently to achieve the target accuracy in Problem 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()  # SOLUTION\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)  # SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert criterion is not None, \"criterion should be defined\"\n",
    "assert optimizer is not None, \"optimizer should be defined\"\n",
    "assert isinstance(criterion, nn.CrossEntropyLoss), \"criterion should be CrossEntropyLoss\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert hasattr(optimizer, \"param_groups\"), \"optimizer should have param_groups\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Train the Network\n",
    "\n",
    "Write a training loop that trains the model for two epochs using the criterion and optimizer defined above. Print the training loss once every 2000 mini-batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # BEGIN SOLUTION\n",
    "        # Training loop: zero grads, forward, loss, backward, step\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # END SOLUTION\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:\n",
    "            print(f\"[epoch {epoch + 1}, minibatch {i + 1:5d}] loss: {running_loss / 2000:.3f}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "# Training should have completed\n",
    "assert \"running_loss\" in dir() or True, \"Training loop should have completed\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "# Verify the model has been trained (parameters should have changed)\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Evaluate on the Entire Test Dataset\n",
    "\n",
    "Calculate and print the accuracy of your network on the full test dataset. Apply the trained model to the whole test set without computing gradients, obtain the predicted labels, and compare them to the true labels to obtain the overall accuracy.\n",
    "\n",
    "Your network should achieve at least 50% accuracy. If it does not, modify your solutions to the previous problems (without increasing the number of training epochs) to achieve the target accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        # BEGIN SOLUTION\n",
    "        # Evaluate without gradients: get predictions and compare to labels\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        # END SOLUTION\n",
    "\n",
    "print(f\"Accuracy of the network on the 10000 test images: {100 * correct // total}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert total > 0, \"total should be greater than 0\"\n",
    "assert correct >= 0, \"correct should be non-negative\"\n",
    "accuracy = 100 * correct / total\n",
    "assert accuracy >= 50, f\"Model should achieve at least 50% accuracy, got {accuracy:.1f}%\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert total == 10000, \"Should evaluate on all 10000 test images\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5: Accuracy per Class\n",
    "\n",
    "The previous problem evaluated the overall accuracy. For this problem, provide a breakdown of the model's accuracy for each individual class in the dataset. Report the classification accuracy for each class separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred = dict.fromkeys(classes, 0)\n",
    "total_pred = dict.fromkeys(classes, 0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        # BEGIN SOLUTION\n",
    "        # Track correct predictions per class\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        for label, prediction in zip(labels, predictions, strict=True):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "        # END SOLUTION\n",
    "\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f\"Accuracy for {classname:5s}: {accuracy:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert len(correct_pred) == 10, \"Should have predictions for all 10 classes\"\n",
    "assert len(total_pred) == 10, \"Should have totals for all 10 classes\"\n",
    "assert all(v >= 0 for v in correct_pred.values()), \"correct_pred values should be non-negative\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert sum(total_pred.values()) == 10000, \"Total predictions should sum to 10000\"\n",
    "# END HIDDEN TESTS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
