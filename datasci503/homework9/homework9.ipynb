{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# DATASCI 503, Homework 9: Clustering and Principal Component Analysis\n",
    "\n",
    "In this assignment, you will practice hierarchical clustering, K-means clustering, and Principal Component Analysis (PCA). You will work with both synthetic dissimilarity matrices and real-world data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.cluster.hierarchy import dendrogram, fcluster, linkage\n",
    "from scipy.spatial.distance import squareform\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Part 1: Hierarchical Clustering with a Dissimilarity Matrix\n",
    "\n",
    "Consider the following dissimilarity matrix for four observations:\n",
    "\n",
    "$$D = \\begin{bmatrix}\n",
    "0 & 0.3 & 0.4 & 0.7 \\\\\n",
    "0.3 & 0 & 0.5 & 0.8 \\\\\n",
    "0.4 & 0.5 & 0 & 0.45 \\\\\n",
    "0.7 & 0.8 & 0.45 & 0\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "The rows and columns correspond to observations 1, 2, 3, and 4 respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 1a (ISLP Ch 12, Exercise 2):** Complete Linkage Dendrogram\n",
    "\n",
    "Using the dissimilarity matrix above, perform hierarchical clustering with **complete linkage** and plot the dendrogram.\n",
    "\n",
    "Store the linkage result in a variable called `linkage_complete`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dissimilarity_matrix = np.array(\n",
    "    [\n",
    "        [0, 0.3, 0.4, 0.7],\n",
    "        [0.3, 0, 0.5, 0.8],\n",
    "        [0.4, 0.5, 0, 0.45],\n",
    "        [0.7, 0.8, 0.45, 0],\n",
    "    ]\n",
    ")\n",
    "observation_names = np.array([\"1\", \"2\", \"3\", \"4\"])\n",
    "\n",
    "# BEGIN SOLUTION\n",
    "# Solutions in this assignment are adapted from work by Song Haoyi.\n",
    "\n",
    "# Convert full dissimilarity matrix to condensed form (upper triangle as 1D array)\n",
    "condensed_matrix = squareform(dissimilarity_matrix)\n",
    "\n",
    "# Perform hierarchical clustering with complete linkage\n",
    "linkage_complete = linkage(condensed_matrix, method=\"complete\")\n",
    "\n",
    "# Plot dendrogram\n",
    "plt.figure(figsize=(10, 5))\n",
    "dendrogram(linkage_complete, labels=observation_names)\n",
    "plt.title(\"Dendrogram (Complete Linkage)\")\n",
    "plt.xlabel(\"Observations\")\n",
    "plt.ylabel(\"Distance\")\n",
    "plt.show()\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert linkage_complete is not None, \"linkage_complete should be defined\"\n",
    "assert linkage_complete.shape == (3, 4), \"Linkage matrix should have shape (3, 4)\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "# Check that complete linkage was used (verify merge distances)\n",
    "assert np.isclose(linkage_complete[0, 2], 0.3, atol=0.01), \"First merge distance should be 0.3\"\n",
    "assert np.isclose(linkage_complete[1, 2], 0.45, atol=0.01), \"Second merge distance should be 0.45\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 1b:** Single Linkage Dendrogram\n",
    "\n",
    "Now perform hierarchical clustering with **single linkage** on the same dissimilarity matrix and plot the dendrogram.\n",
    "\n",
    "Store the linkage result in a variable called `linkage_single`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "# Perform hierarchical clustering with single linkage\n",
    "linkage_single = linkage(condensed_matrix, method=\"single\")\n",
    "\n",
    "# Plot dendrogram\n",
    "plt.figure(figsize=(10, 5))\n",
    "dendrogram(linkage_single, labels=observation_names)\n",
    "plt.title(\"Dendrogram (Single Linkage)\")\n",
    "plt.xlabel(\"Observations\")\n",
    "plt.ylabel(\"Distance\")\n",
    "plt.show()\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert linkage_single is not None, \"linkage_single should be defined\"\n",
    "assert linkage_single.shape == (3, 4), \"Linkage matrix should have shape (3, 4)\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "# Check that single linkage was used\n",
    "assert np.isclose(linkage_single[0, 2], 0.3, atol=0.01), \"First merge distance should be 0.3\"\n",
    "# Single linkage produces different second merge than complete\n",
    "assert (\n",
    "    linkage_single[1, 2] < linkage_complete[1, 2]\n",
    "), \"Single linkage should have smaller merge distances\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 1c:** Cutting the Complete Linkage Dendrogram\n",
    "\n",
    "Cut the **complete linkage** dendrogram at a height that produces exactly **2 clusters**. Use a distance threshold of `t=0.5`.\n",
    "\n",
    "Store the cluster assignments in a variable called `clusters_complete`.\n",
    "\n",
    "Print the cluster memberships showing which observations belong to each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "clusters_complete = fcluster(linkage_complete, t=0.5, criterion=\"distance\")\n",
    "\n",
    "for cluster_id in np.unique(clusters_complete):\n",
    "    members = observation_names[clusters_complete == cluster_id]\n",
    "    print(f\"Cluster {cluster_id} contains: {{{', '.join(members)}}}\")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert clusters_complete is not None, \"clusters_complete should be defined\"\n",
    "assert len(clusters_complete) == 4, \"Should have cluster assignments for 4 observations\"\n",
    "assert len(np.unique(clusters_complete)) == 2, \"Should produce exactly 2 clusters\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "# Observations 1 and 2 should be in the same cluster (closest pair)\n",
    "assert (\n",
    "    clusters_complete[0] == clusters_complete[1]\n",
    "), \"Observations 1 and 2 should be in the same cluster\"\n",
    "# Observations 3 and 4 should be in the same cluster\n",
    "assert (\n",
    "    clusters_complete[2] == clusters_complete[3]\n",
    "), \"Observations 3 and 4 should be in the same cluster\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 1d:** Cutting the Single Linkage Dendrogram\n",
    "\n",
    "Cut the **single linkage** dendrogram at a height of `t=0.42` to produce 2 clusters.\n",
    "\n",
    "Store the cluster assignments in a variable called `clusters_single`.\n",
    "\n",
    "Print the cluster memberships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "clusters_single = fcluster(linkage_single, t=0.42, criterion=\"distance\")\n",
    "\n",
    "for cluster_id in np.unique(clusters_single):\n",
    "    members = observation_names[clusters_single == cluster_id]\n",
    "    print(f\"Cluster {cluster_id} contains: {{{', '.join(members)}}}\")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert clusters_single is not None, \"clusters_single should be defined\"\n",
    "assert len(clusters_single) == 4, \"Should have cluster assignments for 4 observations\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "# With single linkage at t=0.42, should get 2 clusters: {1,2,3} and {4}\n",
    "assert len(np.unique(clusters_single)) == 2, \"Should produce 2 clusters at t=0.42\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 1e:** Reordering the Dendrogram\n",
    "\n",
    "Dendrograms can look different depending on how sibling nodes are ordered, even though they represent the same clustering. Demonstrate this by reordering the observations and showing that the dendrogram looks different but represents the same hierarchical structure.\n",
    "\n",
    "Swap the order of observations: use the order [2, 1, 4, 3] instead of [1, 2, 3, 4].\n",
    "\n",
    "Store the new linkage result in `linkage_reordered` and plot the dendrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "# Reorder observations: swap pairs (1,2) and (3,4)\n",
    "swap_indices = np.array([1, 0, 3, 2])\n",
    "dissimilarity_reordered = dissimilarity_matrix[swap_indices][:, swap_indices]\n",
    "observation_names_reordered = observation_names[swap_indices]\n",
    "\n",
    "# Convert reordered dissimilarity matrix to condensed form\n",
    "condensed_reordered = squareform(dissimilarity_reordered)\n",
    "\n",
    "# Perform hierarchical clustering with complete linkage on reordered data\n",
    "linkage_reordered = linkage(condensed_reordered, method=\"complete\")\n",
    "\n",
    "# Plot dendrogram\n",
    "plt.figure(figsize=(10, 5))\n",
    "dendrogram(linkage_reordered, labels=observation_names_reordered)\n",
    "plt.title(\"Dendrogram (Complete Linkage, Reordered)\")\n",
    "plt.xlabel(\"Observations\")\n",
    "plt.ylabel(\"Distance\")\n",
    "plt.show()\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert linkage_reordered is not None, \"linkage_reordered should be defined\"\n",
    "assert linkage_reordered.shape == (3, 4), \"Linkage matrix should have shape (3, 4)\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "# The merge distances should be the same (same clustering structure)\n",
    "assert np.isclose(\n",
    "    linkage_reordered[0, 2], linkage_complete[0, 2], atol=0.01\n",
    "), \"Merge distances should match\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Part 2: Principal Component Analysis Theory\n",
    "\n",
    "Consider a dataset with 2 features. The eigenvectors and eigenvalues of the covariance matrix are:\n",
    "\n",
    "$$U = \\begin{bmatrix} u_1 & u_2 \\end{bmatrix} = \\begin{bmatrix} 0.6 & -0.8 \\\\ 0.8 & 0.6 \\end{bmatrix}$$\n",
    "\n",
    "$$\\Lambda = \\begin{bmatrix} \\lambda_1 & 0 \\\\ 0 & \\lambda_2 \\end{bmatrix} = \\begin{bmatrix} 4 & 0 \\\\ 0 & 1 \\end{bmatrix}$$\n",
    "\n",
    "where $u_1$ and $u_2$ are the principal component directions (columns of $U$) and $\\lambda_1, \\lambda_2$ are the corresponding eigenvalues (variances)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 2a:** Computing the Covariance Matrix (free response)\n",
    "\n",
    "Given the eigenvectors $U$ and eigenvalues $\\Lambda$, compute the original covariance matrix using the relationship:\n",
    "\n",
    "$$\\Sigma = U \\Lambda U^T$$\n",
    "\n",
    "Show your work and express the final answer as a 2x2 matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "The covariance matrix is computed as:\n",
    "\n",
    "$$\\Sigma = U \\Lambda U^T = \\begin{bmatrix} 0.6 & -0.8 \\\\ 0.8 & 0.6 \\end{bmatrix} \\begin{bmatrix} 4 & 0 \\\\ 0 & 1 \\end{bmatrix} \\begin{bmatrix} 0.6 & 0.8 \\\\ -0.8 & 0.6 \\end{bmatrix}$$\n",
    "\n",
    "First, compute $U\\Lambda$:\n",
    "$$U\\Lambda = \\begin{bmatrix} 0.6 \\cdot 4 & -0.8 \\cdot 1 \\\\ 0.8 \\cdot 4 & 0.6 \\cdot 1 \\end{bmatrix} = \\begin{bmatrix} 2.4 & -0.8 \\\\ 3.2 & 0.6 \\end{bmatrix}$$\n",
    "\n",
    "Then multiply by $U^T$:\n",
    "$$\\Sigma = \\begin{bmatrix} 2.4 \\cdot 0.6 + (-0.8) \\cdot (-0.8) & 2.4 \\cdot 0.8 + (-0.8) \\cdot 0.6 \\\\ 3.2 \\cdot 0.6 + 0.6 \\cdot (-0.8) & 3.2 \\cdot 0.8 + 0.6 \\cdot 0.6 \\end{bmatrix} = \\begin{bmatrix} 1.44 + 0.64 & 1.92 - 0.48 \\\\ 1.92 - 0.48 & 2.56 + 0.36 \\end{bmatrix} = \\begin{bmatrix} 2.08 & 1.44 \\\\ 1.44 & 2.92 \\end{bmatrix}$$\n",
    "> END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 2b:** Variance Explained (free response)\n",
    "\n",
    "What percentage of the total variance is explained by the first principal component?\n",
    "\n",
    "Show your calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "The proportion of variance explained by the first PC is:\n",
    "\n",
    "$$\\frac{\\lambda_1}{\\lambda_1 + \\lambda_2} = \\frac{4}{4 + 1} = \\frac{4}{5} = 0.80 = 80\\%$$\n",
    "\n",
    "The first principal component explains **80%** of the total variance.\n",
    "> END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 2c:** Computing Principal Component Scores (free response)\n",
    "\n",
    "For a data point $x = [1, 2]$, compute the scores (projections) onto both principal components.\n",
    "\n",
    "Recall that the score for PC $i$ is computed as $PC_i = x \\cdot u_i$.\n",
    "\n",
    "Show your work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "For $x = [1, 2]$:\n",
    "\n",
    "**First Principal Component Score:**\n",
    "$$PC_1 = x \\cdot u_1 = \\begin{bmatrix} 1 & 2 \\end{bmatrix} \\begin{bmatrix} 0.6 \\\\ 0.8 \\end{bmatrix} = 1 \\times 0.6 + 2 \\times 0.8 = 0.6 + 1.6 = 2.2$$\n",
    "\n",
    "**Second Principal Component Score:**\n",
    "$$PC_2 = x \\cdot u_2 = \\begin{bmatrix} 1 & 2 \\end{bmatrix} \\begin{bmatrix} -0.8 \\\\ 0.6 \\end{bmatrix} = 1 \\times (-0.8) + 2 \\times 0.6 = -0.8 + 1.2 = 0.4$$\n",
    "\n",
    "The PC scores are: $PC_1 = 2.2$ and $PC_2 = 0.4$.\n",
    "> END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## Part 3: Clustering US Arrests Data\n",
    "\n",
    "In this question, you will apply clustering techniques to the US Arrests dataset, which contains violent crime rates per 100,000 residents for each US state. The variables are:\n",
    "- **Murder**: Murder arrests per 100,000\n",
    "- **Assault**: Assault arrests per 100,000\n",
    "- **UrbanPop**: Percent urban population\n",
    "- **Rape**: Rape arrests per 100,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "arrests = pd.read_csv(\"./data/arrests.csv\")\n",
    "state_names = arrests[\"rownames\"].values\n",
    "features = arrests.drop([\"rownames\"], axis=1)\n",
    "\n",
    "print(f\"Dataset shape: {features.shape}\")\n",
    "print(f\"Features: {list(features.columns)}\")\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 3a:** Hierarchical Clustering Dendrogram\n",
    "\n",
    "Perform hierarchical clustering on the (unscaled) US Arrests data using **complete linkage** and plot the dendrogram.\n",
    "\n",
    "Store the linkage result in a variable called `arrests_linkage`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "# Perform hierarchical clustering with complete linkage\n",
    "arrests_linkage = linkage(features, method=\"complete\")\n",
    "\n",
    "# Plot the dendrogram\n",
    "plt.figure(figsize=(12, 6))\n",
    "dendrogram(arrests_linkage)\n",
    "plt.title(\"Hierarchical Clustering of US Arrests Data (Complete Linkage)\")\n",
    "plt.xlabel(\"State Index\")\n",
    "plt.ylabel(\"Distance\")\n",
    "plt.show()\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert arrests_linkage is not None, \"arrests_linkage should be defined\"\n",
    "assert arrests_linkage.shape[0] == 49, \"Linkage should have 49 merges (50 states - 1)\"\n",
    "assert arrests_linkage.shape[1] == 4, \"Linkage matrix should have 4 columns\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "# Check that distances are reasonable for unscaled data\n",
    "assert arrests_linkage[-1, 2] > 100, \"Final merge distance should be > 100 for unscaled data\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 3b:** Cutting into 5 Clusters\n",
    "\n",
    "Cut the dendrogram at a distance threshold of `t=75` to obtain cluster assignments.\n",
    "\n",
    "Store the cluster labels in a variable called `hierarchical_labels`.\n",
    "\n",
    "Print which states belong to each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "hierarchical_labels = fcluster(arrests_linkage, t=75, criterion=\"distance\")\n",
    "\n",
    "print(\"Hierarchical Clustering Results (t=75):\")\n",
    "for cluster_id in np.unique(hierarchical_labels):\n",
    "    cluster_states = state_names[hierarchical_labels == cluster_id]\n",
    "    print(f\"Cluster {cluster_id}: {cluster_states}\")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert hierarchical_labels is not None, \"hierarchical_labels should be defined\"\n",
    "assert len(hierarchical_labels) == 50, \"Should have labels for 50 states\"\n",
    "num_clusters = len(np.unique(hierarchical_labels))\n",
    "assert num_clusters == 5, f\"Should produce 5 clusters at t=75, got {num_clusters}\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "# Check that cluster assignments are integers\n",
    "assert hierarchical_labels.dtype in [np.int32, np.int64], \"Cluster labels should be integers\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "Here is a helper function to create silhouette plots for evaluating cluster quality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def silhouette_plot(data, labels):\n",
    "    \"\"\"Create a silhouette plot and return the average silhouette score.\"\"\"\n",
    "    silhouette_avg = silhouette_score(data, labels, metric=\"euclidean\")\n",
    "    sample_silhouette_values = silhouette_samples(data, labels)\n",
    "    y_lower = 10\n",
    "\n",
    "    for cluster_id in np.unique(labels):\n",
    "        cluster_silhouette_values = sample_silhouette_values[labels == cluster_id]\n",
    "        cluster_silhouette_values.sort()\n",
    "\n",
    "        cluster_size = cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + cluster_size\n",
    "\n",
    "        color = plt.cm.nipy_spectral(float(cluster_id) / 5)\n",
    "        plt.fill_betweenx(\n",
    "            np.arange(y_lower, y_upper),\n",
    "            0,\n",
    "            cluster_silhouette_values,\n",
    "            facecolor=color,\n",
    "            edgecolor=color,\n",
    "            alpha=0.7,\n",
    "        )\n",
    "        plt.plot(\n",
    "            cluster_silhouette_values,\n",
    "            np.arange(y_lower, y_upper),\n",
    "            \"k.\",\n",
    "            alpha=0.7,\n",
    "        )\n",
    "        plt.text(-0.05, y_lower + 0.5 * cluster_size, str(cluster_id))\n",
    "        y_lower = y_upper + 10\n",
    "\n",
    "    plt.xlabel(\"Silhouette Coefficient Values\")\n",
    "    plt.ylabel(\"Cluster Label\")\n",
    "    plt.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "    plt.yticks([])\n",
    "    plt.xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    return silhouette_avg\n",
    "\n",
    "\n",
    "# Create silhouette plot for hierarchical clustering\n",
    "plt.figure(figsize=(10, 7))\n",
    "silhouette_hierarchical = silhouette_plot(features, hierarchical_labels)\n",
    "plt.title(\n",
    "    f\"Silhouette Analysis - Hierarchical Clustering (avg={silhouette_hierarchical:.3f})\",\n",
    "    fontsize=14,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 3c:** K-Means Clustering\n",
    "\n",
    "Apply K-means clustering to the (unscaled) US Arrests data with `n_clusters=5` and `random_state=33`.\n",
    "\n",
    "Store the fitted KMeans object in a variable called `kmeans_model` and the cluster labels (1-indexed) in `kmeans_labels`.\n",
    "\n",
    "Print which states belong to each cluster and compare the silhouette score with hierarchical clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "kmeans_model = KMeans(n_clusters=5, random_state=33, n_init=10)\n",
    "kmeans_model.fit(features)\n",
    "# Add 1 to make labels 1-indexed (consistent with hierarchical)\n",
    "kmeans_labels = kmeans_model.predict(features) + 1\n",
    "\n",
    "print(\"K-Means Clustering Results:\")\n",
    "for cluster_id in np.unique(kmeans_labels):\n",
    "    cluster_states = state_names[kmeans_labels == cluster_id]\n",
    "    print(f\"Cluster {cluster_id}: {cluster_states}\")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert kmeans_model is not None, \"kmeans_model should be defined\"\n",
    "assert kmeans_labels is not None, \"kmeans_labels should be defined\"\n",
    "assert len(kmeans_labels) == 50, \"Should have labels for 50 states\"\n",
    "assert len(np.unique(kmeans_labels)) == 5, \"Should have exactly 5 clusters\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "# Check that labels are 1-indexed\n",
    "assert min(kmeans_labels) == 1, \"Labels should be 1-indexed\"\n",
    "assert max(kmeans_labels) == 5, \"Max label should be 5\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create silhouette plot for K-means\n",
    "plt.figure(figsize=(10, 7))\n",
    "silhouette_kmeans = silhouette_plot(features, kmeans_labels)\n",
    "plt.title(\n",
    "    f\"Silhouette Analysis - K-Means Clustering (avg={silhouette_kmeans:.3f})\",\n",
    "    fontsize=14,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSilhouette Score Comparison:\")\n",
    "print(f\"  Hierarchical: {silhouette_hierarchical:.4f}\")\n",
    "print(f\"  K-Means:      {silhouette_kmeans:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 3d:** Effect of Scaling\n",
    "\n",
    "The features in the arrests dataset have very different scales (e.g., UrbanPop is a percentage while Assault can be in the hundreds). Scaling the features before clustering can significantly affect the results.\n",
    "\n",
    "Use [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) to scale the features, then repeat the hierarchical clustering (complete linkage, cut at `t=3.2` for 5 clusters) and K-means clustering (`n_clusters=5`, `random_state=33`).\n",
    "\n",
    "Store the scaled data in `features_scaled`, the hierarchical labels in `hierarchical_labels_scaled`, and the K-means labels in `kmeans_labels_scaled`.\n",
    "\n",
    "Compare the silhouette scores with and without scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "features_scaled = pd.DataFrame(scaler.fit_transform(features), columns=features.columns)\n",
    "\n",
    "# Hierarchical clustering on scaled data\n",
    "linkage_scaled = linkage(features_scaled, method=\"complete\")\n",
    "hierarchical_labels_scaled = fcluster(linkage_scaled, t=3.2, criterion=\"distance\")\n",
    "\n",
    "print(\"Hierarchical Clustering on Scaled Data (t=3.2):\")\n",
    "for cluster_id in np.unique(hierarchical_labels_scaled):\n",
    "    cluster_states = state_names[hierarchical_labels_scaled == cluster_id]\n",
    "    print(f\"Cluster {cluster_id}: {cluster_states}\")\n",
    "\n",
    "# K-means on scaled data\n",
    "kmeans_scaled = KMeans(n_clusters=5, random_state=33, n_init=10)\n",
    "kmeans_scaled.fit(features_scaled)\n",
    "kmeans_labels_scaled = kmeans_scaled.predict(features_scaled) + 1\n",
    "\n",
    "print(\"\\nK-Means Clustering on Scaled Data:\")\n",
    "for cluster_id in np.unique(kmeans_labels_scaled):\n",
    "    cluster_states = state_names[kmeans_labels_scaled == cluster_id]\n",
    "    print(f\"Cluster {cluster_id}: {cluster_states}\")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert features_scaled is not None, \"features_scaled should be defined\"\n",
    "assert hierarchical_labels_scaled is not None, \"hierarchical_labels_scaled should be defined\"\n",
    "assert kmeans_labels_scaled is not None, \"kmeans_labels_scaled should be defined\"\n",
    "assert features_scaled.shape == features.shape, \"Scaled features should have same shape\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "# Check that scaling was applied correctly\n",
    "assert np.allclose(features_scaled.mean(), 0, atol=1e-10), \"Scaled features should have mean ~0\"\n",
    "assert np.allclose(features_scaled.std(), 1, atol=0.1), \"Scaled features should have std ~1\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silhouette plots for scaled data\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "plt.sca(axes[0])\n",
    "silhouette_hier_scaled = silhouette_plot(features_scaled, hierarchical_labels_scaled)\n",
    "axes[0].set_title(\n",
    "    f\"Hierarchical (Scaled) - avg={silhouette_hier_scaled:.3f}\",\n",
    "    fontsize=12,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "\n",
    "plt.sca(axes[1])\n",
    "silhouette_kmeans_scaled = silhouette_plot(features_scaled, kmeans_labels_scaled)\n",
    "axes[1].set_title(\n",
    "    f\"K-Means (Scaled) - avg={silhouette_kmeans_scaled:.3f}\",\n",
    "    fontsize=12,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSilhouette Score Comparison:\")\n",
    "print(f\"  Unscaled Hierarchical: {silhouette_hierarchical:.4f}\")\n",
    "print(f\"  Scaled Hierarchical:   {silhouette_hier_scaled:.4f}\")\n",
    "print(f\"  Unscaled K-Means:      {silhouette_kmeans:.4f}\")\n",
    "print(f\"  Scaled K-Means:        {silhouette_kmeans_scaled:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 3e:** PCA on Arrests Data\n",
    "\n",
    "Apply Principal Component Analysis to the (unscaled) arrests data with 3 components using [`sklearn.decomposition.PCA`](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html).\n",
    "\n",
    "Store the fitted PCA object in a variable called `pca_model`.\n",
    "\n",
    "Report:\n",
    "1. The variance explained by each principal component\n",
    "2. The proportion of variance explained by each component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "pca_model = PCA(n_components=3, svd_solver=\"full\")\n",
    "pca_model.fit(features)\n",
    "\n",
    "print(\"Variance explained by each PC:\")\n",
    "for idx, var in enumerate(pca_model.explained_variance_):\n",
    "    print(f\"  PC{idx + 1}: {var:.2f}\")\n",
    "\n",
    "print(\"\\nProportion of variance explained:\")\n",
    "for idx, ratio in enumerate(pca_model.explained_variance_ratio_):\n",
    "    print(f\"  PC{idx + 1}: {ratio:.4f} ({ratio * 100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nCumulative variance explained: {sum(pca_model.explained_variance_ratio_) * 100:.2f}%\")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert pca_model is not None, \"pca_model should be defined\"\n",
    "assert hasattr(pca_model, \"explained_variance_\"), \"PCA model should be fitted\"\n",
    "assert len(pca_model.explained_variance_) == 3, \"Should have 3 components\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "# Check that PC1 explains most variance\n",
    "assert (\n",
    "    pca_model.explained_variance_ratio_[0] > 0.9\n",
    "), \"PC1 should explain >90% variance (unscaled data)\"\n",
    "# Variances should be in decreasing order\n",
    "assert (\n",
    "    pca_model.explained_variance_[0] > pca_model.explained_variance_[1]\n",
    "), \"PC1 variance > PC2 variance\"\n",
    "assert (\n",
    "    pca_model.explained_variance_[1] > pca_model.explained_variance_[2]\n",
    "), \"PC2 variance > PC3 variance\"\n",
    "# END HIDDEN TESTS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
