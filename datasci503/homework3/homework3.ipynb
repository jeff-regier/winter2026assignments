{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASCI 503, Homework 3: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is one of the most widely used methods for binary classification. It models the probability that an observation belongs to a particular class. In this assignment, you'll explore odds, log-odds, and the softmax generalization to multiple classes, while training classifiers and evaluating performance using ROC curves and AUC. But first, a problem about the curse of dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 1 (ISLP Ch 4, Exercise 4):** The Curse of Dimensionality\n",
    "\n",
    "When the number of features $p$ is large, there tends to be a deterioration in the performance of KNN and other *local* approaches that perform prediction using only observations that are *near* the test observation for which a prediction must be made. This phenomenon is known as the *curse of dimensionality*, and it ties into the fact that non-parametric approaches often perform poorly when $p$ is large. We will now investigate this curse.\n",
    "\n",
    "**(a)** Suppose that we have a set of observations, each with measurements on $p = 1$ feature, $X$. We assume that $X$ is uniformly (evenly) distributed on $[0, 1]$. Associated with each observation is a response value. Suppose that we wish to predict a test observation's response using only observations that are within 10% of the range of $X$ closest to that test observation. For instance, in order to predict the response for a test observation with $X = 0.6$, we will use observations in the range $[0.55, 0.65]$. On average, what fraction of the available observations will we use to make the prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "For $p = 1$, $X \\sim \\text{Uniform}[0,1]$. The fraction of the available observations used to make each prediction is always **10%**.\n",
    "\n",
    "> END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** Now suppose that we have a set of observations, each with measurements on $p = 2$ features, $X_1$ and $X_2$. We assume that $(X_1, X_2)$ are uniformly distributed on $[0, 1] \\times [0, 1]$. We wish to predict a test observation's response using only observations that are within 10% of the range of $X_1$ *and* within 10% of the range of $X_2$ closest to that test observation. For instance, in order to predict the response for a test observation with $X_1 = 0.6$ and $X_2 = 0.35$, we will use observations in the range $[0.55, 0.65]$ for $X_1$ and in the range $[0.3, 0.4]$ for $X_2$. On average, what fraction of the available observations will we use to make the prediction?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "For $p = 2$, the fraction is $0.1 \\times 0.1 = 0.01$, or **1%**.\n",
    "\n",
    "> END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** Now suppose that we have a set of observations on $p = 100$ features. Again the observations are uniformly distributed on each feature, and again each feature ranges in value from 0 to 1. We wish to predict a test observation's response using observations within the 10% of each feature's range that is closest to that test observation. What fraction of the available observations will we use to make the prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "For $p = 100$, the fraction is $0.1^{100}$, which is essentially **0%**.\n",
    "\n",
    "> END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d)** Using your answers to parts (a)â€“(c), argue that a drawback of KNN when $p$ is large is that there are very few training observations \"near\" any given test observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "The drawback of KNN with large $p$ is that as $p$ increases, the fraction of available observations used for prediction approaches 0. KNN's simple idea that similar inputs lead to similar outputs is not powerful enough for high-dimensional problems.\n",
    "\n",
    "> END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e)** Now suppose that we wish to make a prediction for a test observation by creating a $p$-dimensional hypercube centered around the test observation that contains, on average, 10% of the training observations. For $p = 1, 2,$ and $100$, what is the length of each side of the hypercube? Comment on your answer.\n",
    "\n",
    "> *Note: A hypercube is a generalization of a cube to an arbitrary number of dimensions. When $p = 1$, a hypercube is simply a line segment, when $p = 2$ it is a square, and when $p = 100$ it is a 100-dimensional cube.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "Since Volume $= s^p = 0.1$, we have $s = 0.1^{1/p}$.\n",
    "- For $p = 1$: $s = 0.1$\n",
    "- For $p = 2$: $s \\approx 0.316$\n",
    "- For $p = 100$: $s \\approx 0.977$ (nearly the full range)\n",
    "\n",
    "> END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 2 (ISLP Ch 4, Exercise 1):** Deriving the Odds Formula\n",
    "\n",
    "Using a little bit of algebra, prove that\n",
    "\n",
    "$$p(X) = \\frac{e^{\\beta_0 + \\beta_1 X}}{1 + e^{\\beta_0 + \\beta_1 X}}$$\n",
    "\n",
    "is equivalent to\n",
    "\n",
    "$$\\frac{p(X)}{1 - p(X)} = e^{\\beta_0 + \\beta_1 X}.$$\n",
    "\n",
    "In other words, the logistic function representation and logit representation for the logistic regression model are equivalent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "From the logistic regression formula:\n",
    "\n",
    "$$\n",
    "p(x) = \\frac{e^{\\beta_0 + \\beta_1 X}}{1+ e^{\\beta_0 + \\beta_1 X}}\n",
    "$$\n",
    "\n",
    "So\n",
    "\n",
    "$$\n",
    "1-p(x) = 1-\\frac{e^{\\beta_0 + \\beta_1 X}}{1+ e^{\\beta_0 + \\beta_1 X}} = \\frac{1}{1+ e^{\\beta_0 + \\beta_1 X}}\n",
    "$$\n",
    "\n",
    "Therefore\n",
    "\n",
    "$$\n",
    "\\frac{p(x)}{1-p(x)} = \\frac{e^{\\beta_0 + \\beta_1 X} / (1+ e^{\\beta_0 + \\beta_1 X})}{1 / (1+ e^{\\beta_0 + \\beta_1 X})} = e^{\\beta_0 + \\beta_1 X}\n",
    "$$\n",
    "\n",
    "> END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 3 (ISLP Ch 4, Exercise 9):** Odds and Probability Conversion\n",
    "\n",
    "This problem has to do with odds.\n",
    "\n",
    "**(a)** On average, what fraction of people with an odds of 0.37 of defaulting on their credit card payment will in fact default?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "Given: Odds $= \\frac{p}{1-p} = 0.37$. Solving: $p = \\frac{0.37}{1.37} \\approx 0.27$\n",
    "\n",
    "> END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** Suppose that an individual has a 16% chance of defaulting on her credit card payment. What are the odds that she will default?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "Given: $p = 0.16$. Odds $= \\frac{0.16}{0.84} \\approx 0.19$\n",
    "\n",
    "> END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 4 (ISLP Ch 4, Exercise 12, parts a, b, and c):** Softmax vs Binary Logistic Regression\n",
    "\n",
    "Suppose that you wish to classify an observation $X \\in \\mathbb{R}$ into apples and oranges. You fit a logistic regression model and find that\n",
    "\n",
    "$$\\widehat{\\Pr}(Y = \\text{orange} | X = x) = \\frac{\\exp(\\hat{\\beta}_0 + \\hat{\\beta}_1 x)}{1 + \\exp(\\hat{\\beta}_0 + \\hat{\\beta}_1 x)}.$$\n",
    "\n",
    "Your friend fits a logistic regression model to the same data using the *softmax* formulation, and finds that\n",
    "\n",
    "$$\\widehat{\\Pr}(Y = \\text{orange} | X = x) = \\frac{\\exp(\\hat{\\alpha}_{\\text{orange}0} + \\hat{\\alpha}_{\\text{orange}1} x)}{\\exp(\\hat{\\alpha}_{\\text{orange}0} + \\hat{\\alpha}_{\\text{orange}1} x) + \\exp(\\hat{\\alpha}_{\\text{apple}0} + \\hat{\\alpha}_{\\text{apple}1} x)}.$$\n",
    "\n",
    "**(a)** What is the log odds of orange versus apple in your model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "From the log-odds formulation: $\\frac{p(\\text{orange}|x)}{p(\\text{apple}|x)} = e^{\\beta_0 + \\beta_1 X}$\n",
    "\n",
    "> END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** What is the log odds of orange versus apple in your friend's model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "Taking the ratio of probabilities and simplifying:\n",
    "$$\\log \\left( \\frac{p(\\text{orange} | x)}{p(\\text{apple}|x)} \\right) = (\\hat{\\alpha}_{\\text{orange},0} - \\hat{\\alpha}_{\\text{apple},0}) + (\\hat{\\alpha}_{\\text{orange},1} - \\hat{\\alpha}_{\\text{apple},1}) X$$\n",
    "\n",
    "> END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** Suppose that in your model, $\\hat{\\beta}_0 = 2$ and $\\hat{\\beta}_1 = -1$. What are the coefficient estimates in your friend's model? Be as specific as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "The relationship is: $\\hat{\\beta}_0 = \\hat{\\alpha}_{\\text{orange},0} - \\hat{\\alpha}_{\\text{apple},0}$ and $\\hat{\\beta}_1 = \\hat{\\alpha}_{\\text{orange},1} - \\hat{\\alpha}_{\\text{apple},1}$. With the given values, the friend's model gives different predictions since $1.2 - 3 = -1.8 \\neq 2$.\n",
    "\n",
    "> END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 5:** Predicting Academic Success\n",
    "\n",
    "Suppose we fit logistic regression to predict the probability that a STATS 503 student gets an A in the class, from two variables. The variables are average hours of study per week ($X_1$) and GPA in other statistics courses taken ($X_2$). The fitted coefficients are $\\beta_0 = -4$, $\\beta_1 = 0.05$, and $\\beta_2 = 1$.\n",
    "\n",
    "**(a)** Predict the probability of getting an A for a student who studies 5 hours a week and has a GPA of 3.5 in other statistics courses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "Log-odds $= -4 + 0.05(5) + 3.5 = -0.25$, so $p = \\frac{e^{-0.25}}{1+e^{-0.25}} \\approx 0.438$ or **43.8%**.\n",
    "\n",
    "> END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) What are the odds this student gets an A?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "Odds $= e^{-0.25} \\approx 0.779$\n",
    "\n",
    "> END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) How many hours would this student need to study to have a 50% chance of getting an A?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "For $p = 0.5$, log-odds $= 0$. Solving $0 = -4 + 0.05 X_1 + 3.5$ gives $X_1 = 10$ hours.\n",
    "\n",
    "> END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applied Problems: College Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college_train = pd.read_csv(\"./data/college_train.csv\")\n",
    "college_test = pd.read_csv(\"./data/college_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = college_train.drop([\"Private\", \"Name\"], axis=1)\n",
    "Y_train = np.where(college_train[\"Private\"] == \"Yes\", 1, 0)\n",
    "X_test = college_test.drop([\"Private\", \"Name\"], axis=1)\n",
    "Y_test = np.where(college_test[\"Private\"] == \"Yes\", 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 6:** Training a Classifier\n",
    "\n",
    "Train a logistic regression model to classify colleges as Private or Public using the provided training data. Store the trained model in a variable called `model_log`.\n",
    "\n",
    "**Hint:** Use [`sklearn.linear_model.LogisticRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). You may need to increase `max_iter` for convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "model_log = sklearn.linear_model.LogisticRegression(max_iter=30000)\n",
    "model_log.fit(X_train, Y_train)\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert model_log is not None, \"model_log should be defined\"\n",
    "assert hasattr(model_log, \"predict\"), \"model_log should have a predict method\"\n",
    "assert hasattr(model_log, \"predict_proba\"), \"model_log should have a predict_proba method\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert hasattr(model_log, \"coef_\"), \"Model should be fitted (have coef_ attribute)\"\n",
    "num_features = X_train.shape[1]\n",
    "assert model_log.coef_.shape[1] == num_features, \"Model should have correct coefficients\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 7:** Negative Log-Likelihood\n",
    "\n",
    "For each sample in the `college_test` dataset, use the fit model to predict the probability that `Private` is `Yes` and use the fit model to predict the probability that `Private` is `No`. Use these probabilities to calculate the negative log likelihood of the testing dataset for the model:\n",
    "\n",
    "$$-\\sum_{i=1}^{n} \\log \\hat{p}(y_i \\mid x_i),$$\n",
    "\n",
    "where $n$ is the number of samples in `college_test` and each $(x_i, y_i)$ pair is a sample from that dataset.\n",
    "Store the predicted probabilities in a variable called `y_pred_prob` and the mean NLL in a variable called `mean_nll`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "y_pred_prob = model_log.predict_proba(X_test)\n",
    "mean_nll = sklearn.metrics.log_loss(Y_test, y_pred_prob)\n",
    "print(f\"Mean NLL: {mean_nll:.4f}\")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert y_pred_prob is not None, \"y_pred_prob should be defined\"\n",
    "assert y_pred_prob.shape == (len(Y_test), 2), \"y_pred_prob should have shape (n_samples, 2)\"\n",
    "assert mean_nll is not None, \"mean_nll should be defined\"\n",
    "assert 0 < mean_nll < 1, \"mean_nll should be between 0 and 1 for a reasonable model\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert np.allclose(y_pred_prob.sum(axis=1), 1.0), \"Probabilities should sum to 1\"\n",
    "assert mean_nll < 0.5, \"Model should achieve NLL less than 0.5\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 8:** Classification Metrics\n",
    "\n",
    "Now use $\\hat{p}$ to create a hard classifier, also known as a decision rule. Specifically, consider the rule\n",
    "\n",
    "$$\\hat{y}(x) = \\begin{cases} \\text{Yes} & \\text{if } \\hat{p}(\\text{Yes} \\mid x) > 0.5 \\\\ \\text{No} & \\text{otherwise.} \\end{cases}$$\n",
    "\n",
    "Using the test data, compute the false positive rate (FPR), true positive rate (TPR), false negative rate (FNR), and true negative rate (TNR) made by this decision rule.\n",
    "Store these in variables `fpr`, `tpr`,  `fnr`, and `tnr`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "thresh = 0.5\n",
    "y_pred = np.where(y_pred_prob[:, 1] > thresh, 1, 0)\n",
    "\n",
    "# Calculate using confusion matrix\n",
    "cnf_matrix = sklearn.metrics.confusion_matrix(Y_test, y_pred)\n",
    "fp_count = cnf_matrix[0, 1].astype(float)\n",
    "fn_count = cnf_matrix[1, 0].astype(float)\n",
    "tp_count = cnf_matrix[1, 1].astype(float)\n",
    "tn_count = cnf_matrix[0, 0].astype(float)\n",
    "\n",
    "tpr = tp_count / (tp_count + fn_count)\n",
    "fpr = fp_count / (fp_count + tn_count)\n",
    "tnr = tn_count / (tn_count + fp_count)\n",
    "fnr = fn_count / (tp_count + fn_count)\n",
    "\n",
    "print(f\"TPR: {tpr:.4f}\")\n",
    "print(f\"FPR: {fpr:.4f}\")\n",
    "print(f\"TNR: {tnr:.4f}\")\n",
    "print(f\"FNR: {fnr:.4f}\")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert 0 <= tpr <= 1, \"TPR should be between 0 and 1\"\n",
    "assert 0 <= fpr <= 1, \"FPR should be between 0 and 1\"\n",
    "assert 0 <= tnr <= 1, \"TNR should be between 0 and 1\"\n",
    "assert 0 <= fnr <= 1, \"FNR should be between 0 and 1\"\n",
    "assert np.isclose(tpr + fnr, 1.0), \"TPR + FNR should equal 1\"\n",
    "assert np.isclose(fpr + tnr, 1.0), \"FPR + TNR should equal 1\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert tpr > 0.9, \"TPR should be greater than 0.9 for this model\"\n",
    "assert fpr < 0.15, \"FPR should be less than 0.15 for this model\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 9:** Threshold Tradeoffs\n",
    "\n",
    "We will now use $\\hat{p}$ to create a different hard classifier.\n",
    "\n",
    "$$\\hat{y}(x) = \\begin{cases} \\text{Yes} & \\text{if } \\hat{p}(\\text{Yes} \\mid x) > 0.9 \\\\ \\text{No} & \\text{otherwise.} \\end{cases}$$\n",
    "\n",
    "Using the test data, compute the FPR, TPR, FNR, and TNR for this new decision rule.\n",
    "Store the results in variables called `fpr_high`, `tpr_high`, `fnr_high`, and `tnr_high`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "thresh_high = 0.9\n",
    "y_pred_high = np.where(y_pred_prob[:, 1] > thresh_high, 1, 0)\n",
    "\n",
    "tpr_high = sklearn.metrics.recall_score(Y_test, y_pred_high)\n",
    "fpr_high = 1 - sklearn.metrics.recall_score(1 - Y_test, 1 - y_pred_high)\n",
    "tnr_high = sklearn.metrics.recall_score(1 - Y_test, 1 - y_pred_high)\n",
    "fnr_high = 1 - sklearn.metrics.recall_score(Y_test, y_pred_high)\n",
    "\n",
    "print(f\"TPR at 0.9: {tpr_high:.4f}\")\n",
    "print(f\"FPR at 0.9: {fpr_high:.4f}\")\n",
    "print(f\"TNR at 0.9: {tnr_high:.4f}\")\n",
    "print(f\"FNR at 0.9: {fnr_high:.4f}\")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert 0 <= tpr_high <= 1, \"TPR should be between 0 and 1\"\n",
    "assert 0 <= fpr_high <= 1, \"FPR should be between 0 and 1\"\n",
    "assert np.isclose(tpr_high + fnr_high, 1.0), \"TPR + FNR should equal 1\"\n",
    "assert np.isclose(fpr_high + tnr_high, 1.0), \"FPR + TNR should equal 1\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert tpr_high <= tpr, \"TPR should decrease when threshold increases\"\n",
    "assert fpr_high <= fpr, \"FPR should decrease when threshold increases\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 10:** ROC Curve\n",
    "\n",
    "We will now use $\\hat{p}$ to create a family of different hard classifiers.\n",
    "\n",
    "$$\\hat{y}_t(x) = \\begin{cases} \\text{Yes} & \\text{if } \\hat{p}(\\text{Yes} \\mid x) > t \\\\ \\text{No} & \\text{otherwise.} \\end{cases}$$\n",
    "\n",
    "Using the test data, for each value of $t \\in \\{0.0, 1/100, 2/100, \\ldots, 99/100, 1.0\\}$, compute the FPR and TPR of the decision rule $\\hat{y}_t$, saving them in variables named `fpr_list` and `tpr_list`. Plot your results as an ROC curve.\n",
    "\n",
    "*Note: It is possible to plot the ROC curve with sci-kit's `roc_curve` function, but for this problem, we want you to do it \"by hand.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "thresholds = np.arange(0, 1.001, 0.01)\n",
    "fpr_list = []\n",
    "tpr_list = []\n",
    "\n",
    "for thresh in thresholds:\n",
    "    y_pred_thresh = np.where(y_pred_prob[:, 1] > thresh, 1, 0)\n",
    "    current_tpr = sklearn.metrics.recall_score(Y_test, y_pred_thresh, zero_division=0)\n",
    "    current_fpr = 1 - sklearn.metrics.recall_score(1 - Y_test, 1 - y_pred_thresh, zero_division=0)\n",
    "    tpr_list.append(current_tpr)\n",
    "    fpr_list.append(current_fpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_list, tpr_list)\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.plot([0, 1], [0, 1], \"k--\", label=\"Random classifier\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert len(fpr_list) > 0, \"fpr_list should not be empty\"\n",
    "assert len(tpr_list) > 0, \"tpr_list should not be empty\"\n",
    "assert len(fpr_list) == len(tpr_list), \"fpr_list and tpr_list should have same length\"\n",
    "assert all(0 <= x <= 1 for x in fpr_list), \"All FPR values should be between 0 and 1\"\n",
    "assert all(0 <= x <= 1 for x in tpr_list), \"All TPR values should be between 0 and 1\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert len(fpr_list) == 101, \"Should have 101 threshold values\"\n",
    "assert fpr_list[0] == 1.0 and tpr_list[0] == 1.0, \"At threshold 0, should predict all positive\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 11:** AUC Score\n",
    "\n",
    "Use $\\hat{p}$, the test data, and `sklearn.metrics.roc_auc_score` to compute the area under your ROC curve. The first argument should be the true labels from the testing dataset. The second argument should be the probability that `Private` is `Yes`, as predicted by your model. Store the result in a variable called `auc_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "auc_score = sklearn.metrics.roc_auc_score(Y_test, y_pred_prob[:, 1])\n",
    "print(f\"AUC Score: {auc_score:.4f}\")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert auc_score is not None, \"auc_score should be defined\"\n",
    "assert 0 <= auc_score <= 1, \"AUC should be between 0 and 1\"\n",
    "assert auc_score > 0.5, \"AUC should be greater than 0.5 (better than random)\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert auc_score > 0.95, \"AUC should be greater than 0.95 for this model\"\n",
    "# END HIDDEN TESTS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "winter2026assignments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
