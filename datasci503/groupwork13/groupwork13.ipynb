{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASCI 503, Group Work 13: Autoencoders with MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions:** During lab section, and afterward as necessary, you will collaborate in two-person teams to complete the problems that are interspersed below. The GSI will help individual teams encountering difficulty, make announcements addressing common issues, and help ensure progress for all teams. **During lab, feel free to flag down your GSI to ask questions at any point!** Upon completion, one member of the team should submit their team's work through Canvas **as html**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Autoencoders are the deep learning frontier of dimensionality reduction.\n",
    "\n",
    "**Challenge**: Summarize a wide dataset with as few dimensions as possible.\n",
    "\n",
    "In the past, we have covered dimensionality techniques, primarily PCA. The idea behind PCA was maximizing the total variance in some principal directions that may differ from the raw direction of the data.\n",
    "\n",
    "In this notebook, we attempt to take in data $X$ and map it to a latent space $Z$ and see if we can learn a representative enough $Z$ to reconstruct $X$. This exercise in deep learning is accomplished with a network structure called an [autoencoder](https://www.geeksforgeeks.org/auto-encoders/#).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Data Setup\n",
    "\n",
    "We have provided most of the dataset construction for the MNIST dataset. Please create training, validation, and testing datasets as well as `DataLoader` objects for each dataset.\n",
    "\n",
    "Specifically:\n",
    "1. Apply `transforms.ToTensor()` to convert images to tensors and scale pixel values to [0, 1].\n",
    "2. Download the MNIST training set (60,000 examples) and split it into 80% training and 20% validation.\n",
    "3. Download the MNIST test set (10,000 examples).\n",
    "4. Create `DataLoader` objects for each dataset with `batch_size=512`.\n",
    "\n",
    "Store your results in variables named `train_dataset`, `val_dataset`, `test_dataset`, `train_loader`, `val_loader`, and `test_loader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "# Apply transforms to convert images to tensors and scale pixel values to [0, 1]\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# Download the MNIST training set (60,000 examples)\n",
    "full_trainset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "\n",
    "# Split training set into 80% training and 20% validation\n",
    "train_size = int(0.8 * len(full_trainset))\n",
    "val_size = len(full_trainset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_trainset, [train_size, val_size])\n",
    "\n",
    "# Download the MNIST test set (10,000 examples)\n",
    "test_dataset = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "# Create DataLoaders to load data in batches\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=512, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert len(train_dataset) == 48000, f\"Expected 48000 training samples, got {len(train_dataset)}\"\n",
    "assert len(val_dataset) == 12000, f\"Expected 12000 validation samples, got {len(val_dataset)}\"\n",
    "assert len(test_dataset) == 10000, f\"Expected 10000 test samples, got {len(test_dataset)}\"\n",
    "assert train_loader.batch_size == 512, \"train_loader batch_size should be 512\"\n",
    "assert val_loader.batch_size == 512, \"val_loader batch_size should be 512\"\n",
    "assert test_loader.batch_size == 512, \"test_loader batch_size should be 512\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert train_loader.dataset is train_dataset, \"train_loader should use train_dataset\"\n",
    "assert val_loader.dataset is val_dataset, \"val_loader should use val_dataset\"\n",
    "assert test_loader.dataset is test_dataset, \"test_loader should use test_dataset\"\n",
    "sample_batch, _ = next(iter(train_loader))\n",
    "assert sample_batch.shape == torch.Size(\n",
    "    [512, 1, 28, 28]\n",
    "), \"Sample batch shape should be [512, 1, 28, 28]\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Creating an Autoencoder\n",
    "\n",
    "Fill in the following `AutoEncoder` class by constructing an encoder network that has a depth of at least 3 layers. Note that the latent dimension is an argument that we pass into the class constructor.\n",
    "\n",
    "The encoder should:\n",
    "- Take flattened 28x28 images (784 features) as input\n",
    "- Have at least 3 hidden layers with ReLU activations\n",
    "- Output a latent representation of size `latent_dim`\n",
    "\n",
    "The decoder should:\n",
    "- Take the latent representation as input\n",
    "- Mirror the encoder structure\n",
    "- Output reconstructed images of size 784 with Sigmoid activation\n",
    "\n",
    "The `forward` method should return both the reconstruction and the latent representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(torch.nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        # BEGIN SOLUTION\n",
    "        # Encoder: 784 -> 256 -> 128 -> 64 -> latent_dim\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, latent_dim),\n",
    "        )\n",
    "\n",
    "        # Decoder: latent_dim -> 64 -> 128 -> 256 -> 784\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 28 * 28),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        # END SOLUTION\n",
    "\n",
    "    def forward(self, x):\n",
    "        # BEGIN SOLUTION\n",
    "        latents = self.encoder(x)\n",
    "        reconstruction = self.decoder(latents)\n",
    "        return reconstruction, latents\n",
    "        # END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "test_ae = AutoEncoder(latent_dim=2)\n",
    "test_input = torch.randn(10, 784)\n",
    "test_output, test_latent = test_ae(test_input)\n",
    "assert test_output.shape == (10, 784), f\"Expected output shape (10, 784), got {test_output.shape}\"\n",
    "assert test_latent.shape == (10, 2), f\"Expected latent shape (10, 2), got {test_latent.shape}\"\n",
    "assert hasattr(test_ae, \"encoder\"), \"AutoEncoder should have an encoder attribute\"\n",
    "assert hasattr(test_ae, \"decoder\"), \"AutoEncoder should have a decoder attribute\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "# Test with different latent dimensions\n",
    "test_ae_10 = AutoEncoder(latent_dim=10)\n",
    "test_output_10, test_latent_10 = test_ae_10(test_input)\n",
    "assert test_latent_10.shape == (10, 10), \"Latent dim should match constructor argument\"\n",
    "# Check output is in valid range (0, 1) due to Sigmoid\n",
    "assert torch.all(test_output >= 0) and torch.all(\n",
    "    test_output <= 1\n",
    "), \"Output should be between 0 and 1\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Training an Autoencoder\n",
    "\n",
    "Last week we learned to train neural networks with early stopping as a regularizer. Autoencoders are no different in our case than a neural network because we implement (overwrite, actually) the `forward` method of the `torch.nn.Module` class.\n",
    "\n",
    "Please finish implementing the `train_AE` function to train your autoencoder. The function should:\n",
    "1. Use MSE loss as the criterion\n",
    "2. Use the Adam optimizer with learning rate 0.001\n",
    "3. Implement early stopping based on validation loss\n",
    "4. Print the epoch, validation loss, and patience counter each epoch\n",
    "\n",
    "Please leave the print statement that states what the current epoch, validation loss, and patience counter is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_autoencoder(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    model=None,\n",
    "    num_epochs=100,\n",
    "    early_stopping_patience=5,\n",
    "):\n",
    "    if model is None:\n",
    "        model = AutoEncoder(latent_dim=2)\n",
    "\n",
    "    # BEGIN SOLUTION\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    patience_counter = 0\n",
    "    lowest_val_loss = float(\"inf\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training loop\n",
    "        model.train()\n",
    "        for data in train_loader:\n",
    "            images, _ = data\n",
    "            images = images.view(images.shape[0], -1)\n",
    "\n",
    "            outputs, _latents = model(images)\n",
    "            loss = criterion(outputs, images)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for data in val_loader:\n",
    "                images, _ = data\n",
    "                images = images.view(images.shape[0], -1)\n",
    "\n",
    "                outputs, _latents = model(images)\n",
    "                val_loss += criterion(outputs, images).item()\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        # Early stopping check\n",
    "        if val_loss < lowest_val_loss:\n",
    "            lowest_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                break\n",
    "\n",
    "        print(\n",
    "            f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
    "            f\"Validation Loss: {val_loss:.4f}, Patience Count: {patience_counter}\"\n",
    "        )\n",
    "    # END SOLUTION\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "# Test that train_autoencoder returns a model\n",
    "import inspect\n",
    "\n",
    "sig = inspect.signature(train_autoencoder)\n",
    "params = list(sig.parameters.keys())\n",
    "assert \"train_loader\" in params, \"train_autoencoder should have train_loader parameter\"\n",
    "assert \"val_loader\" in params, \"train_autoencoder should have val_loader parameter\"\n",
    "assert \"num_epochs\" in params, \"train_autoencoder should have num_epochs parameter\"\n",
    "assert (\n",
    "    \"early_stopping_patience\" in params\n",
    "), \"train_autoencoder should have early_stopping_patience parameter\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "# Quick test with 1 epoch to verify function works\n",
    "quick_model = AutoEncoder(latent_dim=2)\n",
    "quick_result = train_autoencoder(train_loader, val_loader, model=quick_model, num_epochs=1)\n",
    "assert isinstance(quick_result, AutoEncoder), \"train_autoencoder should return an AutoEncoder\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_autoencoder = train_autoencoder(train_loader, val_loader, num_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4: Understanding Big Picture Details of Autoencoders\n",
    "\n",
    "Now that you have built an autoencoder which consists of an encoder and a decoder, please write in markdown the answers to the following questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)** In 1-2 sentences **MAX**, what is the encoder doing to the input data?\n",
    "\n",
    "> BEGIN SOLUTION\n",
    "\n",
    "The encoder compresses the high-dimensional input data (784 pixels) into a lower-dimensional latent representation (e.g., 2 dimensions), capturing the most important features needed for reconstruction.\n",
    "> END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)** Why as practitioners might we care about a latent space?\n",
    "\n",
    "> BEGIN SOLUTION\n",
    "\n",
    "The latent space provides a compact, meaningful representation of the data that can be used for visualization, clustering, interpolation between data points, anomaly detection, and as features for downstream tasks. It also enables generative modeling by sampling from the latent space.\n",
    "> END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3)** In 1-2 sentences **MAX**, what is the decoder doing given values from the latent space?\n",
    "\n",
    "> BEGIN SOLUTION\n",
    "\n",
    "The decoder reconstructs the original high-dimensional data from the compressed latent representation by learning to map from the low-dimensional latent space back to the original image space.\n",
    "> END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5: Bring the Latent Spaces to Life\n",
    "\n",
    "Create a 2D uniform mesh grid of values to plug in as inputs to the decoder network.\n",
    "\n",
    "Plot the reconstruction images on a grid to see how changing the latent values changes what reconstruction we come out with.\n",
    "\n",
    "Use `SIDE_LENGTH = 25` for the grid dimensions and create latent values ranging from -5 to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIDE_LENGTH = 25\n",
    "NUM_IMAGES = SIDE_LENGTH**2\n",
    "\n",
    "# BEGIN SOLUTION\n",
    "# Create a mesh grid of latent values\n",
    "latent_x = torch.linspace(-5, 5, SIDE_LENGTH)\n",
    "latent_y = torch.linspace(-5, 5, SIDE_LENGTH)\n",
    "xx, yy = torch.meshgrid(latent_x, latent_y, indexing=\"ij\")\n",
    "\n",
    "# Create the plot grid\n",
    "fig, ax = plt.subplots(SIDE_LENGTH, SIDE_LENGTH, figsize=(SIDE_LENGTH, SIDE_LENGTH))\n",
    "ax = ax.flatten()\n",
    "\n",
    "# Generate and plot reconstructions for each latent point\n",
    "for idx, latent in enumerate(zip(xx.flatten(), yy.flatten())):\n",
    "    latent_tensor = torch.tensor(latent)\n",
    "    reconstruction = trained_autoencoder.decoder(latent_tensor)\n",
    "    ax[idx].imshow(reconstruction.detach().numpy().reshape(28, 28), cmap=\"gray\")\n",
    "    ax[idx].set_xticks([])\n",
    "    ax[idx].set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert SIDE_LENGTH == 25, \"SIDE_LENGTH should be 25\"\n",
    "assert NUM_IMAGES == 625, f\"NUM_IMAGES should be 625, got {NUM_IMAGES}\"\n",
    "assert latent_x.shape == (25,), \"latent_x should have 25 values\"\n",
    "assert latent_y.shape == (25,), \"latent_y should have 25 values\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert latent_x.min() == -5, \"latent_x should start at -5\"\n",
    "assert latent_x.max() == 5, \"latent_x should end at 5\"\n",
    "assert latent_y.min() == -5, \"latent_y should start at -5\"\n",
    "assert latent_y.max() == 5, \"latent_y should end at 5\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6: Latent Space Interpolation\n",
    "\n",
    "Write a function called `extrapolate_digits` that takes as input 2 digits and returns a spectrum of 12 images shifting from one digit to the other in latent space. Then, present **3 separate cells** that call the function with 3 unique pairs of digits of your choosing.\n",
    "\n",
    "**Hint:** Think about the steps necessary to pull this off:\n",
    "1. Get 2 inputs corresponding to digits.\n",
    "2. Get their latent values from your trained autoencoder.\n",
    "3. Find a way to create equal intervals in latent space and send those intermediate values through the decoder.\n",
    "4. Tile your outcomes together and present the final plot.\n",
    "\n",
    "We provide a helper function `get_test_digit` that retrieves an example image of a specified digit from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_digit(testloader, digit_val=0):\n",
    "    \"\"\"Retrieve an example image of a specified digit from the test set.\"\"\"\n",
    "    shuffled_loader = torch.utils.data.DataLoader(\n",
    "        testloader.dataset, batch_size=testloader.batch_size, shuffle=True\n",
    "    )\n",
    "\n",
    "    for data in shuffled_loader:\n",
    "        images, labels = data\n",
    "        for idx in range(len(labels)):\n",
    "            if labels[idx] == digit_val:\n",
    "                return images[idx]\n",
    "\n",
    "    return f\"Test set doesn't contain digit {digit_val}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrapolate_digits(digit1, digit2, dataloader, encoder, decoder, num_images=12):\n",
    "    # BEGIN SOLUTION\n",
    "    # Get example images for each digit\n",
    "    digit1_image = get_test_digit(dataloader, digit1)\n",
    "    digit2_image = get_test_digit(dataloader, digit2)\n",
    "\n",
    "    # Encode to latent space\n",
    "    digit1_latent = encoder(digit1_image.view(1, -1)).detach()\n",
    "    digit2_latent = encoder(digit2_image.view(1, -1)).detach()\n",
    "\n",
    "    # Create interpolations in latent space\n",
    "    interpolation_weights = torch.linspace(0, 1, num_images)\n",
    "    interpolations = torch.stack(\n",
    "        [\n",
    "            digit1_latent + (digit2_latent - digit1_latent) * weight\n",
    "            for weight in interpolation_weights\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Plot the interpolations\n",
    "    _fig, ax = plt.subplots(1, num_images, figsize=(num_images, 1))\n",
    "    ax = ax.flatten()\n",
    "\n",
    "    for idx, latent in enumerate(interpolations):\n",
    "        reconstruction = decoder(latent)\n",
    "        ax[idx].imshow(reconstruction.detach().numpy().reshape(28, 28), cmap=\"gray\")\n",
    "        ax[idx].set_xticks([])\n",
    "        ax[idx].set_yticks([])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "import inspect\n",
    "\n",
    "sig = inspect.signature(extrapolate_digits)\n",
    "params = list(sig.parameters.keys())\n",
    "assert \"digit1\" in params, \"extrapolate_digits should have digit1 parameter\"\n",
    "assert \"digit2\" in params, \"extrapolate_digits should have digit2 parameter\"\n",
    "assert \"encoder\" in params, \"extrapolate_digits should have encoder parameter\"\n",
    "assert \"decoder\" in params, \"extrapolate_digits should have decoder parameter\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "# Test that get_test_digit returns a tensor\n",
    "test_digit_img = get_test_digit(test_loader, 5)\n",
    "assert isinstance(test_digit_img, torch.Tensor), \"get_test_digit should return a tensor\"\n",
    "assert test_digit_img.shape == torch.Size([1, 28, 28]), \"Digit image should be shape [1, 28, 28]\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "extrapolate_digits(3, 6, test_loader, trained_autoencoder.encoder, trained_autoencoder.decoder)\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "extrapolate_digits(2, 5, test_loader, trained_autoencoder.encoder, trained_autoencoder.decoder)\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "extrapolate_digits(1, 7, test_loader, trained_autoencoder.encoder, trained_autoencoder.decoder)\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7: Motivation for Variational Autoencoders\n",
    "\n",
    "Based on what you understand about variational autoencoders (VAEs), why might one want to use a VAE over a standard AE? Answer in 1-2 sentences **MAX**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "VAEs learn a continuous, regularized latent space where sampling from the prior (e.g., standard normal) produces meaningful outputs, enabling generative modeling. Unlike standard AEs, VAEs provide a principled probabilistic framework that prevents \"holes\" in the latent space and allows for smooth interpolation and generation of new data.\n",
    "> END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Challenge**: Summarize a wide dataset with as few dimensions as possible... but now ensure that we can sample from the distribution of the latent space and have it mean something.\n",
    "\n",
    "This is the mission statement of **variational** autoencoders, the probabilistic extension of the autoencoder. If we assume that the true data is generated by some latent space, we want to maximize $p(x) = \\int p(x|z)p(z)dz$. Ideally, we want to learn a decoder $p_{\\theta}(x|z)$ that is able to make probabilistic, but accurate reconstructions given some sample from the latent space. If we assume the latent space has a prior $p(z)$, then a posterior distribution would take the form $p(z|x) = \\frac{p(x|z)p(z)}{\\int p(x|z)p(z) dx}$. This denominator being intractable is what motivates us to learn an approximate posterior $q_{\\phi}(z|x)$.\n",
    "\n",
    "In order to learn the approximate posterior however, we need a new objective. This is the evidence lower bound (ELBO). The derivation of the formula can be found [here](https://fangdahan.medium.com/derivation-of-elbo-in-vae-25ad7991fdf7).\n",
    "\n",
    "More details about the full theory decomposition of VAEs and all formula derivations can be found in lecture materials and this [wonderful Medium post](https://medium.com/@j.zh/mathematics-behind-variational-autoencoders-c69297301957).\n",
    "\n",
    "The most important takeaway is that the ELBO can be decomposed as\n",
    "\n",
    "$$\\textrm{ELBO} = E_{q(z|x)}(\\log p(x|z)) + \\textrm{KL}(q(z|x) || p(z))$$\n",
    "\n",
    "The decoder $p(x|z)$ outputs a predicted mean for the reconstruction and that loss boils down to an $\\textrm{MSE} = (x - \\hat{x})^2$. If we assume that the approximate posterior is ALSO a Gaussian distribution, then provided $\\mu$ and $\\sigma$ for the approximate posterior, we can write the KL divergence as:\n",
    "\n",
    "$$\\mathrm{KL}=-\\frac{1}{2} \\sum\\left(1+\\log \\sigma^2-\\mu^2-\\sigma^2\\right)$$\n",
    "\n",
    "The second term in the ELBO involves sampling $z \\sim q_\\phi(z \\mid x)$. But we cannot backpropagate through a sample unless we rewrite the sampling process.\n",
    "So instead of:\n",
    "\n",
    "$$\n",
    "z \\sim \\mathcal{N}\\left(\\mu_\\phi(x), \\sigma_\\phi(x)^2\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "We write:\n",
    "\n",
    "$$\n",
    "z=\\mu_\\phi(x)+\\sigma_\\phi(x) \\cdot \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0, I)\n",
    "$$\n",
    "\n",
    "Now the randomness is pushed to $\\epsilon$ (which is independent), and everything else is deterministic and differentiable. This is the reparameterization trick. You will need to implement such a method in the VAE class to ensure it backpropagates.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 8: Implementing a Variational Autoencoder\n",
    "\n",
    "We now move from autoencoders (AE) to variational autoencoders (VAE). Please fill in each method of the VAE class for training purposes.\n",
    "\n",
    "The VAE should have:\n",
    "- An encoder that outputs both `mu` and `logvar` (log variance)\n",
    "- A `reparameterize` method that implements the reparameterization trick\n",
    "- A decoder that reconstructs the input from the latent sample\n",
    "- A `forward` method that returns the reconstruction, mu, and logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # BEGIN SOLUTION\n",
    "        # Encoder network\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        # Output layers for mu and logvar\n",
    "        self.mu = nn.Linear(256, latent_dim)\n",
    "        self.logvar = nn.Linear(256, latent_dim)\n",
    "\n",
    "        # Decoder network\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 28 * 28),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        # END SOLUTION\n",
    "\n",
    "    def encode(self, x):\n",
    "        # BEGIN SOLUTION\n",
    "        hidden = self.encoder(x)\n",
    "        mu = self.mu(hidden)\n",
    "        logvar = self.logvar(hidden)\n",
    "        return mu, logvar\n",
    "        # END SOLUTION\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        # BEGIN SOLUTION\n",
    "        # Reparameterization trick: z = mu + std * epsilon\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "        # END SOLUTION\n",
    "\n",
    "    def decode(self, z):\n",
    "        # BEGIN SOLUTION\n",
    "        return self.decoder(z)\n",
    "        # END SOLUTION\n",
    "\n",
    "    def forward(self, x):\n",
    "        # BEGIN SOLUTION\n",
    "        mu, logvar = self.encode(x)\n",
    "        latent_sample = self.reparameterize(mu, logvar)\n",
    "        reconstruction = self.decode(latent_sample)\n",
    "        return reconstruction, mu, logvar\n",
    "        # END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "test_vae = VAE(latent_dim=2)\n",
    "test_input = torch.randn(10, 784)\n",
    "test_recon, test_mu, test_logvar = test_vae(test_input)\n",
    "assert test_recon.shape == (\n",
    "    10,\n",
    "    784,\n",
    "), f\"Expected reconstruction shape (10, 784), got {test_recon.shape}\"\n",
    "assert test_mu.shape == (10, 2), f\"Expected mu shape (10, 2), got {test_mu.shape}\"\n",
    "assert test_logvar.shape == (10, 2), f\"Expected logvar shape (10, 2), got {test_logvar.shape}\"\n",
    "assert hasattr(test_vae, \"encode\"), \"VAE should have encode method\"\n",
    "assert hasattr(test_vae, \"decode\"), \"VAE should have decode method\"\n",
    "assert hasattr(test_vae, \"reparameterize\"), \"VAE should have reparameterize method\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "# Test reparameterize produces different samples\n",
    "sample1 = test_vae.reparameterize(test_mu, test_logvar)\n",
    "sample2 = test_vae.reparameterize(test_mu, test_logvar)\n",
    "assert not torch.allclose(sample1, sample2), \"Reparameterize should produce stochastic samples\"\n",
    "# Test decode output range\n",
    "assert torch.all(test_recon >= 0) and torch.all(\n",
    "    test_recon <= 1\n",
    "), \"Reconstruction should be between 0 and 1\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 9: Training a Variational Autoencoder\n",
    "\n",
    "Please finish implementing the `train_VAE` function to train your variational autoencoder. The function should:\n",
    "1. Use the VAE loss (reconstruction loss + KL divergence)\n",
    "2. Use the Adam optimizer with learning rate 0.001\n",
    "3. Implement early stopping based on validation loss\n",
    "4. Print the epoch, validation loss, and patience counter each epoch\n",
    "\n",
    "Please leave the print statement that states what the current epoch, validation loss, and patience counter is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vae(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    model=None,\n",
    "    num_epochs=100,\n",
    "    early_stopping_patience=5,\n",
    "):\n",
    "    if model is None:\n",
    "        model = VAE(latent_dim=2)\n",
    "\n",
    "    # BEGIN SOLUTION\n",
    "    def vae_loss(reconstruction, x, mu, logvar, kl_weight=1.0):\n",
    "        \"\"\"Compute VAE loss: reconstruction loss + KL divergence.\"\"\"\n",
    "        mse_loss = F.mse_loss(reconstruction, x, reduction=\"sum\")\n",
    "        kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        return mse_loss + kl_loss * kl_weight\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    patience_counter = 0\n",
    "    lowest_val_loss = float(\"inf\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training loop\n",
    "        model.train()\n",
    "        for data in train_loader:\n",
    "            images, _ = data\n",
    "            images = images.view(images.shape[0], -1)\n",
    "\n",
    "            outputs, latents_mu, latents_logvar = model(images)\n",
    "            loss = vae_loss(outputs, images, latents_mu, latents_logvar)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for data in val_loader:\n",
    "                images, _ = data\n",
    "                images = images.view(images.shape[0], -1)\n",
    "\n",
    "                outputs, latents_mu, latents_logvar = model(images)\n",
    "                val_loss += vae_loss(outputs, images, latents_mu, latents_logvar).item()\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        # Early stopping check\n",
    "        if val_loss < lowest_val_loss:\n",
    "            lowest_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                break\n",
    "\n",
    "        print(\n",
    "            f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
    "            f\"Validation Loss: {val_loss:.4f}, Patience Count: {patience_counter}\"\n",
    "        )\n",
    "    # END SOLUTION\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "import inspect\n",
    "\n",
    "sig = inspect.signature(train_vae)\n",
    "params = list(sig.parameters.keys())\n",
    "assert \"train_loader\" in params, \"train_vae should have train_loader parameter\"\n",
    "assert \"val_loader\" in params, \"train_vae should have val_loader parameter\"\n",
    "assert \"num_epochs\" in params, \"train_vae should have num_epochs parameter\"\n",
    "assert (\n",
    "    \"early_stopping_patience\" in params\n",
    "), \"train_vae should have early_stopping_patience parameter\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "# Quick test with 1 epoch to verify function works\n",
    "quick_vae = VAE(latent_dim=2)\n",
    "quick_vae_result = train_vae(train_loader, val_loader, model=quick_vae, num_epochs=1)\n",
    "assert isinstance(quick_vae_result, VAE), \"train_vae should return a VAE model\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_model = VAE(2)\n",
    "\n",
    "trained_vae = train_vae(train_loader, val_loader, vae_model, num_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 10: Sampling from the Latent Space\n",
    "\n",
    "Now that we have trained a variational autoencoder, let's take some samples from the prior space and pass them through the decoder to see what reconstructions we can get.\n",
    "\n",
    "Create `latent_samples` by sampling 250 points from a standard normal distribution (the prior), then decode them to get reconstructions. Run the prewritten code afterwards to plot the reconstructions on a scatterplot.\n",
    "\n",
    "What happens at (0, 0)? Answer in the markdown cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_IMAGES = 250\n",
    "\n",
    "# BEGIN SOLUTION\n",
    "# Sample from the prior (standard normal)\n",
    "latent_samples = torch.randn(NUM_IMAGES, 2)\n",
    "# Decode the samples\n",
    "reconstruction = trained_vae.decode(latent_samples)\n",
    "reconstruction = reconstruction.view(NUM_IMAGES, 28, 28)\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert latent_samples.shape == (\n",
    "    250,\n",
    "    2,\n",
    "), f\"Expected latent_samples shape (250, 2), got {latent_samples.shape}\"\n",
    "assert reconstruction.shape == (\n",
    "    250,\n",
    "    28,\n",
    "    28,\n",
    "), f\"Expected reconstruction shape (250, 28, 28), got {reconstruction.shape}\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "# Check that latent samples are roughly standard normal\n",
    "assert abs(latent_samples.mean()) < 0.3, \"Latent samples should have mean near 0\"\n",
    "assert abs(latent_samples.std() - 1.0) < 0.3, \"Latent samples should have std near 1\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.offsetbox import AnnotationBbox, OffsetImage\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# First plot your latent points\n",
    "ax.scatter(latent_samples[:, 0], latent_samples[:, 1], alpha=0.2)\n",
    "\n",
    "# Now overlay each image\n",
    "for latent in latent_samples:\n",
    "    reconstruction = trained_vae.decode(latent)\n",
    "    img = reconstruction.detach().numpy().reshape(28, 28)\n",
    "    # Wrap it in an OffsetImage\n",
    "    im = OffsetImage(img, zoom=0.5, cmap=\"gray\", origin=\"upper\")\n",
    "    # Create an AnnotationBbox, disable the frame so only image shows up\n",
    "    ab = AnnotationBbox(im, latent, frameon=False)\n",
    "    ax.add_artist(ab)\n",
    "\n",
    "# Set limits to cover all points, plus a little padding\n",
    "x_min, x_max = latent_samples[:, 0].min(), latent_samples[:, 0].max()\n",
    "y_min, y_max = latent_samples[:, 1].min(), latent_samples[:, 1].max()\n",
    "pad_x = (x_max - x_min) * 0.05\n",
    "pad_y = (y_max - y_min) * 0.05\n",
    "ax.set_xlim(x_min - pad_x, x_max + pad_x)\n",
    "ax.set_ylim(y_min - pad_y, y_max + pad_y)\n",
    "\n",
    "ax.set_xlabel(\"Latent Dimension 1\")\n",
    "ax.set_ylabel(\"Latent Dimension 2\")\n",
    "ax.set_title(\"Reconstruction Images in Latent Space\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What happens at (0, 0)?**\n",
    "\n",
    "> BEGIN SOLUTION\n",
    "\n",
    "At (0, 0), which is the center of the prior distribution, the VAE typically produces an \"average\" or blended digit that represents the most common features across all training digits. This is because the KL divergence term encourages the encoder to map inputs near the origin, and the decoder learns to produce reasonable outputs for this high-density region. The reconstruction at (0, 0) often appears as a smooth blend of multiple digits.\n",
    "> END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 11: Evaluating Latent Space Effectiveness\n",
    "\n",
    "One problem with working with VAEs is that ideally, we would get meaningful reconstructions if we just sampled from the prior and took those samples through the decoder. **This is because the entire point of the exercise is learning a continuous representation of digits that can be summarized in 2 dimensions.** If the aggregate posterior $q(z)$ does not match the prior $p(z)$ then sampling from the prior may land us in \"dead zones\" - parts of latent space that the decoder never learned to handle.\n",
    "\n",
    "We have started some code to try to compare the distribution of the approximate posterior and the prior. Please finish the code by:\n",
    "1. Creating `prior` samples from a standard normal distribution\n",
    "2. Creating `approx_posterior` samples using the reparameterization trick with the encoded mu and logvar\n",
    "3. Plotting prior samples in red and approximate posterior samples in blue\n",
    "\n",
    "Do the distributions line up? What differences (if any) do you observe? Answer in markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 500\n",
    "\n",
    "# Get test samples\n",
    "comparison_loader = DataLoader(test_dataset, batch_size=NUM_SAMPLES, shuffle=True)\n",
    "test_samples, _ = next(iter(comparison_loader))\n",
    "test_samples = test_samples.view(NUM_SAMPLES, -1)\n",
    "\n",
    "# Encode the test samples to get mu and logvar\n",
    "with torch.no_grad():\n",
    "    reconstruction, latent_mu, latent_logvar = trained_vae(test_samples)\n",
    "\n",
    "# BEGIN SOLUTION\n",
    "# Sample from the prior\n",
    "prior = torch.randn(NUM_SAMPLES, 2)\n",
    "\n",
    "# Sample from the approximate posterior using reparameterization\n",
    "approx_posterior = latent_mu + torch.exp(0.5 * latent_logvar) * torch.randn_like(latent_mu)\n",
    "posterior_samples = approx_posterior.detach().numpy()\n",
    "\n",
    "# Plot both distributions\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(prior[:, 0], prior[:, 1], c=\"red\", alpha=0.5, label=\"Prior\")\n",
    "plt.scatter(\n",
    "    posterior_samples[:, 0],\n",
    "    posterior_samples[:, 1],\n",
    "    c=\"blue\",\n",
    "    alpha=0.5,\n",
    "    label=\"Approx Posterior\",\n",
    ")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Latent Dimension 1\")\n",
    "plt.ylabel(\"Latent Dimension 2\")\n",
    "plt.title(\"Prior vs Approximate Posterior Distributions\")\n",
    "plt.show()\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert prior.shape == (500, 2), f\"Expected prior shape (500, 2), got {prior.shape}\"\n",
    "assert approx_posterior.shape == (\n",
    "    500,\n",
    "    2,\n",
    "), f\"Expected approx_posterior shape (500, 2), got {approx_posterior.shape}\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "# Check prior is standard normal\n",
    "assert abs(prior.mean()) < 0.2, \"Prior should have mean near 0\"\n",
    "assert abs(prior.std() - 1.0) < 0.2, \"Prior should have std near 1\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do the distributions line up? What differences (if any) do you observe?**\n",
    "\n",
    "> BEGIN SOLUTION\n",
    "\n",
    "The distributions may not perfectly align. Common observations include:\n",
    "1. The approximate posterior may have smaller variance than the prior, indicating \"posterior collapse\" or that the encoder is not fully utilizing the latent space.\n",
    "2. The approximate posterior may form clusters corresponding to different digit classes, while the prior is uniformly spread.\n",
    "3. With limited training (5 epochs), the KL divergence may not have fully regularized the posterior to match the prior.\n",
    "\n",
    "If the distributions differ significantly, sampling from the prior may produce lower-quality reconstructions because the decoder was trained on a different distribution of latent codes.\n",
    "> END SOLUTION\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
