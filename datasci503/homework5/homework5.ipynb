{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# DATASCI 503, Homework 5: Resampling Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Resampling methods are techniques that repeatedly draw samples from a training set and refit a model to each sample to obtain additional information about the fitted model. In this assignment, we explore two key resampling methods: **bootstrap** (for estimating the variability of an estimator) and **cross-validation** (for estimating test error and selecting models). These methods connect directly to the bias-variance tradeoffâ€”cross-validation helps us choose models that balance underfitting and overfitting, while bootstrap helps us quantify uncertainty in our estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Problem 1: Bootstrap Sampling Probability\n",
    "\n",
    "We will now derive the probability that a given observation is part of a bootstrap sample. Suppose that we obtain a bootstrap sample from a set of $n$ observations.\n",
    "\n",
    "**(a)** What is the probability that the first bootstrap observation is *not* the $j$th observation from the original sample? Justify your answer.\n",
    "\n",
    "> BEGIN SOLUTION\n",
    "\n",
    "*Solutions in this assignment are adapted from work by John Elmer Loretizo.*\n",
    "\n",
    "We note that observing the $j$th observation from $n$ samples is given as $P(j\\text{th observation})=1/n$. Therefore, we take the complement and $P(\\text{not observing }j\\text{th observation})=1-1/n$.\n",
    "\n",
    "> END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "**(b)** What is the probability that the second bootstrap observation is *not* the $j$th observation from the original sample?\n",
    "\n",
    "> BEGIN SOLUTION\n",
    "\n",
    "Since bootstrap sampling is performed with replacement, we still note the same probability for every $j$th observation as $P(j\\text{th observation})=1/n$ and the $P(\\text{not observing the second }j\\text{th observation})=1-1/n$.\n",
    "> END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "**(c)** Argue that the probability that the $j$th observation is *not* in the bootstrap sample is $(1 - \\frac{1}{n})^n$.\n",
    "\n",
    "> BEGIN SOLUTION\n",
    "\n",
    "Both (a) and (b) suggest the property of independence that is present in a bootstrap method. This stems from the fact that we draw with replacement and therefore every observation will have a $1/n$ chance of getting picked at every draw. Due to independence, we can simply see that for every draw until the $n$th draw, the probability of not having the $j$th observation is simply $(1 - \\frac{1}{n})$ and we multiply each of these probabilities giving us $(1 - \\frac{1}{n})^n$.\n",
    "> END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "**(d)** When $n = 5$, what is the probability that the $j$th observation is in the bootstrap sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "n = 5\n",
    "prob_in_sample_n5 = 1 - (1 - (1 / n)) ** n\n",
    "prob_in_sample_n5\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert abs(prob_in_sample_n5 - 0.6723) < 0.001, f\"Expected ~0.6723, got {prob_in_sample_n5}\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert 0.67 < prob_in_sample_n5 < 0.68, \"Probability should be between 0.67 and 0.68\"\n",
    "assert prob_in_sample_n5 == 1 - (1 - 1 / 5) ** 5, \"Formula not applied correctly\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "We use the probability $P(\\text{observing the }j\\text{th observation in the bootstrap sample})=1-((1 - \\frac{1}{n})^n)$, which gives us a 67.232% chance that the $j$th observation is in the bootstrap sample.\n",
    "> END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "**(e)** When $n = 100$, what is the probability that the $j$th observation is in the bootstrap sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "n = 100\n",
    "prob_in_sample_n100 = 1 - (1 - (1 / n)) ** n\n",
    "prob_in_sample_n100\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert abs(prob_in_sample_n100 - 0.634) < 0.01, f\"Expected ~0.634, got {prob_in_sample_n100}\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert 0.63 < prob_in_sample_n100 < 0.64, \"Probability should be between 0.63 and 0.64\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "Following the same formula above, we have a 63.397% chance that the $j$th observation is in the bootstrap sample.\n",
    "> END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "**(f)** When $n = 10{,}000$, what is the probability that the $j$th observation is in the bootstrap sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "n = 10000\n",
    "prob_in_sample_n10000 = 1 - (1 - (1 / n)) ** n\n",
    "prob_in_sample_n10000\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert abs(prob_in_sample_n10000 - 0.632) < 0.01, f\"Expected ~0.632, got {prob_in_sample_n10000}\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert 0.63 < prob_in_sample_n10000 < 0.64, \"Probability should converge to 1 - 1/e\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "Following the same formula above, we have a 63.214% chance that the $j$th observation is in the bootstrap sample. Note that as $n \\to \\infty$, this probability converges to $1 - 1/e \\approx 0.632$.\n",
    "> END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Problem 2: Estimating Standard Deviation of Predictions\n",
    "\n",
    "Suppose that we use some statistical learning method to make a prediction for the response $Y$ for a particular value of the predictor $X$. Carefully describe how we might estimate the standard deviation of our prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "We can perform bootstrap by repeatedly sampling the dataset and fitting the model from these new datasets and then predicting the response $Y$ at the particular value of predictor $X$. After repeating this over the number of bootstrap samples, we will have a distribution of predicted values of $Y$ given a particular value of $X$. We can then use this distribution to compute the standard deviation of our prediction.\n",
    "> END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Problem 3: Cross-Validation on Simulated Data\n",
    "\n",
    "We will now perform cross-validation on a simulated data set.\n",
    "\n",
    "**(a)** Generate a simulated data set as follows:\n",
    "\n",
    "```python\n",
    "rng = np.random.default_rng(1)\n",
    "x = rng.normal(size=100)\n",
    "y = x - 2 * x**2 + rng.normal(size=100)\n",
    "```\n",
    "    \n",
    "In this data set, what is $n$ and what is $p$? Write out the model used to generate the data in equation form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "rng = np.random.default_rng(1)\n",
    "x = rng.normal(size=100)\n",
    "y = x - 2 * x**2 + rng.normal(size=100)\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "We have $n=100$ and $p=1$ with the equation given as $y = x - 2x^2 + \\epsilon$.\n",
    "> END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "**(b)** Create a scatterplot of $X$ against $Y$. Comment on what you find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "sns.scatterplot(x=x, y=y)\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "We note the nonlinear relationship between $X$ and $Y$ with the curve plot suggesting a quadratic relationship. This is consistent given that the equation for the data generating process has a quadratic term included.\n",
    "> END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "**(c)** Construct 5 folds using `sklearn.model_selection.KFold`, and specify `random_state=3`. Using these folds, compute the cross-validation errors that result from fitting the following four models using least squares. Use the same five folds for all four models.\n",
    "\n",
    "i. $Y = \\beta_0 + \\beta_1 X + \\epsilon$\n",
    "\n",
    "ii. $Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\epsilon$\n",
    "\n",
    "iii. $Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\beta_3 X^3 + \\epsilon$\n",
    "\n",
    "iv. $Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\beta_3 X^3 + \\beta_4 X^4 + \\epsilon$\n",
    "\n",
    "For each fold and each model, report the mean-squared error. Which of the models had the smallest average error? Is this what you expected? Explain your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "# Prepare polynomial features\n",
    "X = x.reshape(-1, 1)\n",
    "X_poly = np.hstack([X**i for i in range(1, 5)])\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "# Perform 5-fold cross-validation for each model\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=3)\n",
    "errors = np.zeros((4, 5))\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    for i in range(4):\n",
    "        X_train_poly = X_poly[train_index, : i + 1]\n",
    "        X_test_poly = X_poly[test_index, : i + 1]\n",
    "\n",
    "        model = LinearRegression().fit(X_train_poly, y_train)\n",
    "        y_pred = model.predict(X_test_poly)\n",
    "        errors[i, fold] = mean_squared_error(y_test, y_pred)\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "# Create a DataFrame to display the results\n",
    "errors_df = pd.DataFrame(errors)\n",
    "errors_df.columns = [\"Fold \" + str(col + 1) for col in errors_df.columns]\n",
    "errors_df[\"Mean\"] = errors_df.mean(axis=1)\n",
    "errors_df.index = errors_df.index + 1\n",
    "errors_df\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert errors_df.shape == (4, 6), f\"Expected shape (4, 6), got {errors_df.shape}\"\n",
    "assert errors_df[\"Mean\"].idxmin() == 2, \"Model 2 should have the lowest mean error\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert errors_df.loc[1, \"Mean\"] > 5, \"Linear model should have high error for quadratic data\"\n",
    "assert errors_df.loc[2, \"Mean\"] < 2, \"Quadratic model should have low error\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "Model 2 has the smallest average error across all models. This result is expected since the data generating process is similar to the one identified in model 2. Clearly, model 1 is underfitting since it suggests a linear relationship for a nonlinear relationship as we have seen above. Subsequent models (3 and 4) offered more flexibility but may have suffered from overfitting and thus a poorer performance for out-of-sample prediction.\n",
    "> END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "### Problem 4: LOOCV and Random Seeds\n",
    "\n",
    "Consider estimating log odds using logistic regression with ridge penalties, setting the regularization strength via LOOCV. True or false: the result will depend on a random seed that we use as part of the LOOCV process. Explain your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "False. One can easily see this by the fact that the LOOCV uses $n-1$ observations as part of its training set and the $n$th observation as its validation set, repeating this process over all the observations. Such a process is deterministic and there is no randomness in the splitting due to the fact that every iteration is just removing the $i$th observation (a single observation) and setting it as the validation set. Therefore, there is no dependence on the random seed.\n",
    "> END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "### Problem 5: Boston Housing Data Analysis\n",
    "\n",
    "We will now consider the Boston housing data set.\n",
    "\n",
    "**(a)** Based on this data set, provide an estimate for the population mean of `medv`. Call this estimate $\\hat{\\mu}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "boston_df = pd.read_csv(\"./data/boston.csv\")\n",
    "mu_hat = boston_df[\"medv\"].mean()\n",
    "mu_hat\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert abs(mu_hat - 22.533) < 0.01, f\"Expected ~22.533, got {mu_hat}\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert 22 < mu_hat < 23, \"Mean should be around 22.5\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "We have the mean of `medv` at $\\hat{\\mu} = 22.5328$.\n",
    "> END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "**(b)** Provide an estimate of the standard error of $\\hat{\\mu}$. Interpret this result.\n",
    "\n",
    "**Hint:** We can compute the standard error of the sample mean by dividing the sample standard deviation by the square root of the number of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "se_mu_hat = boston_df[\"medv\"].std() / np.sqrt(boston_df.shape[0])\n",
    "se_mu_hat\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert abs(se_mu_hat - 0.409) < 0.01, f\"Expected ~0.409, got {se_mu_hat}\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert 0.4 < se_mu_hat < 0.42, \"Standard error should be around 0.41\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "The standard error of `medv` is approximately 0.4089.\n",
    "> END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "**(c)** Now estimate the standard error of $\\hat{\\mu}$ using the bootstrap. How does this compare to your answer from (b)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "def get_mean(data):\n",
    "    return data.mean()\n",
    "\n",
    "\n",
    "def boot_se(func, df, colname, n=None, num_bootstrap=1000, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    first_moment, second_moment = 0, 0\n",
    "    n = n or df.shape[0]\n",
    "    for _ in range(num_bootstrap):\n",
    "        bootstrap_sample = rng.choice(df[colname], size=n, replace=True)\n",
    "        value = func(bootstrap_sample)\n",
    "        first_moment += value\n",
    "        second_moment += value**2\n",
    "    return np.sqrt(second_moment / num_bootstrap - (first_moment / num_bootstrap) ** 2)\n",
    "\n",
    "\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "bootstrap_sem = boot_se(get_mean, boston_df, \"medv\", num_bootstrap=10000, seed=2024)\n",
    "bootstrap_sem\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert abs(bootstrap_sem - 0.408) < 0.02, f\"Expected ~0.408, got {bootstrap_sem}\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert 0.38 < bootstrap_sem < 0.43, \"Bootstrap SE should be close to analytic SE\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "Estimating the standard error of `medv` using bootstrap gives us approximately 0.408, which is very close to the answer from (b). This suggests that the bootstrap method gives us a reliable estimate of the standard error for the given dataset.\n",
    "> END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "**(d)** Based on your bootstrap estimate from (c), provide a 95% confidence interval for the mean of `medv`. Compare it to the results obtained by using `boston_df['medv'].std()` and the two standard error rule.\n",
    "\n",
    "**Hint:** You can approximate a 95% confidence interval using the formula $[\\hat{\\mu} - 2\\text{SE}(\\hat{\\mu}), \\hat{\\mu} + 2\\text{SE}(\\hat{\\mu})]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "confidence_interval_bootstrap = (mu_hat - 2 * bootstrap_sem, mu_hat + 2 * bootstrap_sem)\n",
    "confidence_interval_bootstrap\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "confidence_interval_standard_error = (mu_hat - 2 * se_mu_hat, mu_hat + 2 * se_mu_hat)\n",
    "confidence_interval_standard_error\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "ci_low, ci_high = confidence_interval_bootstrap\n",
    "assert ci_low < mu_hat < ci_high, \"Mean should be within CI\"\n",
    "ci_se_low, ci_se_high = confidence_interval_standard_error\n",
    "assert abs(ci_low - ci_se_low) < 0.1, \"Bootstrap and standard CI should be similar\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert ci_high - ci_low < 2, \"CI width should be less than 2\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "The confidence intervals for both methods are very similar, suggesting robustness of the estimator and that the data distribution is very similar to what is assumed when we compute using the formula in (b).\n",
    "> END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "**(e)** Based on this data set, provide an estimate, $\\hat{m}$, for the median value of `medv` in the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "median_hat = boston_df[\"medv\"].median()\n",
    "median_hat\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert abs(median_hat - 21.2) < 0.01, f\"Expected 21.2, got {median_hat}\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert 21 < median_hat < 22, \"Median should be around 21.2\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "The median of `medv` is 21.2.\n",
    "> END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "**(f)** We now would like to estimate the standard error of $\\hat{m}$. Unfortunately, there is no simple formula for computing the standard error of the median. Instead, estimate the standard error of the median using the bootstrap. Comment on your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "def get_median(data):\n",
    "    return np.median(data)\n",
    "\n",
    "\n",
    "bootstrap_se_median = boot_se(get_median, boston_df, \"medv\", num_bootstrap=10000, seed=2024)\n",
    "bootstrap_se_median\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert abs(bootstrap_se_median - 0.379) < 0.05, f\"Expected ~0.379, got {bootstrap_se_median}\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert 0.3 < bootstrap_se_median < 0.5, \"Bootstrap SE of median should be reasonable\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "The standard error of $\\hat{m}$ is approximately 0.379, which relative to the median of 21.2, is small. This suggests a high degree of precision when estimating the median, and repeated sampling from the same population is likely to result in very similar estimates of the median.\n",
    "> END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "**(g)** Based on this data set, provide an estimate for the tenth percentile of `medv` in Boston census tracts. Call this quantity $\\hat{p}_{0.1}$.\n",
    "\n",
    "**Hint:** You can use `np.percentile()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "percentile_10_hat = np.percentile(boston_df[\"medv\"], q=10)\n",
    "percentile_10_hat\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert abs(percentile_10_hat - 12.75) < 0.1, f\"Expected 12.75, got {percentile_10_hat}\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert 12 < percentile_10_hat < 14, \"10th percentile should be around 12.75\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "The tenth percentile is $\\hat{p}_{0.1} = 12.75$.\n",
    "> END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "**(h)** Use the bootstrap to estimate the standard error of $\\hat{p}_{0.1}$. Comment on your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "def get_tenth_percentile(data):\n",
    "    return np.percentile(data, q=10)\n",
    "\n",
    "\n",
    "bootstrap_se_percentile = boot_se(\n",
    "    get_tenth_percentile, boston_df, \"medv\", num_bootstrap=10000, seed=2024\n",
    ")\n",
    "bootstrap_se_percentile\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert abs(bootstrap_se_percentile - 0.50) < 0.1, f\"Expected ~0.50, got {bootstrap_se_percentile}\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert 0.4 < bootstrap_se_percentile < 0.6, \"Bootstrap SE of 10th percentile should be reasonable\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "The standard error for $\\hat{p}_{0.1}$ is approximately 0.50, suggesting strong precision in the estimation of the tenth percentile from the given dataset.\n",
    "> END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "### Problem 6: LOOCV for Logistic Regression\n",
    "\n",
    "In this problem, you will practice computing the LOOCV error for a logistic regression model on the Weekly data set.\n",
    "\n",
    "**(a)** Fit a logistic regression model that predicts `Direction` using `Lag1` and `Lag2`. Report and comment on the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "weekly_df = pd.read_csv(\"./data/weekly.csv\")\n",
    "weekly_df[\"Coded_Direction\"] = pd.get_dummies(weekly_df[\"Direction\"], dtype=int, drop_first=True)\n",
    "\n",
    "X = weekly_df[[\"Lag1\", \"Lag2\"]]\n",
    "y = weekly_df[\"Coded_Direction\"]\n",
    "model = LogisticRegression().fit(X, y)\n",
    "\n",
    "misclassification_rate_full = 1 - accuracy_score(y, model.predict(X))\n",
    "misclassification_rate_full\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "expected_rate = 0.445\n",
    "actual_rate = misclassification_rate_full\n",
    "assert abs(actual_rate - expected_rate) < 0.01, f\"Expected ~0.445, got {actual_rate}\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert 0.4 < misclassification_rate_full < 0.5, \"Misclassification rate should be around 44%\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "The misclassification rate is at 44.54%. This suggests a relatively poor performance since almost half of the observations are incorrectly classified.\n",
    "\n",
    "> END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {},
   "source": [
    "**(b)** Fit a logistic regression model that predicts `Direction` using `Lag1` and `Lag2` using all but the first observation. Report and comment on the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "X_without_first = X[1:]\n",
    "y_without_first = y[1:]\n",
    "\n",
    "model_without_first = LogisticRegression().fit(X_without_first, y_without_first)\n",
    "misclassification_rate_without_first = 1 - accuracy_score(y, model_without_first.predict(X))\n",
    "misclassification_rate_without_first\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "expected_rate = 0.444\n",
    "actual_rate = misclassification_rate_without_first\n",
    "assert abs(actual_rate - expected_rate) < 0.01, f\"Expected ~0.444, got {actual_rate}\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "diff = abs(misclassification_rate_without_first - misclassification_rate_full)\n",
    "assert diff < 0.01, \"Rates should be similar\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "Similarly, the misclassification rate is at 44.36%, suggesting a very small improvement (most likely by chance) by removing the first observation.\n",
    "> END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76",
   "metadata": {},
   "source": [
    "**(c)** Use the model from (b) to predict the direction of the first observation. Was this observation correctly classified?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "prediction = model_without_first.predict(X.iloc[0, :].values.reshape(1, -1))[-1]\n",
    "first_observation_correct = prediction == y.iloc[0]\n",
    "first_observation_correct\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert not first_observation_correct, \"First observation should be incorrectly classified\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert not first_observation_correct, \"First observation should be misclassified\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "The observation was incorrectly classified.\n",
    "> END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80",
   "metadata": {},
   "source": [
    "**(d)** Write a for loop from `i = 0` to `i = n-1`, where `n` is the number of observations in the data set, that performs each of the following steps:\n",
    "\n",
    "i. Fit a logistic regression model using all but the `i`th observation to predict `Direction` using `Lag1` and `Lag2`.\n",
    "\n",
    "ii. Use this model to predict the direction for the `i`th observation.\n",
    "\n",
    "iii. Determine whether or not an error was made in predicting the direction for the `i`th observation. If an error was made, then indicate this as a 1, and otherwise indicate it as a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "loocv_errors = []\n",
    "for i in range(X.shape[0]):\n",
    "    X_train = X.drop(i)\n",
    "    y_train = y.drop(i)\n",
    "\n",
    "    model_loocv = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "    pred = model_loocv.predict(X.iloc[i, :].values.reshape(1, -1))[-1]\n",
    "    prediction_error = 1 if pred != y.iloc[i] else 0\n",
    "    loocv_errors.append(prediction_error)\n",
    "\n",
    "loocv_errors[:5]\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert len(loocv_errors) == len(y), f\"Expected {len(y)} errors, got {len(loocv_errors)}\"\n",
    "assert all(e in [0, 1] for e in loocv_errors), \"Errors should be 0 or 1\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert sum(loocv_errors) > 400, \"There should be many misclassifications\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83",
   "metadata": {},
   "source": [
    "**(e)** Take the average of the `n` numbers obtained in part (d)(iii) of this problem in order to obtain the LOOCV estimate for the test error. Comment on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "loocv_error_rate = sum(loocv_errors) / len(loocv_errors)\n",
    "loocv_error_rate\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert abs(loocv_error_rate - 0.45) < 0.01, f\"Expected ~0.45, got {loocv_error_rate}\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert 0.44 < loocv_error_rate < 0.46, \"LOOCV error rate should be around 45%\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "We get the test error rate at approximately 45%, suggesting that both `Lag1` and `Lag2` are not effective predictors for the direction of the current day's returns.\n",
    "> END SOLUTION\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
