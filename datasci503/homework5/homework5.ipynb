{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASCI 503, Homework 5: Resampling Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resampling methods are techniques that repeatedly draw samples from a training set and refit a model to each sample to obtain additional information about the fitted model. In this assignment, we explore two key resampling methods: **bootstrap** (for estimating the variability of an estimator) and **cross-validation** (for estimating test error and selecting models). These methods connect directly to the bias-variance tradeoff—cross-validation helps us choose models that balance underfitting and overfitting, while bootstrap helps us quantify uncertainty in our estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 1 (ISLP Ch 5, Exercise 2):** Bootstrap Sampling Probability\n",
    "\n",
    "We will now derive the probability that a given observation is part of a bootstrap sample. Suppose that we obtain a bootstrap sample from a set of $n$ observations.\n",
    "\n",
    "**(a)** What is the probability that the first bootstrap observation is not the $j$-th observation from the original sample? Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "*Solutions in this assignment are adapted from work by John Elmer Loretizo.*\n",
    "\n",
    "We note that observing the $j$-th observation from $n$ samples is given as $P(j\\text{th observation})=1/n$. Therefore, we take the complement and $P(\\text{not observing }j\\text{th observation})=1-1/n$.\n",
    "\n",
    "> END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** What is the probability that the second bootstrap observation is not the $j$-th observation from the original sample?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "Since bootstrap sampling is performed with replacement, we still note the same probability for every $j$-th observation as $P(j\\text{th observation})=1/n$ and the $P(\\text{not observing the second }j\\text{th observation})=1-1/n$.\n",
    "\n",
    "> END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** Argue that the probability that the $j$-th observation is not in the bootstrap sample is $(1 - \\frac{1}{n})^n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "Both (a) and (b) suggest the property of independence that is present in a bootstrap method. This stems from the fact that we draw with replacement and therefore every observation will have a $1/n$ chance of getting picked at every draw. Due to independence, we can simply see that for every draw until the $n$-th draw, the probability of not having the $j$-th observation is simply $(1 - \\frac{1}{n})$ and we multiply each of these probabilities giving us $(1 - \\frac{1}{n})^n$.\n",
    "\n",
    "> END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d)** When $n = 5$, what is the probability that the $j$-th observation is in the bootstrap sample? Store your answer in a variable called `prob_in_sample_n5`. Then explain your calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "# Using the probability P(observing the jth observation) = 1 - ((1 - 1/n)^n)\n",
    "n = 5\n",
    "prob_in_sample_n5 = 1 - (1 - (1 / n)) ** n\n",
    "print(f\"Probability: {prob_in_sample_n5:.4f} (about 67.23%)\")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "Using the result from (c), the probability that the $j$-th observation is in the bootstrap sample is $1 - (1 - 1/n)^n = 1 - (4/5)^5 \\approx 0.6723$.\n",
    "\n",
    "> END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert isinstance(prob_in_sample_n5, float), \"Result should be a float\"\n",
    "assert 0 < prob_in_sample_n5 < 1, \"Probability must be between 0 and 1\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert abs(prob_in_sample_n5 - 0.6723) < 0.001, f\"Expected ~0.6723, got {prob_in_sample_n5}\"\n",
    "assert abs(prob_in_sample_n5 - (1 - (1 - 1 / 5) ** 5)) < 1e-10, \"Formula not applied correctly\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e)** When $n = 100$, what is the probability that the $j$-th observation is in the bootstrap sample? Store your answer in a variable called `prob_in_sample_n100`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "# Following the same formula, we get about 63.4%\n",
    "n = 100\n",
    "prob_in_sample_n100 = 1 - (1 - (1 / n)) ** n\n",
    "print(f\"Probability: {prob_in_sample_n100:.4f}\")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert isinstance(prob_in_sample_n100, float), \"Result should be a float\"\n",
    "assert 0 < prob_in_sample_n100 < 1, \"Probability must be between 0 and 1\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert abs(prob_in_sample_n100 - 0.634) < 0.01, f\"Expected ~0.634, got {prob_in_sample_n100}\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(f)** When $n = 10{,}000$, what is the probability that the $j$-th observation is in the bootstrap sample? Store your answer in a variable called `prob_in_sample_n10000`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "# Following the same formula, we get about 63.2%\n",
    "# Note: as n -> infinity, this probability converges to 1 - 1/e ≈ 0.632\n",
    "n = 10000\n",
    "prob_in_sample_n10000 = 1 - (1 - (1 / n)) ** n\n",
    "print(f\"Probability: {prob_in_sample_n10000:.4f}\")\n",
    "print(f\"Limit as n->inf: {1 - 1 / np.e:.4f}\")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert isinstance(prob_in_sample_n10000, float), \"Result should be a float\"\n",
    "assert 0 < prob_in_sample_n10000 < 1, \"Probability must be between 0 and 1\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert abs(prob_in_sample_n10000 - 0.632) < 0.01, f\"Expected ~0.632, got {prob_in_sample_n10000}\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 2 (ISLP Ch 5, Exercise 4):** Estimating Standard Deviation of Predictions\n",
    "\n",
    "Suppose that we use some statistical learning method to make a prediction for the response $Y$ for a particular value of the predictor $X$. Carefully describe how we might estimate the standard deviation of our prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "We can perform bootstrap by repeatedly sampling the dataset and fitting the model from these new datasets and then predicting the response $Y$ at the particular value of predictor $X$. After repeating this over the number of bootstrap samples, we will have a distribution of predicted values of $Y$ given a particular value of $X$. We can then use this distribution to compute the standard deviation of our prediction.\n",
    "\n",
    "> END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 3:** Cross-Validation on Simulated Data\n",
    "\n",
    "We will now perform cross-validation on a simulated data set.\n",
    "\n",
    "**(a)** Generate a simulated data set as follows:\n",
    "\n",
    "```python\n",
    "rng = np.random.default_rng(2024)\n",
    "x = rng.normal(size=100)\n",
    "y = x - 2 * x**2 + rng.normal(size=100)\n",
    "```\n",
    "    \n",
    "In this data set, what is $n$ and what is $p$? Write out the model used to generate the data in equation form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "# Generate the data\n",
    "# n = 100, p = 1, equation: y = x - 2x^2 + epsilon\n",
    "rng = np.random.default_rng(2024)\n",
    "x = rng.normal(size=100)\n",
    "y = x - 2 * x**2 + rng.normal(size=100)\n",
    "print(f\"n = {len(x)}, p = 1\")\n",
    "print(\"Model: y = x - 2x² + ε\")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "In this data set, $n = 100$ and $p = 1$ (the single predictor $X$). The model is $Y = X - 2X^2 + \\epsilon$, where $\\epsilon \\sim N(0, 1)$.\n",
    "\n",
    "> END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** Create a scatterplot of $X$ against $Y$. Comment on what you find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "# The scatterplot shows a nonlinear (quadratic) relationship between X and Y,\n",
    "# which is consistent with the data generating process that includes a quadratic term.\n",
    "sns.scatterplot(x=x, y=y)\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "The scatterplot shows a clear nonlinear (quadratic) relationship between $X$ and $Y$, consistent with the data generating process that includes a quadratic term. The curve opens downward due to the negative coefficient on $X^2$.\n",
    "\n",
    "> END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** Construct 5 folds using `sklearn.model_selection.KFold`, and specify `random_state=3`. Using these folds, compute the cross-validation errors that result from fitting the following four models using least squares. Use the same five folds for all four models.\n",
    "\n",
    "i. $Y = \\beta_0 + \\beta_1 X + \\epsilon$\n",
    "\n",
    "ii. $Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\epsilon$\n",
    "\n",
    "iii. $Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\beta_3 X^3 + \\epsilon$\n",
    "\n",
    "iv. $Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\beta_3 X^3 + \\beta_4 X^4 + \\epsilon$\n",
    "\n",
    "For each fold and each model, report the mean-squared error. Which of the models had the smallest average error? Is this what you expected? Explain your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "# Prepare polynomial features\n",
    "X = x.reshape(-1, 1)\n",
    "X_poly = np.hstack([X**i for i in range(1, 5)])\n",
    "\n",
    "# Perform 5-fold cross-validation for each model\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=3)\n",
    "errors = np.zeros((4, 5))\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    for i in range(4):\n",
    "        X_train_poly = X_poly[train_index, : i + 1]\n",
    "        X_test_poly = X_poly[test_index, : i + 1]\n",
    "\n",
    "        model = LinearRegression().fit(X_train_poly, y_train)\n",
    "        y_pred = model.predict(X_test_poly)\n",
    "        errors[i, fold] = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "errors_df = pd.DataFrame(errors)\n",
    "errors_df.columns = [\"Fold \" + str(col + 1) for col in errors_df.columns]\n",
    "errors_df[\"Mean\"] = errors_df.mean(axis=1)\n",
    "errors_df.index = errors_df.index + 1\n",
    "print(errors_df)\n",
    "print(f\"\\nModel {errors_df['Mean'].idxmin()} has the smallest average error.\")\n",
    "print(\"This is expected since the data was generated with a quadratic relationship.\")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "Model 2 (quadratic) has the smallest average cross-validation error. This is expected since the true data generating process is quadratic ($Y = X - 2X^2 + \\epsilon$). Adding higher-order polynomial terms (cubic, quartic) does not meaningfully improve the fit.\n",
    "\n",
    "> END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert errors_df.shape == (4, 6), f\"Expected shape (4, 6), got {errors_df.shape}\"\n",
    "assert errors_df[\"Mean\"].idxmin() == 2, \"Model 2 should have the lowest mean error\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert errors_df.loc[1, \"Mean\"] > 4, \"Linear model should have high error for quadratic data\"\n",
    "assert errors_df.loc[2, \"Mean\"] < 2, \"Quadratic model should have low error\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 4:** LOOCV and Random Seeds\n",
    "\n",
    "Consider estimating log odds using logistic regression with ridge penalties, setting the regularization strength via LOOCV. True or false: the result will depend on a random seed that we use as part of the LOOCV process. Explain your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "False. One can easily see this by the fact that the LOOCV uses $n-1$ observations as part of its training set and the $n$-th observation as its validation set, repeating this process over all the observations. Such a process is deterministic and there is no randomness in the splitting due to the fact that every iteration is just removing the $i$-th observation (a single observation) and setting it as the validation set. Therefore, there is no dependence on the random seed.\n",
    "\n",
    "> END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 5 (ISLP Ch 5, Exercise 9):** Boston Housing Data Analysis\n",
    "\n",
    "We will now consider the Boston housing data set, which contains information about housing in the Boston area collected in the 1970s. The target variable `medv` represents the median value of owner-occupied homes in $1000s for each census tract.\n",
    "\n",
    "**(a)** Based on this data set, provide an estimate for the population mean of `medv`. Call this estimate $\\hat{\\mu}$ and store it in a variable called `mu_hat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_df = pd.read_csv(\"./data/boston.csv\")\n",
    "# BEGIN SOLUTION\n",
    "mu_hat = boston_df[\"medv\"].mean()\n",
    "print(f\"Estimated mean (mu_hat): {mu_hat:.4f}\")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert isinstance(mu_hat, float), \"mu_hat should be a float\"\n",
    "assert 0 < mu_hat < 100, \"Mean should be a reasonable housing value\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert abs(mu_hat - 22.533) < 0.01, f\"Expected ~22.533, got {mu_hat}\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** Provide an estimate of the standard error of $\\hat{\\mu}$ and store it in a variable called `se_mu_hat`. Interpret this result.\n",
    "\n",
    "**Hint:** We can compute the standard error of the sample mean by dividing the sample standard deviation by the square root of the number of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "se_mu_hat = boston_df[\"medv\"].std() / np.sqrt(boston_df.shape[0])\n",
    "print(f\"Standard error of mean: {se_mu_hat:.4f}\")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "The standard error of approximately 0.41 indicates that the sample mean estimate of median home value has relatively low variability, suggesting our estimate is reasonably precise.\n",
    "\n",
    "> END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert isinstance(se_mu_hat, float), \"se_mu_hat should be a float\"\n",
    "assert se_mu_hat > 0, \"Standard error must be positive\"\n",
    "assert se_mu_hat < mu_hat, \"Standard error should be smaller than the mean\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert abs(se_mu_hat - 0.409) < 0.01, f\"Expected ~0.409, got {se_mu_hat}\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** Now estimate the standard error of $\\hat{\\mu}$ using the bootstrap. Store the result in a variable called `bootstrap_sem`. How does this compare to your answer from (b)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "def get_mean(data):\n",
    "    return data.mean()\n",
    "\n",
    "\n",
    "def boot_se(func, df, colname, n=None, num_bootstrap=1000, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    first_moment, second_moment = 0, 0\n",
    "    n = n or df.shape[0]\n",
    "    for _ in range(num_bootstrap):\n",
    "        bootstrap_sample = rng.choice(df[colname], size=n, replace=True)\n",
    "        value = func(bootstrap_sample)\n",
    "        first_moment += value\n",
    "        second_moment += value**2\n",
    "    return np.sqrt(second_moment / num_bootstrap - (first_moment / num_bootstrap) ** 2)\n",
    "\n",
    "\n",
    "bootstrap_sem = boot_se(get_mean, boston_df, \"medv\", num_bootstrap=10000, seed=2024)\n",
    "print(f\"Bootstrap SE: {bootstrap_sem:.4f}\")\n",
    "print(f\"Formula SE:   {se_mu_hat:.4f}\")\n",
    "print(\"The bootstrap estimate is very close to the formula-based estimate.\")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "The bootstrap estimate of the standard error is very close to the formula-based estimate from (b). This is expected since the Central Limit Theorem guarantees that the sample mean is approximately normally distributed for large samples, making the analytical formula accurate.\n",
    "\n",
    "> END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert isinstance(bootstrap_sem, float), \"bootstrap_sem should be a float\"\n",
    "assert bootstrap_sem > 0, \"Standard error must be positive\"\n",
    "assert bootstrap_sem < 1, \"Bootstrap SE should be reasonable for this dataset\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert abs(bootstrap_sem - 0.408) < 0.02, f\"Expected ~0.408, got {bootstrap_sem}\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d)** Based on your bootstrap estimate from (c), provide a 95% confidence interval for the mean of `medv`. Compare it to the results obtained by using `boston_df['medv'].std()` and the two standard error rule.\n",
    "\n",
    "**Hint:** You can approximate a 95% confidence interval using the formula $[\\hat{\\mu} - 2\\text{SE}(\\hat{\\mu}), \\hat{\\mu} + 2\\text{SE}(\\hat{\\mu})]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "confidence_interval_bootstrap = (mu_hat - 2 * bootstrap_sem, mu_hat + 2 * bootstrap_sem)\n",
    "confidence_interval_standard_error = (mu_hat - 2 * se_mu_hat, mu_hat + 2 * se_mu_hat)\n",
    "print(f\"Bootstrap CI: {confidence_interval_bootstrap}\")\n",
    "print(f\"Formula CI:   {confidence_interval_standard_error}\")\n",
    "print(\"The confidence intervals are very similar, suggesting robustness of the estimator.\")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "The bootstrap-based and formula-based 95% confidence intervals are very similar, both suggesting the population mean of `medv` lies approximately between 21.7 and 23.4 thousand dollars.\n",
    "\n",
    "> END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "ci_low, ci_high = confidence_interval_bootstrap\n",
    "assert ci_low < mu_hat < ci_high, \"Mean should be within CI\"\n",
    "ci_se_low, ci_se_high = confidence_interval_standard_error\n",
    "assert abs(ci_low - ci_se_low) < 0.1, \"Bootstrap and standard CI should be similar\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert ci_high - ci_low < 2, \"CI width should be less than 2\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e)** Based on this data set, provide an estimate, $\\hat{m}$, for the median value of `medv` in the population. Store it in a variable called `median_hat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "median_hat = boston_df[\"medv\"].median()\n",
    "print(f\"Median: {median_hat}\")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert isinstance(median_hat, float), \"median_hat should be a float\"\n",
    "assert 0 < median_hat < 100, \"Median should be a reasonable housing value\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert abs(median_hat - 21.2) < 0.01, f\"Expected 21.2, got {median_hat}\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(f)** We now would like to estimate the standard error of $\\hat{m}$. Unfortunately, there is no simple formula for computing the standard error of the median. Instead, estimate the standard error of the median using the bootstrap and store it in a variable called `bootstrap_se_median`. Comment on your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "def get_median(data):\n",
    "    return np.median(data)\n",
    "\n",
    "\n",
    "bootstrap_se_median = boot_se(get_median, boston_df, \"medv\", num_bootstrap=10000, seed=2024)\n",
    "print(f\"Bootstrap SE of median: {bootstrap_se_median:.4f}\")\n",
    "print(f\"Relative to median ({median_hat}), this SE is small, suggesting high precision.\")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "The bootstrap standard error of the median (~0.38) is small relative to the median itself (21.2), suggesting the median is estimated with good precision. The SE of the median is slightly smaller than the SE of the mean, which is consistent with the median being more robust to the right-skewed distribution of housing values.\n",
    "\n",
    "> END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert isinstance(bootstrap_se_median, float), \"bootstrap_se_median should be a float\"\n",
    "assert bootstrap_se_median > 0, \"Standard error must be positive\"\n",
    "assert bootstrap_se_median < 1, \"Bootstrap SE should be reasonable for this dataset\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert abs(bootstrap_se_median - 0.379) < 0.05, f\"Expected ~0.379, got {bootstrap_se_median}\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(g)** Based on this data set, provide an estimate for the tenth percentile of `medv` in Boston census tracts. Call this quantity $\\hat{p}_{0.1}$ and store it in a variable called `percentile_10_hat`.\n",
    "\n",
    "**Hint:** You can use `np.percentile()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "percentile_10_hat = np.percentile(boston_df[\"medv\"], q=10)\n",
    "print(f\"10th percentile: {percentile_10_hat}\")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert isinstance(percentile_10_hat, int | float), \"percentile_10_hat should be numeric\"\n",
    "assert 0 < percentile_10_hat < median_hat, \"10th percentile should be less than the median\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert abs(percentile_10_hat - 12.75) < 0.1, f\"Expected 12.75, got {percentile_10_hat}\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(h)** Use the bootstrap to estimate the standard error of $\\hat{p}_{0.1}$ and store it in a variable called `bootstrap_se_percentile`. Comment on your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "def get_tenth_percentile(data):\n",
    "    return np.percentile(data, q=10)\n",
    "\n",
    "\n",
    "bootstrap_se_percentile = boot_se(\n",
    "    get_tenth_percentile, boston_df, \"medv\", num_bootstrap=10000, seed=2024\n",
    ")\n",
    "print(f\"Bootstrap SE of 10th percentile: {bootstrap_se_percentile:.4f}\")\n",
    "print(\"This suggests strong precision in estimating the tenth percentile.\")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "The bootstrap standard error of the 10th percentile (~0.50) is somewhat larger than the SE of the median (~0.38). This makes sense since extreme quantiles are estimated from fewer effective observations than central quantiles like the median.\n",
    "\n",
    "> END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert isinstance(bootstrap_se_percentile, float), \"bootstrap_se_percentile should be a float\"\n",
    "assert bootstrap_se_percentile > 0, \"Standard error must be positive\"\n",
    "assert bootstrap_se_percentile < 2, \"Bootstrap SE should be reasonable for this dataset\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert abs(bootstrap_se_percentile - 0.50) < 0.1, f\"Expected ~0.50, got {bootstrap_se_percentile}\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 6:** LOOCV for Logistic Regression\n",
    "\n",
    "In this problem, you will practice computing the LOOCV error for a logistic regression model on the Weekly data set.\n",
    "\n",
    "**(a)** Fit a logistic regression model that predicts `Direction` using `Lag1` and `Lag2`. Report the misclassification rate on the training data and comment on the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_df = pd.read_csv(\"./data/weekly.csv\")\n",
    "# BEGIN SOLUTION\n",
    "weekly_df[\"Coded_Direction\"] = pd.get_dummies(weekly_df[\"Direction\"], dtype=int, drop_first=True)\n",
    "\n",
    "X = weekly_df[[\"Lag1\", \"Lag2\"]]\n",
    "y = weekly_df[\"Coded_Direction\"]\n",
    "model = LogisticRegression().fit(X, y)\n",
    "\n",
    "misclassification_rate_full = 1 - accuracy_score(y, model.predict(X))\n",
    "print(f\"Misclassification rate: {misclassification_rate_full:.4f}\")\n",
    "print(\"This is relatively poor performance - almost half are incorrectly classified.\")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "The misclassification rate on the training data is approximately 44.5%, which is quite poor—barely better than random guessing. This suggests that `Lag1` and `Lag2` alone are not strong predictors of market direction.\n",
    "\n",
    "> END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert isinstance(\n",
    "    misclassification_rate_full, float\n",
    "), \"misclassification_rate_full should be a float\"\n",
    "assert 0 < misclassification_rate_full < 1, \"Misclassification rate must be between 0 and 1\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert (\n",
    "    abs(misclassification_rate_full - 0.445) < 0.01\n",
    "), f\"Expected ~0.445, got {misclassification_rate_full}\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** Fit a logistic regression model that predicts `Direction` using `Lag1` and `Lag2` using all but the first observation. Report the misclassification rate on the full data and comment on the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "X_without_first = X[1:]\n",
    "y_without_first = y[1:]\n",
    "\n",
    "model_without_first = LogisticRegression().fit(X_without_first, y_without_first)\n",
    "misclassification_rate_without_first = 1 - accuracy_score(y, model_without_first.predict(X))\n",
    "print(f\"Misclassification rate: {misclassification_rate_without_first:.4f}\")\n",
    "print(\"Very similar to (a) - removing one observation has minimal effect.\")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert isinstance(\n",
    "    misclassification_rate_without_first, float\n",
    "), \"misclassification_rate_without_first should be a float\"\n",
    "assert (\n",
    "    0 < misclassification_rate_without_first < 1\n",
    "), \"Misclassification rate must be between 0 and 1\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert (\n",
    "    abs(misclassification_rate_without_first - 0.444) < 0.01\n",
    "), f\"Expected ~0.444, got {misclassification_rate_without_first}\"\n",
    "diff = abs(misclassification_rate_without_first - misclassification_rate_full)\n",
    "assert diff < 0.01, \"Rates should be similar\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** Use the model from (b) to predict the direction of the first observation. Was this observation correctly classified?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "prediction = model_without_first.predict(X.iloc[0, :].values.reshape(1, -1))[-1]\n",
    "first_observation_correct = prediction == y.iloc[0]\n",
    "print(f\"Prediction: {prediction}, Actual: {y.iloc[0]}\")\n",
    "print(f\"Correctly classified: {first_observation_correct}\")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert not first_observation_correct, \"First observation should be incorrectly classified\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert isinstance(first_observation_correct, bool | np.bool_), \"Result should be a boolean\"\n",
    "assert prediction == 1, \"Model should predict 'Up' (1) for the first observation\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d)** Write a for loop from `i = 0` to `i = n-1`, where `n` is the number of observations in the data set, that performs each of the following steps:\n",
    "\n",
    "i. Fit a logistic regression model using all but the `i`th observation to predict `Direction` using `Lag1` and `Lag2`.\n",
    "\n",
    "ii. Use this model to predict the direction for the `i`th observation.\n",
    "\n",
    "iii. Determine whether or not an error was made in predicting the direction for the `i`th observation. If an error was made, then indicate this as a 1, and otherwise indicate it as a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "loocv_errors = []\n",
    "for i in range(X.shape[0]):\n",
    "    X_train = X.drop(i)\n",
    "    y_train = y.drop(i)\n",
    "\n",
    "    model_loocv = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "    pred = model_loocv.predict(X.iloc[i, :].values.reshape(1, -1))[-1]\n",
    "    prediction_error = 1 if pred != y.iloc[i] else 0\n",
    "    loocv_errors.append(prediction_error)\n",
    "\n",
    "print(f\"First 5 errors: {loocv_errors[:5]}\")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert len(loocv_errors) == len(y), f\"Expected {len(y)} errors, got {len(loocv_errors)}\"\n",
    "assert all(e in [0, 1] for e in loocv_errors), \"Errors should be 0 or 1\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert 400 < sum(loocv_errors) < 600, f\"Expected ~490 total errors, got {sum(loocv_errors)}\"\n",
    "assert loocv_errors[0] == 1, \"First observation should be misclassified (consistent with part c)\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e)** Take the average of the `n` numbers obtained in part (d)(iii) of this problem in order to obtain the LOOCV estimate for the test error. Comment on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "loocv_error_rate = sum(loocv_errors) / len(loocv_errors)\n",
    "print(f\"LOOCV error rate: {loocv_error_rate:.4f}\")\n",
    "print(\"About 45% error rate - Lag1 and Lag2 are not effective predictors.\")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "The LOOCV error rate is approximately 45%, very similar to the training error rate from (a). This confirms that logistic regression with `Lag1` and `Lag2` has limited predictive ability for market direction.\n",
    "\n",
    "> END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert isinstance(loocv_error_rate, float), \"loocv_error_rate should be a float\"\n",
    "assert 0 < loocv_error_rate < 1, \"Error rate must be between 0 and 1\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert abs(loocv_error_rate - 0.45) < 0.01, f\"Expected ~0.45, got {loocv_error_rate}\"\n",
    "assert (\n",
    "    abs(loocv_error_rate - sum(loocv_errors) / len(loocv_errors)) < 1e-10\n",
    "), \"Error rate should be derived from loocv_errors\"\n",
    "# END HIDDEN TESTS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "winter2026assignments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
