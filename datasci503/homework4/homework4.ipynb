{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# DATASCI 503, Homework 4: Classification\n",
    "\n",
    "This assignment covers Linear Discriminant Analysis (LDA), Quadratic Discriminant Analysis (QDA), and logistic regression for classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from sklearn.discriminant_analysis import (\n",
    "    LinearDiscriminantAnalysis,\n",
    "    QuadraticDiscriminantAnalysis,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sympy import solve, symbols\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 1:** LDA Discriminant Function Derivation\n",
    "\n",
    "It was stated in the text that classifying an observation to the class for which\n",
    "$$ p_k(x) = \\frac{\\pi_k \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{1}{2\\sigma^2}(x - \\mu_k)^2\\right)}{\\sum_{l=1}^K \\pi_l \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{1}{2\\sigma^2}(x - \\mu_l)^2\\right)} $$\n",
    "is largest is equivalent to classifying an observation to the class for which\n",
    "$$ \\delta_k(x) = x \\cdot \\frac{\\mu_k}{\\sigma^2} - \\frac{\\mu_k^2}{2\\sigma^2} + \\log(\\pi_k) $$\n",
    "is largest.\n",
    "\n",
    "Prove that this is the case. In other words, under the assumption that the observations in the $k$th class are drawn from a $\\mathcal{N}(\\mu_k, \\sigma^2)$ distribution, the Bayes classifier assigns an observation to the class for which the discriminant function is maximized.\n",
    "\n",
    "**Hint:** Take the log of the numerator and simplify, noting that terms that don't depend on $k$ can be ignored when comparing across classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "Taking the log of the numerator (the denominator is the same for all classes $k$, so we can ignore it):\n",
    "\n",
    "$$\\log\\left(\\pi_k \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{1}{2\\sigma^2}(x - \\mu_k)^2\\right)\\right)$$\n",
    "\n",
    "Using log properties:\n",
    "$$\\log(\\pi_k) + \\log\\left(\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\right) + \\log\\left(\\exp\\left(-\\frac{1}{2\\sigma^2}(x - \\mu_k)^2\\right)\\right)$$\n",
    "\n",
    "$$= \\log(\\pi_k) - \\frac{1}{2}\\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}(x - \\mu_k)^2$$\n",
    "\n",
    "Expanding $(x - \\mu_k)^2$:\n",
    "$$= \\log(\\pi_k) - \\frac{1}{2}\\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}x^2 + \\frac{\\mu_k}{\\sigma^2}x - \\frac{\\mu_k^2}{2\\sigma^2}$$\n",
    "\n",
    "The terms $-\\frac{1}{2}\\log(2\\pi\\sigma^2)$ and $-\\frac{1}{2\\sigma^2}x^2$ do not depend on $k$, so they don't affect which class maximizes the expression. Dropping these terms:\n",
    "$$\\delta_k(x) = \\log(\\pi_k) + \\frac{\\mu_k}{\\sigma^2}x - \\frac{\\mu_k^2}{2\\sigma^2}$$\n",
    "> END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 2:** QDA is Quadratic\n",
    "\n",
    "This problem relates to the QDA model, in which the observations within each class are drawn from a normal distribution with a class-specific mean vector and a class-specific covariance matrix. We consider the simple case where $p = 1$; i.e., there is only one feature.\n",
    "\n",
    "Suppose that we have $K$ classes, and that if an observation belongs to the $k$th class then $X$ comes from a one-dimensional normal distribution, $X \\sim \\mathcal{N}(\\mu_k, \\sigma^2_k)$. Prove that in this case, the Bayes classifier is *not linear*. Argue that it is in fact quadratic.\n",
    "\n",
    "**Hint:** Follow the arguments laid out in Problem 1, but without making the assumption that $\\sigma^2_1 = \\dots = \\sigma^2_K$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "Following the same approach as Problem 1, but with class-specific variances $\\sigma_k^2$:\n",
    "\n",
    "$$\\log\\left(\\pi_k \\frac{1}{\\sqrt{2\\pi\\sigma_k^2}} \\exp\\left(-\\frac{(x - \\mu_k)^2}{2\\sigma_k^2}\\right)\\right)$$\n",
    "\n",
    "$$= \\log(\\pi_k) - \\frac{1}{2}\\log(2\\pi\\sigma_k^2) - \\frac{(x - \\mu_k)^2}{2\\sigma_k^2}$$\n",
    "\n",
    "$$= \\log(\\pi_k) - \\frac{1}{2}\\log(2\\pi\\sigma_k^2) - \\frac{x^2}{2\\sigma_k^2} + \\frac{x\\mu_k}{\\sigma_k^2} - \\frac{\\mu_k^2}{2\\sigma_k^2}$$\n",
    "\n",
    "Computing the log odds between class $k$ and class $k'$:\n",
    "$$\\log\\frac{p_k(x)}{p_{k'}(x)} = \\log(\\pi_k) - \\frac{1}{2}\\log(2\\pi\\sigma_k^2) - \\frac{x^2}{2\\sigma_k^2} + \\frac{x\\mu_k}{\\sigma_k^2} - \\frac{\\mu_k^2}{2\\sigma_k^2}$$\n",
    "$$- \\left(\\log(\\pi_{k'}) - \\frac{1}{2}\\log(2\\pi\\sigma_{k'}^2) - \\frac{x^2}{2\\sigma_{k'}^2} + \\frac{x\\mu_{k'}}{\\sigma_{k'}^2} - \\frac{\\mu_{k'}^2}{2\\sigma_{k'}^2}\\right)$$\n",
    "\n",
    "When $\\sigma_k \\neq \\sigma_{k'}$, the $x^2$ terms do not cancel, resulting in a quadratic decision boundary.\n",
    "> END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 3:** LDA vs QDA Performance\n",
    "\n",
    "We now examine the differences between LDA and QDA.\n",
    "\n",
    "(a) If the Bayes decision boundary is linear, do we expect LDA or QDA to perform better on the training set? On the test set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "If the Bayes decision boundary is linear: On training, QDA may perform slightly better due to flexibility/overfitting. On test, LDA will likely perform better because it correctly captures the linear structure.\n",
    "\n",
    "> END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "(b) If the Bayes decision boundary is non-linear, do we expect LDA or QDA to perform better on the training set? On the test set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "On both training and test sets, QDA is expected to perform better because it can model non-linear boundaries.\n",
    "\n",
    "> END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "(c) True or False: Even if the Bayes decision boundary for a given problem is linear, we will probably achieve a superior test error rate using QDA rather than LDA because QDA is flexible enough to model a linear decision boundary. Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "False. While QDA can model a linear decision boundary, it has more parameters to estimate. With limited data, this can lead to overfitting, resulting in worse test error compared to LDA.\n",
    "\n",
    "> END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 4:** Dividend Prediction\n",
    "\n",
    "Suppose that we wish to predict whether a given stock will issue a dividend this year (\"Yes\" or \"No\") based on $X$, last year's percent profit. We examine a large number of companies and discover that:\n",
    "- The mean value of $X$ for companies that issued a dividend was $\\bar{X} = 10$\n",
    "- The mean for those that didn't was $\\bar{X} = 0$\n",
    "- The variance of $X$ for both groups was $\\sigma^2 = 36$\n",
    "- 80% of companies issued dividends\n",
    "\n",
    "Assuming that $X$ follows a normal distribution, compute the probability that a company will issue a dividend this year given that its percentage profit was $X = 4$ last year. Store your answer (as a decimal between 0 and 1) in a variable called `prob_dividend`.\n",
    "\n",
    "**Hint:** Use Bayes' theorem: $P(D|X) = \\frac{P(X|D)P(D)}{P(X)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute P(D|X=4) using Bayes' theorem\n",
    "# BEGIN SOLUTION\n",
    "# Parameters\n",
    "mu_dividend = 10  # Mean for companies that issued dividend\n",
    "mu_no_dividend = 0  # Mean for companies that did not\n",
    "sigma = np.sqrt(36)  # Standard deviation (same for both)\n",
    "prior_dividend = 0.8  # P(D)\n",
    "prior_no_dividend = 0.2  # P(not D)\n",
    "x_observed = 4  # Observed profit\n",
    "\n",
    "# P(X=4 | D) and P(X=4 | not D) using Gaussian pdf\n",
    "p_x_given_d = norm.pdf(x_observed, loc=mu_dividend, scale=sigma)\n",
    "p_x_given_not_d = norm.pdf(x_observed, loc=mu_no_dividend, scale=sigma)\n",
    "\n",
    "# P(X=4) using law of total probability\n",
    "p_x = p_x_given_d * prior_dividend + p_x_given_not_d * prior_no_dividend\n",
    "\n",
    "# P(D | X=4) using Bayes' theorem\n",
    "prob_dividend = (p_x_given_d * prior_dividend) / p_x\n",
    "# END SOLUTION\n",
    "\n",
    "print(f\"Probability of dividend given X=4: {prob_dividend:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert 0.75 < prob_dividend < 0.76, f\"Expected ~0.7519, got {prob_dividend}\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert (\n",
    "    abs(prob_dividend - 0.7518524532975261) < 1e-6\n",
    "), \"prob_dividend should be approximately 0.7519\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## LDA Decision Boundary\n",
    "\n",
    "Suppose you have one continuous predictor $X$ and a binary categorical response $Y$, which can take values 1 or 2. Suppose you collected training data from the two classes and obtained class-specific sample means $\\hat{\\mu}_1 = -1$ and $\\hat{\\mu}_2 = 3$, along with the pooled variance estimate over the two classes, $\\hat{\\sigma}^2 = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 5:** Equal Priors\n",
    "\n",
    "Assume equal class priors and derive the LDA classification rule for this problem. Using `scipy.stats.norm.pdf` to compute the necessary probability density functions, show both of the estimated class-conditional densities in the same plot. Also show the estimated Bayes decision boundary in this plot. Make sure you label the axes.\n",
    "\n",
    "Let $c$ denote the position of the decision boundary. Store the numerical value of $c$ in a variable called `boundary_c`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot class-conditional densities and compute decision boundary\n",
    "# BEGIN SOLUTION\n",
    "# Parameters\n",
    "mu1, mu2 = -1, 3\n",
    "sigma = 1\n",
    "\n",
    "# Generate x values for plotting\n",
    "x_vals = np.linspace(-5, 7, 1000)\n",
    "\n",
    "# Class-conditional densities\n",
    "pdf_class1 = norm.pdf(x_vals, mu1, sigma)\n",
    "pdf_class2 = norm.pdf(x_vals, mu2, sigma)\n",
    "\n",
    "# Decision boundary with equal priors: midpoint between means\n",
    "boundary_c = (mu1 + mu2) / 2\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(x_vals, pdf_class1, label=\"Class 1 ($Y=1$)\")\n",
    "plt.plot(x_vals, pdf_class2, label=\"Class 2 ($Y=2$)\")\n",
    "plt.axvline(\n",
    "    x=boundary_c, color=\"red\", linestyle=\"--\", label=f\"Decision Boundary ($c={boundary_c}$)\"\n",
    ")\n",
    "plt.title(\"Class-Conditional Densities and Decision Boundary\")\n",
    "plt.xlabel(\"$X$\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# END SOLUTION\n",
    "\n",
    "print(f\"Decision boundary position: c = {boundary_c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert boundary_c == 1.0, f\"Expected boundary at 1.0, got {boundary_c}\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert boundary_c == (-1 + 3) / 2, \"boundary_c should be the midpoint of mu1 and mu2\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 6:** Unequal Priors (Conceptual)\n",
    "\n",
    "Suppose the estimates were obtained from 100 training points, among which 40 were from class 1 and 60 were from class 2. Suppose now you will estimate class priors from data.\n",
    "\n",
    "Without calculating the new boundary $\\hat{c}$, would you expect it to be the same as, less than, or greater than $c$? Explain your reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "The new boundary $\\hat{c}$ will be less than $c$.\n",
    "\n",
    "Since class 2 has a higher prior probability (0.6 vs 0.4), the decision boundary shifts toward the class with lower prior (class 1). This accounts for the higher likelihood of encountering class 2 samples, making it \"easier\" to classify a point as class 2 by expanding its decision region.\n",
    "\n",
    "Mathematically, the LDA decision boundary with priors is:\n",
    "$$c = \\frac{\\mu_1 + \\mu_2}{2} + \\frac{\\sigma^2}{\\mu_2 - \\mu_1}\\log\\left(\\frac{\\pi_1}{\\pi_2}\\right)$$\n",
    "\n",
    "Since $\\pi_1 < \\pi_2$, the log term is negative, shifting $c$ to the left (smaller).\n",
    "> END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 7:** Calculate Boundary with Unequal Priors\n",
    "\n",
    "Now calculate the new boundary value $\\hat{c}$ using the priors estimated from the data (40 from class 1, 60 from class 2). Store your answer in a variable called `boundary_c_hat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate boundary with unequal priors\n",
    "# BEGIN SOLUTION\n",
    "mu1, mu2 = -1, 3\n",
    "sigma_sq = 1\n",
    "prior_1, prior_2 = 0.4, 0.6\n",
    "\n",
    "# LDA decision boundary formula with priors\n",
    "boundary_c_hat = (mu1 + mu2) / 2 + (np.log(prior_1 / prior_2) * sigma_sq) / (mu2 - mu1)\n",
    "# END SOLUTION\n",
    "\n",
    "print(f\"New decision boundary: c_hat = {boundary_c_hat:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert 0.89 < boundary_c_hat < 0.91, f\"Expected ~0.899, got {boundary_c_hat}\"\n",
    "assert boundary_c_hat < 1.0, \"boundary_c_hat should be less than 1.0\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert (\n",
    "    abs(boundary_c_hat - 0.898633722972959) < 1e-6\n",
    "), \"boundary_c_hat should be approximately 0.8986\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 8:** LDA vs QDA Recommendation\n",
    "\n",
    "Suppose in addition to the pooled covariance value $\\hat{\\sigma}^2 = 1$, I now tell you the individual class-specific covariances were estimated as $\\hat{\\sigma}_1^2 = 0.25$ and $\\hat{\\sigma}_2^2 = 1.5$.\n",
    "\n",
    "Based on this new information, would you recommend using LDA or QDA, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "QDA should be used because the class-specific variances are substantially different ($\\hat{\\sigma}_1^2 = 0.25$ vs $\\hat{\\sigma}_2^2 = 1.5$). LDA assumes equal covariances across classes, which is violated here. QDA can model these different variances and will produce a quadratic decision boundary that better captures the true class structure.\n",
    "> END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 9:** QDA Decision Boundary\n",
    "\n",
    "Derive the QDA rule if $\\hat{\\sigma}_1^2 = 0.25$ and $\\hat{\\sigma}_2^2 = 1.5$, $\\hat{\\mu}_1 = -1$ and $\\hat{\\mu}_2 = 3$, assuming equal class priors. Calculate the numerical values for the decision boundary. Store the two boundary values in a list called `qda_boundaries` (sorted from smallest to largest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate QDA decision boundary\n",
    "# BEGIN SOLUTION\n",
    "# With equal priors, the decision boundary is where the discriminant functions are equal\n",
    "# delta_1(x) = delta_2(x), which means N(x; mu1, sigma1^2) = N(x; mu2, sigma2^2)\n",
    "\n",
    "x = symbols(\"x\")\n",
    "sigma1_sq = 0.25\n",
    "sigma2_sq = 1.5\n",
    "mu1, mu2 = -1, 3\n",
    "\n",
    "# Log discriminant functions (ignoring common constant terms)\n",
    "delta1 = -0.5 * np.log(2 * np.pi * sigma1_sq) - ((x - mu1) ** 2) / (2 * sigma1_sq)\n",
    "delta2 = -0.5 * np.log(2 * np.pi * sigma2_sq) - ((x - mu2) ** 2) / (2 * sigma2_sq)\n",
    "\n",
    "# Solve delta1 = delta2\n",
    "boundary_solutions = solve(delta1 - delta2, x)\n",
    "qda_boundaries = sorted([float(sol) for sol in boundary_solutions])\n",
    "# END SOLUTION\n",
    "\n",
    "print(f\"QDA decision boundaries: {qda_boundaries}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert len(qda_boundaries) == 2, \"Should have two boundary points\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert qda_boundaries[0] < 0, \"First boundary should be negative\"\n",
    "assert qda_boundaries[1] > 0, \"Second boundary should be positive\"\n",
    "assert abs(qda_boundaries[0] - (-3.892254248596096)) < 1e-4, \"First boundary incorrect\"\n",
    "assert abs(qda_boundaries[1] - 0.29225424859609667) < 1e-4, \"Second boundary incorrect\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## Stock Market Prediction\n",
    "\n",
    "The `Smarket` dataset consists of percentage returns for the S&P 500 stock index over 1,250 days, from the beginning of 2001 until the end of 2005. For each date, we have recorded the percentage returns for each of the five previous trading days (`Lag1` through `Lag5`), the trading `Volume` (in billions of shares) for the previous trading day, and the return and direction (Up or Down) of the market on the date in question (`Today` and `Direction`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Smarket data\n",
    "smarket = pd.read_csv(\"./data/Smarket.csv\")\n",
    "smarket.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 10:** Exploratory Data Analysis\n",
    "\n",
    "Produce some numerical and graphical summaries of the `smarket` data. Do there appear to be any patterns? Create at least one visualization (e.g., boxplots comparing Up vs Down days)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory analysis of smarket data\n",
    "# BEGIN SOLUTION\n",
    "# Create side-by-side boxplots for each feature by Direction\n",
    "fig, axes = plt.subplots(2, 4, figsize=(14, 8))\n",
    "features = [\"Lag1\", \"Lag2\", \"Lag3\", \"Lag4\", \"Lag5\", \"Volume\", \"Today\"]\n",
    "\n",
    "for i, nm in enumerate(features):\n",
    "    ax = axes[i // 4, i % 4]\n",
    "    up_values = smarket.loc[smarket.Direction == \"Up\"][nm]\n",
    "    down_values = smarket.loc[smarket.Direction == \"Down\"][nm]\n",
    "    ax.boxplot([up_values, down_values])\n",
    "    ax.set_ylabel(nm)\n",
    "    ax.set_xticks([1, 2])\n",
    "    ax.set_xticklabels([\"Up\", \"Down\"])\n",
    "\n",
    "axes[1, 3].axis(\"off\")  # Hide empty subplot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "print(\"Interpretation:\")\n",
    "print(\"Based on the boxplots, there is very little visible difference between Up and Down\")\n",
    "print(\"days for the lag variables and volume. Only the Today variable shows a clear\")\n",
    "print(\"difference (which is expected since Direction is derived from Today). This suggests\")\n",
    "print(\"that the lag variables may not be strong predictors of Direction.\")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert len(plt.get_fignums()) > 0, \"Expected at least one plot to be created\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "# EDA problem - graded on effort and interpretation\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 11:** LDA on Stock Market Data\n",
    "\n",
    "Fit an LDA model using training data from 2001 to 2004, with `Direction` as the response and `Lag1` and `Lag2` as predictors. Use the model to predict on the held-out test data (2005). Store the test accuracy in a variable called `lda_accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit LDA model and evaluate on test set\n",
    "# BEGIN SOLUTION\n",
    "# Split data by year\n",
    "train_smarket = smarket.loc[smarket[\"Year\"] <= 2004]\n",
    "test_smarket = smarket.loc[smarket[\"Year\"] > 2004]\n",
    "\n",
    "# Prepare features and labels\n",
    "x_train_sm = train_smarket[[\"Lag1\", \"Lag2\"]]\n",
    "y_train_sm = train_smarket[\"Direction\"]\n",
    "x_test_sm = test_smarket[[\"Lag1\", \"Lag2\"]]\n",
    "y_test_sm = test_smarket[\"Direction\"]\n",
    "\n",
    "# Fit LDA\n",
    "lda_smarket = LinearDiscriminantAnalysis().fit(x_train_sm, y_train_sm)\n",
    "y_pred_lda = lda_smarket.predict(x_test_sm)\n",
    "\n",
    "# Compute accuracy\n",
    "lda_accuracy = accuracy_score(y_test_sm, y_pred_lda)\n",
    "# END SOLUTION\n",
    "\n",
    "print(f\"LDA Test Accuracy: {lda_accuracy:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_sm, y_pred_lda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert 0.5 < lda_accuracy < 0.6, f\"Expected accuracy around 0.56, got {lda_accuracy}\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert abs(lda_accuracy - 0.5595238095238095) < 1e-6, \"LDA accuracy should be approximately 0.5595\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 12:** QDA on Stock Market Data\n",
    "\n",
    "Repeat the analysis using QDA instead of LDA. Store the test accuracy in a variable called `qda_accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit QDA model and evaluate on test set\n",
    "# BEGIN SOLUTION\n",
    "qda_smarket = QuadraticDiscriminantAnalysis().fit(x_train_sm, y_train_sm)\n",
    "y_pred_qda = qda_smarket.predict(x_test_sm)\n",
    "qda_accuracy = accuracy_score(y_test_sm, y_pred_qda)\n",
    "# END SOLUTION\n",
    "\n",
    "print(f\"QDA Test Accuracy: {qda_accuracy:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_sm, y_pred_qda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert 0.59 < qda_accuracy < 0.61, f\"Expected accuracy around 0.60, got {qda_accuracy}\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert abs(qda_accuracy - 0.5992063492063492) < 1e-6, \"QDA accuracy should be approximately 0.5992\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "## Auto MPG Classification\n",
    "\n",
    "In this problem, you will develop a model to predict whether a given car will be classified as having high or low gas mileage based on the Auto dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Auto data\n",
    "auto_df = pd.read_csv(\"./data/auto_nonan.csv\", index_col=0).set_index(\"name\")\n",
    "auto_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 13:** Create Binary Variable\n",
    "\n",
    "Create a binary variable `mpg01` that equals 1 if the value of `mpg` for that car is above 25, and 0 otherwise. Add this variable as a new column to your data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mpg01 column\n",
    "# BEGIN SOLUTION\n",
    "auto_df[\"mpg01\"] = np.where(auto_df[\"mpg\"] > 25, 1, 0)\n",
    "# END SOLUTION\n",
    "\n",
    "auto_df[[\"mpg\", \"mpg01\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert \"mpg01\" in auto_df.columns, \"mpg01 column not found\"\n",
    "assert auto_df[\"mpg01\"].isin([0, 1]).all(), \"mpg01 should only contain 0 and 1\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert auto_df[\"mpg01\"].sum() == 156, \"Number of cars with mpg > 25 should be 156\"\n",
    "assert (auto_df[\"mpg01\"] == 0).sum() == 236, \"Number of cars with mpg <= 25 should be 236\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 14:** Exploratory Analysis\n",
    "\n",
    "Make some exploratory plots to investigate the association between `mpg01` and other variables. Besides `mpg` itself, which four quantitative features do you think are most likely to be useful in predicting `mpg01`? Defend your argument with plots (e.g., side-by-side boxplots)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory analysis\n",
    "# BEGIN SOLUTION\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "features_to_plot = [\"displacement\", \"horsepower\", \"weight\", \"acceleration\", \"year\", \"cylinders\"]\n",
    "\n",
    "for i, nm in enumerate(features_to_plot):\n",
    "    ax = axes[i // 3, i % 3]\n",
    "    vals0 = auto_df.loc[auto_df.mpg01 == 0][nm]\n",
    "    vals1 = auto_df.loc[auto_df.mpg01 == 1][nm]\n",
    "    ax.boxplot([vals0, vals1])\n",
    "    ax.set_ylabel(nm)\n",
    "    ax.set_xticks([1, 2])\n",
    "    ax.set_xticklabels([\"mpg01=0\", \"mpg01=1\"])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "print(\"Based on the boxplots, the four most useful features for predicting mpg01 are:\")\n",
    "print(\"1. cylinders - Clear separation between low/high mpg cars\")\n",
    "print(\"2. displacement - Strong separation, low mpg cars have higher displacement\")\n",
    "print(\"3. horsepower - Clear difference, high mpg cars have lower horsepower\")\n",
    "print(\"4. weight - Strong predictor, lighter cars tend to have better mpg\")\n",
    "print()\n",
    "print(\"These features show the clearest separation between the two groups.\")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert len(plt.get_fignums()) > 0, \"Expected at least one plot to be created\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "# EDA problem - graded on effort and interpretation\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 15:** Train/Test Split\n",
    "\n",
    "Split the data into training and test sets using `train_test_split` with:\n",
    "- `random_state=123`\n",
    "- `train_size=0.8`\n",
    "- `stratify` set to the values of `mpg01`\n",
    "\n",
    "Store the number of training samples where `mpg01` is 1 in a variable called `n_mpg01_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "# BEGIN SOLUTION\n",
    "# Use the four selected features\n",
    "features = [\"cylinders\", \"displacement\", \"horsepower\", \"weight\"]\n",
    "x_auto = auto_df[features]\n",
    "y_auto = auto_df[\"mpg01\"]\n",
    "\n",
    "x_train_auto, x_test_auto, y_train_auto, y_test_auto = train_test_split(\n",
    "    x_auto, y_auto, train_size=0.8, random_state=123, stratify=y_auto\n",
    ")\n",
    "\n",
    "n_mpg01_train = (y_train_auto == 1).sum()\n",
    "# END SOLUTION\n",
    "\n",
    "print(f\"Training samples with mpg01=1: {n_mpg01_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert n_mpg01_train == 125, f\"Expected 125, got {n_mpg01_train}\"\n",
    "assert len(x_train_auto) == 313, \"Training set should have 313 samples\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert len(x_test_auto) == 79, \"Test set should have 79 samples\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 16:** LDA on Auto Data\n",
    "\n",
    "Fit an LDA model on the training data using the four selected features. Report the misclassification rate on both training and test data. Store the test misclassification rate in a variable called `lda_misclass_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit LDA model\n",
    "# BEGIN SOLUTION\n",
    "lda_auto = LinearDiscriminantAnalysis().fit(x_train_auto, y_train_auto)\n",
    "y_train_pred_lda = lda_auto.predict(x_train_auto)\n",
    "y_test_pred_lda = lda_auto.predict(x_test_auto)\n",
    "\n",
    "lda_misclass_train = 1 - accuracy_score(y_train_auto, y_train_pred_lda)\n",
    "lda_misclass_test = 1 - accuracy_score(y_test_auto, y_test_pred_lda)\n",
    "# END SOLUTION\n",
    "\n",
    "print(f\"LDA Training Misclassification Rate: {lda_misclass_train:.4f}\")\n",
    "print(f\"LDA Test Misclassification Rate: {lda_misclass_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert 0.1 < lda_misclass_test < 0.25, f\"Expected ~0.20, got {lda_misclass_test}\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert (\n",
    "    abs(lda_misclass_test - 0.20253164556962022) < 1e-6\n",
    "), \"LDA test misclass rate should be ~0.2025\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 17:** QDA on Auto Data\n",
    "\n",
    "Repeat the analysis using QDA. Store the test misclassification rate in a variable called `qda_misclass_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit QDA model\n",
    "# BEGIN SOLUTION\n",
    "qda_auto = QuadraticDiscriminantAnalysis().fit(x_train_auto, y_train_auto)\n",
    "y_train_pred_qda = qda_auto.predict(x_train_auto)\n",
    "y_test_pred_qda = qda_auto.predict(x_test_auto)\n",
    "\n",
    "qda_misclass_train = 1 - accuracy_score(y_train_auto, y_train_pred_qda)\n",
    "qda_misclass_test = 1 - accuracy_score(y_test_auto, y_test_pred_qda)\n",
    "# END SOLUTION\n",
    "\n",
    "print(f\"QDA Training Misclassification Rate: {qda_misclass_train:.4f}\")\n",
    "print(f\"QDA Test Misclassification Rate: {qda_misclass_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert 0.15 < qda_misclass_test < 0.2, f\"Expected ~0.18, got {qda_misclass_test}\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert (\n",
    "    abs(qda_misclass_test - 0.17721518987341767) < 1e-6\n",
    "), \"QDA test misclass rate should be ~0.1772\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 18:** Compare LDA and QDA\n",
    "\n",
    "Compare and contrast the performance of LDA and QDA. What do your results suggest about the class-specific covariances?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "QDA performs better than LDA on both training and test data (lower misclassification rates). This suggests that the class-specific covariances are not equal between the two groups (high vs low mpg cars). The assumption of equal covariances in LDA appears to be violated, making QDA's more flexible model a better fit for this data.\n",
    "> END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 19:** Logistic Regression\n",
    "\n",
    "Fit a logistic regression model on the training data. Store the test misclassification rate in a variable called `logistic_misclass_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit logistic regression model\n",
    "# BEGIN SOLUTION\n",
    "logistic_auto = LogisticRegression(max_iter=1000).fit(x_train_auto, y_train_auto)\n",
    "y_train_pred_log = logistic_auto.predict(x_train_auto)\n",
    "y_test_pred_log = logistic_auto.predict(x_test_auto)\n",
    "\n",
    "logistic_misclass_train = 1 - accuracy_score(y_train_auto, y_train_pred_log)\n",
    "logistic_misclass_test = 1 - accuracy_score(y_test_auto, y_test_pred_log)\n",
    "# END SOLUTION\n",
    "\n",
    "print(f\"Logistic Training Misclassification Rate: {logistic_misclass_train:.4f}\")\n",
    "print(f\"Logistic Test Misclassification Rate: {logistic_misclass_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert 0.1 < logistic_misclass_test < 0.2, f\"Expected ~0.15, got {logistic_misclass_test}\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert (\n",
    "    abs(logistic_misclass_test - 0.15189873417721522) < 1e-6\n",
    "), \"Logistic test misclass should be ~0.1519\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 20:** K-Nearest Neighbors\n",
    "\n",
    "Fit KNN models for various values of K (from 1 to 35). Plot the training and test classification error vs K. Store the best K (based on test error) in a variable called `best_k`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit KNN models for various K\n",
    "# BEGIN SOLUTION\n",
    "k_values = range(1, 36)\n",
    "train_errors_knn = []\n",
    "test_errors_knn = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(x_train_auto, y_train_auto)\n",
    "\n",
    "    y_train_pred_knn = knn.predict(x_train_auto)\n",
    "    y_test_pred_knn = knn.predict(x_test_auto)\n",
    "\n",
    "    train_errors_knn.append(1 - accuracy_score(y_train_auto, y_train_pred_knn))\n",
    "    test_errors_knn.append(1 - accuracy_score(y_test_auto, y_test_pred_knn))\n",
    "\n",
    "best_k = k_values[np.argmin(test_errors_knn)]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values, train_errors_knn, label=\"Training Error\")\n",
    "plt.plot(k_values, test_errors_knn, label=\"Test Error\")\n",
    "plt.xlabel(\"Number of Neighbors K\")\n",
    "plt.ylabel(\"Classification Error\")\n",
    "plt.title(\"KNN Classification Error vs. Number of Neighbors\")\n",
    "plt.legend()\n",
    "plt.gca().invert_xaxis()\n",
    "plt.show()\n",
    "# END SOLUTION\n",
    "\n",
    "print(f\"Best K based on test error: {best_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert 1 <= best_k <= 35, \"best_k should be between 1 and 35\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert best_k == 23, f\"Best K should be 23, got {best_k}\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 21:** Model Comparison Summary\n",
    "\n",
    "Compare the test performance of all methods (LDA, QDA, Logistic Regression, KNN with best K). Which method performs best on this dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "Test misclassification rates:\n",
    "- LDA: ~20.3%\n",
    "- QDA: ~17.7%\n",
    "- Logistic Regression: ~15.2%\n",
    "- KNN (K=23): ~16.5%\n",
    "\n",
    "Logistic regression performs best on this dataset, followed closely by KNN and QDA. LDA performs worst, which is consistent with our earlier observation that the class-specific covariances are unequal. Logistic regression provides a good balance between flexibility and simplicity for this classification task.\n",
    "> END SOLUTION\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
