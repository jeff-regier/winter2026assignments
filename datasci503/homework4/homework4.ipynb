{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# DATASCI 503, Homework 4: Classification\n",
    "\n",
    "This assignment covers Linear Discriminant Analysis (LDA), Quadratic Discriminant Analysis (QDA), and logistic regression for classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from sklearn.discriminant_analysis import (\n",
    "    LinearDiscriminantAnalysis,\n",
    "    QuadraticDiscriminantAnalysis,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sympy import solve, symbols\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 1 (ISLP Ch 4, Exercise 2):** LDA Discriminant Function Derivation\n",
    "\n",
    "It was stated in the text that classifying an observation to the class for which\n",
    "\n",
    "$$p_k(x) = \\frac{\\pi_k \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{1}{2\\sigma^2}(x - \\mu_k)^2\\right)}{\\sum_{l=1}^{K} \\pi_l \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{1}{2\\sigma^2}(x - \\mu_l)^2\\right)}$$\n",
    "\n",
    "is largest is equivalent to classifying an observation to the class for which\n",
    "\n",
    "$$\\delta_k(x) = x \\cdot \\frac{\\mu_k}{\\sigma^2} - \\frac{\\mu_k^2}{2\\sigma^2} + \\log(\\pi_k)$$\n",
    "\n",
    "is largest. Prove that this is the case. In other words, under the assumption that the observations in the $k$-th class are drawn from a $N(\\mu_k, \\sigma^2)$ distribution, the Bayes classifier assigns an observation to the class for which the discriminant function is maximized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "Taking the log of the numerator (the denominator is the same for all classes $k$, so we can ignore it):\n",
    "\n",
    "$$\\log\\left(\\pi_k \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{1}{2\\sigma^2}(x - \\mu_k)^2\\right)\\right)$$\n",
    "\n",
    "Using log properties:\n",
    "$$\\log(\\pi_k) + \\log\\left(\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\right) + \\log\\left(\\exp\\left(-\\frac{1}{2\\sigma^2}(x - \\mu_k)^2\\right)\\right)$$\n",
    "\n",
    "$$= \\log(\\pi_k) - \\frac{1}{2}\\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}(x - \\mu_k)^2$$\n",
    "\n",
    "Expanding $(x - \\mu_k)^2$:\n",
    "$$= \\log(\\pi_k) - \\frac{1}{2}\\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}x^2 + \\frac{\\mu_k}{\\sigma^2}x - \\frac{\\mu_k^2}{2\\sigma^2}$$\n",
    "\n",
    "The terms $-\\frac{1}{2}\\log(2\\pi\\sigma^2)$ and $-\\frac{1}{2\\sigma^2}x^2$ do not depend on $k$, so they don't affect which class maximizes the expression. Dropping these terms:\n",
    "$$\\delta_k(x) = \\log(\\pi_k) + \\frac{\\mu_k}{\\sigma^2}x - \\frac{\\mu_k^2}{2\\sigma^2}$$\n",
    "> END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 2 (ISLP Ch 4, Exercise 3):** QDA is Quadratic\n",
    "\n",
    "This problem relates to the QDA model, in which the observations within each class are drawn from a normal distribution with a class-specific mean vector and a class-specific covariance matrix. We consider the simple case where $p = 1$; i.e. there is only one feature.\n",
    "\n",
    "Suppose that we have $K$ classes, and that if an observation belongs to the $k$-th class then $X$ comes from a one-dimensional normal distribution, $X \\sim N(\\mu_k, \\sigma_k^2)$. Recall that the density function for the one-dimensional normal distribution is given by\n",
    "\n",
    "$$f_k(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma_k} \\exp\\left(-\\frac{1}{2\\sigma_k^2}(x - \\mu_k)^2\\right).$$\n",
    "\n",
    "Prove that in this case, the Bayes classifier is *not* linear. Argue that it is in fact quadratic.\n",
    "\n",
    "*Hint: For this problem, you should follow the arguments laid out in Problem 1, but without making the assumption that $\\sigma_1^2 = \\cdots = \\sigma_K^2$.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "Following the same approach as Problem 1, but with class-specific variances $\\sigma_k^2$:\n",
    "\n",
    "$$\\log\\left(\\pi_k \\frac{1}{\\sqrt{2\\pi\\sigma_k^2}} \\exp\\left(-\\frac{(x - \\mu_k)^2}{2\\sigma_k^2}\\right)\\right)$$\n",
    "\n",
    "$$= \\log(\\pi_k) - \\frac{1}{2}\\log(2\\pi\\sigma_k^2) - \\frac{(x - \\mu_k)^2}{2\\sigma_k^2}$$\n",
    "\n",
    "$$= \\log(\\pi_k) - \\frac{1}{2}\\log(2\\pi\\sigma_k^2) - \\frac{x^2}{2\\sigma_k^2} + \\frac{x\\mu_k}{\\sigma_k^2} - \\frac{\\mu_k^2}{2\\sigma_k^2}$$\n",
    "\n",
    "Computing the log odds between class $k$ and class $k'$:\n",
    "$$\\log\\frac{p_k(x)}{p_{k'}(x)} = \\log(\\pi_k) - \\frac{1}{2}\\log(2\\pi\\sigma_k^2) - \\frac{x^2}{2\\sigma_k^2} + \\frac{x\\mu_k}{\\sigma_k^2} - \\frac{\\mu_k^2}{2\\sigma_k^2}$$\n",
    "$$- \\left(\\log(\\pi_{k'}) - \\frac{1}{2}\\log(2\\pi\\sigma_{k'}^2) - \\frac{x^2}{2\\sigma_{k'}^2} + \\frac{x\\mu_{k'}}{\\sigma_{k'}^2} - \\frac{\\mu_{k'}^2}{2\\sigma_{k'}^2}\\right)$$\n",
    "\n",
    "When $\\sigma_k \\neq \\sigma_{k'}$, the $x^2$ terms do not cancel, resulting in a quadratic decision boundary.\n",
    "> END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 3 (ISLP Ch 4, Exercise 5a, 5b, and 5d):** LDA vs QDA Performance\n",
    "\n",
    "We now examine the differences between LDA and QDA.\n",
    "\n",
    "(a) If the Bayes decision boundary is linear, do we expect LDA or QDA to perform better on the training set? On the test set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "If the Bayes decision boundary is linear: On training, QDA may perform slightly better due to flexibility/overfitting. On test, LDA will likely perform better because it correctly captures the linear structure.\n",
    "\n",
    "> END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "(b) If the Bayes decision boundary is non-linear, do we expect LDA or QDA to perform better on the training set? On the test set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "On both training and test sets, QDA is expected to perform better because it can model non-linear boundaries.\n",
    "\n",
    "> END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "(c) True or False: Even if the Bayes decision boundary for a given problem is linear, we will probably achieve a superior test error rate using QDA rather than LDA because QDA is flexible enough to model a linear decision boundary. Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "False. While QDA can model a linear decision boundary, it has more parameters to estimate. With limited data, this can lead to overfitting, resulting in worse test error compared to LDA.\n",
    "\n",
    "> END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 4 (ISLP Ch 4, Exercise 7):** Dividend Prediction\n",
    "\n",
    "Suppose that we wish to predict whether a given stock will issue a dividend this year (\"Yes\" or \"No\") based on $X$, last year's percent profit. We examine a large number of companies and discover that the mean value of $X$ for companies that issued a dividend was $\\bar{X} = 10$, while the mean for those that didn't was $\\bar{X} = 0$. In addition, the variance of $X$ for these two sets of companies was $\\hat{\\sigma}^2 = 36$. Finally, 80% of companies issued dividends. Assuming that $X$ follows a normal distribution, predict the probability that a company will issue a dividend this year given that its percentage profit was $X = 4$ last year.\n",
    "\n",
    "*Hint: Recall that the density function for a normal random variable is $f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-(x-\\mu)^2 / 2\\sigma^2}$. You will need to use Bayes' theorem.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute P(D|X=4) using Bayes' theorem\n",
    "# BEGIN SOLUTION\n",
    "# Parameters\n",
    "mu_dividend = 10  # Mean for companies that issued dividend\n",
    "mu_no_dividend = 0  # Mean for companies that did not\n",
    "sigma = np.sqrt(36)  # Standard deviation (same for both)\n",
    "prior_dividend = 0.8  # P(D)\n",
    "prior_no_dividend = 0.2  # P(not D)\n",
    "x_observed = 4  # Observed profit\n",
    "\n",
    "# P(X=4 | D) and P(X=4 | not D) using Gaussian pdf\n",
    "p_x_given_d = norm.pdf(x_observed, loc=mu_dividend, scale=sigma)\n",
    "p_x_given_not_d = norm.pdf(x_observed, loc=mu_no_dividend, scale=sigma)\n",
    "\n",
    "# P(X=4) using law of total probability\n",
    "p_x = p_x_given_d * prior_dividend + p_x_given_not_d * prior_no_dividend\n",
    "\n",
    "# P(D | X=4) using Bayes' theorem\n",
    "prob_dividend = (p_x_given_d * prior_dividend) / p_x\n",
    "# END SOLUTION\n",
    "\n",
    "print(f\"Probability of dividend given X=4: {prob_dividend:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert 0.75 < prob_dividend < 0.76, f\"Expected ~0.7519, got {prob_dividend}\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert (\n",
    "    abs(prob_dividend - 0.7518524532975261) < 1e-6\n",
    "), \"prob_dividend should be approximately 0.7519\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## LDA Decision Boundary\n",
    "\n",
    "Suppose you have one continuous predictor $X$ and a binary categorical response $Y$, which can take values 1 or 2. Suppose you collected training data from the two classes and obtained class-specific sample means $\\hat{\\mu}_1 = -1$ and $\\hat{\\mu}_2 = 3$, along with the pooled variance estimate over the two classes, $\\hat{\\sigma}^2 = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 5 (a):** Equal Priors\n",
    "\n",
    "Assume equal class priors and derive the LDA classification rule for this problem. Using `scipy.stats.norm.pdf` to compute the necessary probability density functions, show both of the estimated class-conditional densities in the same plot. Also show the estimated Bayes decision boundary in this plot. Make sure you label the axes.\n",
    "\n",
    "Let $c$ denote the position of the decision boundary. Store the numerical value of $c$ in a variable called `boundary_c`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot class-conditional densities and compute decision boundary\n",
    "# BEGIN SOLUTION\n",
    "# Parameters\n",
    "mu1, mu2 = -1, 3\n",
    "sigma = 1\n",
    "\n",
    "# Generate x values for plotting\n",
    "x_vals = np.linspace(-5, 7, 1000)\n",
    "\n",
    "# Class-conditional densities\n",
    "pdf_class1 = norm.pdf(x_vals, mu1, sigma)\n",
    "pdf_class2 = norm.pdf(x_vals, mu2, sigma)\n",
    "\n",
    "# Decision boundary with equal priors: midpoint between means\n",
    "boundary_c = (mu1 + mu2) / 2\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(x_vals, pdf_class1, label=\"Class 1 ($Y=1$)\")\n",
    "plt.plot(x_vals, pdf_class2, label=\"Class 2 ($Y=2$)\")\n",
    "plt.axvline(\n",
    "    x=boundary_c, color=\"red\", linestyle=\"--\", label=f\"Decision Boundary ($c={boundary_c}$)\"\n",
    ")\n",
    "plt.title(\"Class-Conditional Densities and Decision Boundary\")\n",
    "plt.xlabel(\"$X$\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# END SOLUTION\n",
    "\n",
    "print(f\"Decision boundary position: c = {boundary_c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert boundary_c == 1.0, f\"Expected boundary at 1.0, got {boundary_c}\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert boundary_c == (-1 + 3) / 2, \"boundary_c should be the midpoint of mu1 and mu2\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "**Problem 5 (b)** Unequal Priors (Conceptual)\n",
    "\n",
    "Suppose the estimates were obtained from 100 training points, among which 40 were from class 1 and 60 were from class 2. Suppose now you will estimate class priors from data.\n",
    "\n",
    "Without calculating the new boundary $\\hat{c}$, would you expect it to be the same as, less than, or greater than $c$? Explain your reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "The new boundary $\\hat{c}$ will be less than $c$.\n",
    "\n",
    "Since class 2 has a higher prior probability (0.6 vs 0.4), the decision boundary shifts toward the class with lower prior (class 1). This accounts for the higher likelihood of encountering class 2 samples, making it \"easier\" to classify a point as class 2 by expanding its decision region.\n",
    "\n",
    "Mathematically, the LDA decision boundary with priors is:\n",
    "$$c = \\frac{\\mu_1 + \\mu_2}{2} + \\frac{\\sigma^2}{\\mu_2 - \\mu_1}\\log\\left(\\frac{\\pi_1}{\\pi_2}\\right)$$\n",
    "\n",
    "Since $\\pi_1 < \\pi_2$, the log term is negative, shifting $c$ to the left (smaller).\n",
    "> END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "**Problem 5 (c)** Calculate Boundary with Unequal Priors\n",
    "\n",
    "Now calculate the new boundary value $\\hat{c}$ using the priors estimated from the data (40 from class 1, 60 from class 2). Store your answer in a variable called `boundary_c_hat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate boundary with unequal priors\n",
    "# BEGIN SOLUTION\n",
    "mu1, mu2 = -1, 3\n",
    "sigma_sq = 1\n",
    "prior_1, prior_2 = 0.4, 0.6\n",
    "\n",
    "# LDA decision boundary formula with priors\n",
    "boundary_c_hat = (mu1 + mu2) / 2 + (np.log(prior_1 / prior_2) * sigma_sq) / (mu2 - mu1)\n",
    "# END SOLUTION\n",
    "\n",
    "print(f\"New decision boundary: c_hat = {boundary_c_hat:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert 0.89 < boundary_c_hat < 0.91, f\"Expected ~0.899, got {boundary_c_hat}\"\n",
    "assert boundary_c_hat < 1.0, \"boundary_c_hat should be less than 1.0\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert (\n",
    "    abs(boundary_c_hat - 0.898633722972959) < 1e-6\n",
    "), \"boundary_c_hat should be approximately 0.8986\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "**Problem 5 (d)** LDA vs QDA Recommendation\n",
    "\n",
    "Suppose in addition to the pooled covariance value $\\hat{\\sigma}^2 = 1$, I now tell you the individual class-specific covariances were estimated as $\\hat{\\sigma}_1^2 = 0.25$ and $\\hat{\\sigma}_2^2 = 1.5$.\n",
    "\n",
    "Based on this new information, would you recommend using LDA or QDA, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "QDA should be used because the class-specific variances are substantially different ($\\hat{\\sigma}_1^2 = 0.25$ vs $\\hat{\\sigma}_2^2 = 1.5$). LDA assumes equal covariances across classes, which is violated here. QDA can model these different variances and will produce a quadratic decision boundary that better captures the true class structure.\n",
    "> END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "**Problem 5 (e)** QDA Decision Boundary\n",
    "\n",
    "Derive the QDA rule if $\\hat{\\sigma}_1^2 = 0.25$ and $\\hat{\\sigma}_2^2 = 1.5$, $\\hat{\\mu}_1 = -1$ and $\\hat{\\mu}_2 = 3$, assuming equal class priors. Calculate the numerical values for the decision boundary. Store the two boundary values in a list called `qda_boundaries` (sorted from smallest to largest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate QDA decision boundary\n",
    "# BEGIN SOLUTION\n",
    "# With equal priors, the decision boundary is where the discriminant functions are equal\n",
    "# delta_1(x) = delta_2(x), which means N(x; mu1, sigma1^2) = N(x; mu2, sigma2^2)\n",
    "\n",
    "x = symbols(\"x\")\n",
    "sigma1_sq = 0.25\n",
    "sigma2_sq = 1.5\n",
    "mu1, mu2 = -1, 3\n",
    "\n",
    "# Log discriminant functions (ignoring common constant terms)\n",
    "delta1 = -0.5 * np.log(2 * np.pi * sigma1_sq) - ((x - mu1) ** 2) / (2 * sigma1_sq)\n",
    "delta2 = -0.5 * np.log(2 * np.pi * sigma2_sq) - ((x - mu2) ** 2) / (2 * sigma2_sq)\n",
    "\n",
    "# Solve delta1 = delta2\n",
    "boundary_solutions = solve(delta1 - delta2, x)\n",
    "qda_boundaries = sorted([float(sol) for sol in boundary_solutions])\n",
    "# END SOLUTION\n",
    "\n",
    "print(f\"QDA decision boundaries: {qda_boundaries}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert len(qda_boundaries) == 2, \"Should have two boundary points\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert qda_boundaries[0] < 0, \"First boundary should be negative\"\n",
    "assert qda_boundaries[1] > 0, \"Second boundary should be positive\"\n",
    "assert abs(qda_boundaries[0] - (-3.892254248596096)) < 1e-4, \"First boundary incorrect\"\n",
    "assert abs(qda_boundaries[1] - 0.29225424859609667) < 1e-4, \"Second boundary incorrect\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## Stock Market Prediction\n",
    "\n",
    "The `Smarket` dataset consists of percentage returns for the S&P 500 stock index over 1,250 days, from the beginning of 2001 until the end of 2005. For each date, we have recorded the percentage returns for each of the five previous trading days (`Lag1` through `Lag5`), the trading `Volume` (in billions of shares) for the previous trading day, and the return and direction (Up or Down) of the market on the date in question (`Today` and `Direction`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Smarket data\n",
    "smarket = pd.read_csv(\"./data/Smarket.csv\")\n",
    "smarket.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 6 (a):** Exploratory Data Analysis\n",
    "\n",
    "Produce some numerical and graphical summaries of the `smarket` data. Do there appear to be any patterns? Create at least one visualization (e.g., boxplots comparing Up vs Down days)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory analysis of smarket data\n",
    "# BEGIN SOLUTION\n",
    "# Create side-by-side boxplots for each feature by Direction\n",
    "fig, axes = plt.subplots(2, 4, figsize=(14, 8))\n",
    "features = [\"Lag1\", \"Lag2\", \"Lag3\", \"Lag4\", \"Lag5\", \"Volume\", \"Today\"]\n",
    "\n",
    "for i, nm in enumerate(features):\n",
    "    ax = axes[i // 4, i % 4]\n",
    "    up_values = smarket.loc[smarket.Direction == \"Up\"][nm]\n",
    "    down_values = smarket.loc[smarket.Direction == \"Down\"][nm]\n",
    "    ax.boxplot([up_values, down_values])\n",
    "    ax.set_ylabel(nm)\n",
    "    ax.set_xticks([1, 2])\n",
    "    ax.set_xticklabels([\"Up\", \"Down\"])\n",
    "\n",
    "axes[1, 3].axis(\"off\")  # Hide empty subplot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "print(\"Interpretation:\")\n",
    "print(\"Based on the boxplots, there is very little visible difference between Up and Down\")\n",
    "print(\"days for the lag variables and volume. Only the Today variable shows a clear\")\n",
    "print(\"difference (which is expected since Direction is derived from Today). This suggests\")\n",
    "print(\"that the lag variables may not be strong predictors of Direction.\")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert True, \"Plot should be created above\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "# EDA problem - graded on effort and interpretation\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 6 (b):** LDA on Stock Market Data\n",
    "\n",
    "Fit an LDA model using training data from 2001 to 2004, with `Direction` as the response and `Lag1` and `Lag2` as predictors. Use the model to predict on the held-out test data (2005). Store the test accuracy in a variable called `lda_accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit LDA model and evaluate on test set\n",
    "# BEGIN SOLUTION\n",
    "# Split data by year\n",
    "train_smarket = smarket.loc[smarket[\"Year\"] <= 2004]\n",
    "test_smarket = smarket.loc[smarket[\"Year\"] > 2004]\n",
    "\n",
    "# Prepare features and labels\n",
    "x_train_sm = train_smarket[[\"Lag1\", \"Lag2\"]]\n",
    "y_train_sm = train_smarket[\"Direction\"]\n",
    "x_test_sm = test_smarket[[\"Lag1\", \"Lag2\"]]\n",
    "y_test_sm = test_smarket[\"Direction\"]\n",
    "\n",
    "# Fit LDA\n",
    "lda_smarket = LinearDiscriminantAnalysis().fit(x_train_sm, y_train_sm)\n",
    "y_pred_lda = lda_smarket.predict(x_test_sm)\n",
    "\n",
    "# Compute accuracy\n",
    "lda_accuracy = accuracy_score(y_test_sm, y_pred_lda)\n",
    "# END SOLUTION\n",
    "\n",
    "print(f\"LDA Test Accuracy: {lda_accuracy:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_sm, y_pred_lda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert 0.5 < lda_accuracy < 0.6, f\"Expected accuracy around 0.56, got {lda_accuracy}\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert abs(lda_accuracy - 0.5595238095238095) < 1e-6, \"LDA accuracy should be approximately 0.5595\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 6 (c):** QDA on Stock Market Data\n",
    "\n",
    "Repeat the analysis using QDA instead of LDA. Store the test accuracy in a variable called `qda_accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit QDA model and evaluate on test set\n",
    "# BEGIN SOLUTION\n",
    "qda_smarket = QuadraticDiscriminantAnalysis().fit(x_train_sm, y_train_sm)\n",
    "y_pred_qda = qda_smarket.predict(x_test_sm)\n",
    "qda_accuracy = accuracy_score(y_test_sm, y_pred_qda)\n",
    "# END SOLUTION\n",
    "\n",
    "print(f\"QDA Test Accuracy: {qda_accuracy:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_sm, y_pred_qda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert 0.59 < qda_accuracy < 0.61, f\"Expected accuracy around 0.60, got {qda_accuracy}\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert abs(qda_accuracy - 0.5992063492063492) < 1e-6, \"QDA accuracy should be approximately 0.5992\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "## Auto MPG Classification\n",
    "\n",
    "In this problem, you will develop a model to predict whether a given car will be classified as having high or low gas mileage based on the Auto dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Auto data\n",
    "auto_df = pd.read_csv(\"./data/auto_nonan.csv\", index_col=0).set_index(\"name\")\n",
    "auto_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 7 (a):** Create Binary Variable\n",
    "\n",
    "Create a binary variable `mpg01` that equals 1 if the value of `mpg` for that car is above 25, and 0 otherwise. Add this variable as a new column to your data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mpg01 column\n",
    "# BEGIN SOLUTION\n",
    "auto_df[\"mpg01\"] = np.where(auto_df[\"mpg\"] > 25, 1, 0)\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert \"mpg01\" in auto_df.columns, \"mpg01 column not found\"\n",
    "assert auto_df[\"mpg01\"].isin([0, 1]).all(), \"mpg01 should only contain 0 and 1\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert auto_df[\"mpg01\"].sum() == 156, \"Number of cars with mpg > 25 should be 156\"\n",
    "assert (auto_df[\"mpg01\"] == 0).sum() == 236, \"Number of cars with mpg <= 25 should be 236\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 7 (b):** Exploratory Analysis\n",
    "\n",
    "Make some exploratory plots to investigate the association between `mpg01` and other variables. Besides `mpg` itself, which four quantitative features do you think are most likely to be useful in predicting `mpg01`? Defend your argument with plots (e.g., side-by-side boxplots)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory analysis\n",
    "# BEGIN SOLUTION\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "features_to_plot = [\"displacement\", \"horsepower\", \"weight\", \"acceleration\", \"year\", \"cylinders\"]\n",
    "\n",
    "for i, nm in enumerate(features_to_plot):\n",
    "    ax = axes[i // 3, i % 3]\n",
    "    vals0 = auto_df.loc[auto_df.mpg01 == 0][nm]\n",
    "    vals1 = auto_df.loc[auto_df.mpg01 == 1][nm]\n",
    "    ax.boxplot([vals0, vals1])\n",
    "    ax.set_ylabel(nm)\n",
    "    ax.set_xticks([1, 2])\n",
    "    ax.set_xticklabels([\"mpg01=0\", \"mpg01=1\"])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "print(\"Based on the boxplots, the four most useful features for predicting mpg01 are:\")\n",
    "print(\"1. cylinders - Clear separation between low/high mpg cars\")\n",
    "print(\"2. displacement - Strong separation, low mpg cars have higher displacement\")\n",
    "print(\"3. horsepower - Clear difference, high mpg cars have lower horsepower\")\n",
    "print(\"4. weight - Strong predictor, lighter cars tend to have better mpg\")\n",
    "print()\n",
    "print(\"These features show the clearest separation between the two groups.\")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert True, \"Plot should be created above\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "# EDA problem - graded on effort and interpretation\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 7 (c):** Train/Test Split\n",
    "\n",
    "Split the data into training and test sets using `train_test_split` with:\n",
    "- `random_state=123`\n",
    "- `train_size=0.8`\n",
    "- `stratify` set to the values of `mpg01`\n",
    "\n",
    "Store the number of training samples where `mpg01` is 1 in a variable called `n_mpg01_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "# BEGIN SOLUTION\n",
    "# Use the four selected features\n",
    "features = [\"cylinders\", \"displacement\", \"horsepower\", \"weight\"]\n",
    "x_auto = auto_df[features]\n",
    "y_auto = auto_df[\"mpg01\"]\n",
    "\n",
    "x_train_auto, x_test_auto, y_train_auto, y_test_auto = train_test_split(\n",
    "    x_auto, y_auto, train_size=0.8, random_state=123, stratify=y_auto\n",
    ")\n",
    "\n",
    "n_mpg01_train = (y_train_auto == 1).sum()\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert n_mpg01_train == 125, f\"Expected 125, got {n_mpg01_train}\"\n",
    "assert len(x_train_auto) == 313, \"Training set should have 313 samples\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert len(x_test_auto) == 79, \"Test set should have 79 samples\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 7 (d):** LDA on Auto Data\n",
    "\n",
    "Fit an LDA model on the training data using the four selected features. Report the misclassification rate on both training and test data. Store the test misclassification rate in a variable called `lda_misclass_test`.\n",
    "\n",
    "Choose two of the four variables from part (b), and make a scatterplot of the training data points. Use different colors to indicate the true values of `mpg01` and different plotting symbols (e.g., `+` and `o`) to indicate predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit LDA model and create visualization\n",
    "# BEGIN SOLUTION\n",
    "lda_auto = LinearDiscriminantAnalysis().fit(x_train_auto, y_train_auto)\n",
    "y_train_pred_lda = lda_auto.predict(x_train_auto)\n",
    "y_test_pred_lda = lda_auto.predict(x_test_auto)\n",
    "\n",
    "lda_misclass_train = 1 - accuracy_score(y_train_auto, y_train_pred_lda)\n",
    "lda_misclass_test = 1 - accuracy_score(y_test_auto, y_test_pred_lda)\n",
    "\n",
    "# Scatterplot using weight and horsepower\n",
    "plt.figure(figsize=(8, 6))\n",
    "for true_val, pred_val, marker, color in [\n",
    "    (0, 0, \"o\", \"blue\"),\n",
    "    (0, 1, \"+\", \"blue\"),\n",
    "    (1, 0, \"o\", \"red\"),\n",
    "    (1, 1, \"+\", \"red\"),\n",
    "]:\n",
    "    mask = (y_train_auto == true_val) & (y_train_pred_lda == pred_val)\n",
    "    plt.scatter(\n",
    "        x_train_auto.loc[mask, \"weight\"],\n",
    "        x_train_auto.loc[mask, \"horsepower\"],\n",
    "        marker=marker,\n",
    "        c=color,\n",
    "        label=f\"True={true_val}, Pred={pred_val}\",\n",
    "        alpha=0.7,\n",
    "    )\n",
    "plt.xlabel(\"Weight\")\n",
    "plt.ylabel(\"Horsepower\")\n",
    "plt.title(\"LDA Classification\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert 0.1 < lda_misclass_test < 0.25, f\"Expected ~0.20, got {lda_misclass_test}\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert (\n",
    "    abs(lda_misclass_test - 0.20253164556962022) < 1e-6\n",
    "), \"LDA test misclass rate should be ~0.2025\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 7 (e):** QDA on Auto Data\n",
    "\n",
    "Repeat part (d) using QDA. Fit a QDA model on training data, calculate training and test misclassification rates, and make a scatterplot analogous to part (d) using the same two variables. Store the test misclassification rate in a variable called `qda_misclass_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit QDA model and create visualization\n",
    "# BEGIN SOLUTION\n",
    "qda_auto = QuadraticDiscriminantAnalysis().fit(x_train_auto, y_train_auto)\n",
    "y_train_pred_qda = qda_auto.predict(x_train_auto)\n",
    "y_test_pred_qda = qda_auto.predict(x_test_auto)\n",
    "\n",
    "qda_misclass_train = 1 - accuracy_score(y_train_auto, y_train_pred_qda)\n",
    "qda_misclass_test = 1 - accuracy_score(y_test_auto, y_test_pred_qda)\n",
    "\n",
    "# Scatterplot using weight and horsepower\n",
    "plt.figure(figsize=(8, 6))\n",
    "for true_val, pred_val, marker, color in [\n",
    "    (0, 0, \"o\", \"blue\"),\n",
    "    (0, 1, \"+\", \"blue\"),\n",
    "    (1, 0, \"o\", \"red\"),\n",
    "    (1, 1, \"+\", \"red\"),\n",
    "]:\n",
    "    mask = (y_train_auto == true_val) & (y_train_pred_qda == pred_val)\n",
    "    plt.scatter(\n",
    "        x_train_auto.loc[mask, \"weight\"],\n",
    "        x_train_auto.loc[mask, \"horsepower\"],\n",
    "        marker=marker,\n",
    "        c=color,\n",
    "        label=f\"True={true_val}, Pred={pred_val}\",\n",
    "        alpha=0.7,\n",
    "    )\n",
    "plt.xlabel(\"Weight\")\n",
    "plt.ylabel(\"Horsepower\")\n",
    "plt.title(\"QDA Classification\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert 0.15 < qda_misclass_test < 0.2, f\"Expected ~0.18, got {qda_misclass_test}\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert (\n",
    "    abs(qda_misclass_test - 0.17721518987341767) < 1e-6\n",
    "), \"QDA test misclass rate should be ~0.1772\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 7 (f):** Compare LDA and QDA\n",
    "\n",
    "Compare and contrast the performance of LDA and QDA. What do your results suggest about the class-specific covariances?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "QDA performs better than LDA on both training and test data (lower misclassification rates). This suggests that the class-specific covariances are not equal between the two groups (high vs low mpg cars). The assumption of equal covariances in LDA appears to be violated, making QDA's more flexible model a better fit for this data.\n",
    "> END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 7 (g):** Logistic Regression\n",
    "\n",
    "Repeat part (d) using logistic regression. Fit a logistic regression model on training data, calculate training and test misclassification rates, and make a scatterplot analogous to part (d) using the same two variables. Store the test misclassification rate in a variable called `logistic_misclass_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit logistic regression model and create visualization\n",
    "# BEGIN SOLUTION\n",
    "logistic_auto = LogisticRegression(max_iter=1000).fit(x_train_auto, y_train_auto)\n",
    "y_train_pred_log = logistic_auto.predict(x_train_auto)\n",
    "y_test_pred_log = logistic_auto.predict(x_test_auto)\n",
    "\n",
    "logistic_misclass_train = 1 - accuracy_score(y_train_auto, y_train_pred_log)\n",
    "logistic_misclass_test = 1 - accuracy_score(y_test_auto, y_test_pred_log)\n",
    "\n",
    "# Scatterplot using weight and horsepower\n",
    "plt.figure(figsize=(8, 6))\n",
    "for true_val, pred_val, marker, color in [\n",
    "    (0, 0, \"o\", \"blue\"),\n",
    "    (0, 1, \"+\", \"blue\"),\n",
    "    (1, 0, \"o\", \"red\"),\n",
    "    (1, 1, \"+\", \"red\"),\n",
    "]:\n",
    "    mask = (y_train_auto == true_val) & (y_train_pred_log == pred_val)\n",
    "    plt.scatter(\n",
    "        x_train_auto.loc[mask, \"weight\"],\n",
    "        x_train_auto.loc[mask, \"horsepower\"],\n",
    "        marker=marker,\n",
    "        c=color,\n",
    "        label=f\"True={true_val}, Pred={pred_val}\",\n",
    "        alpha=0.7,\n",
    "    )\n",
    "plt.xlabel(\"Weight\")\n",
    "plt.ylabel(\"Horsepower\")\n",
    "plt.title(\"Logistic Regression Classification\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert 0.1 < logistic_misclass_test < 0.2, f\"Expected ~0.15, got {logistic_misclass_test}\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert (\n",
    "    abs(logistic_misclass_test - 0.15189873417721522) < 1e-6\n",
    "), \"Logistic test misclass should be ~0.1519\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 7 (h):** Logistic Regression Probability Estimation\n",
    "\n",
    "Using your fitted logistic regression model, estimate the probability of a car having `mpg` above 25 if its values for the four predictors are all at the corresponding median values in the training dataset. Store this probability in a variable called `prob_median_logistic`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate probability at median predictor values\n",
    "# BEGIN SOLUTION\n",
    "median_values = x_train_auto.median().values.reshape(1, -1)\n",
    "prob_median_logistic = logistic_auto.predict_proba(median_values)[0, 1]\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert 0 <= prob_median_logistic <= 1, \"Probability should be between 0 and 1\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert 0.3 < prob_median_logistic < 0.5, f\"Expected ~0.4, got {prob_median_logistic}\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 7 (i):** K-Nearest Neighbors\n",
    "\n",
    "Fit KNN models for various values of K (from 1 to 35). Plot the training and test classification error vs K (or 1/K; if you use 1/K, make sure the x-axis is on the log scale). Which K gives the best performance on the training data? On the test data? Which K would you use? Store your chosen K in a variable called `best_k`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit KNN models for various K\n",
    "# BEGIN SOLUTION\n",
    "k_values = range(1, 36)\n",
    "train_errors_knn = []\n",
    "test_errors_knn = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(x_train_auto, y_train_auto)\n",
    "\n",
    "    y_train_pred_knn = knn.predict(x_train_auto)\n",
    "    y_test_pred_knn = knn.predict(x_test_auto)\n",
    "\n",
    "    train_errors_knn.append(1 - accuracy_score(y_train_auto, y_train_pred_knn))\n",
    "    test_errors_knn.append(1 - accuracy_score(y_test_auto, y_test_pred_knn))\n",
    "\n",
    "best_k = k_values[np.argmin(test_errors_knn)]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values, train_errors_knn, label=\"Training Error\")\n",
    "plt.plot(k_values, test_errors_knn, label=\"Test Error\")\n",
    "plt.xlabel(\"Number of Neighbors K\")\n",
    "plt.ylabel(\"Classification Error\")\n",
    "plt.title(\"KNN Classification Error vs. Number of Neighbors\")\n",
    "plt.legend()\n",
    "plt.gca().invert_xaxis()\n",
    "plt.show()\n",
    "# END SOLUTION\n",
    "\n",
    "print(f\"Best K based on test error: {best_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert 1 <= best_k <= 35, \"best_k should be between 1 and 35\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert best_k == 23, f\"Best K should be 23, got {best_k}\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 7 (j):** KNN Classification with Visualization\n",
    "\n",
    "Repeat part (d) using KNN with the number of neighbors chosen in part (i). Fit a KNN classification model on training data, calculate training and test misclassification rates, and make a scatterplot analogous to part (d) using the same two variables. Store the test misclassification rate in a variable called `knn_misclass_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit KNN model with best_k and create visualization\n",
    "# BEGIN SOLUTION\n",
    "knn_best = KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn_best.fit(x_train_auto, y_train_auto)\n",
    "\n",
    "y_train_pred_knn = knn_best.predict(x_train_auto)\n",
    "y_test_pred_knn = knn_best.predict(x_test_auto)\n",
    "\n",
    "knn_misclass_train = 1 - accuracy_score(y_train_auto, y_train_pred_knn)\n",
    "knn_misclass_test = 1 - accuracy_score(y_test_auto, y_test_pred_knn)\n",
    "\n",
    "# Scatterplot using weight and horsepower\n",
    "plt.figure(figsize=(8, 6))\n",
    "for true_val, pred_val, marker, color in [\n",
    "    (0, 0, \"o\", \"blue\"),\n",
    "    (0, 1, \"+\", \"blue\"),\n",
    "    (1, 0, \"o\", \"red\"),\n",
    "    (1, 1, \"+\", \"red\"),\n",
    "]:\n",
    "    mask = (y_train_auto == true_val) & (y_train_pred_knn == pred_val)\n",
    "    plt.scatter(\n",
    "        x_train_auto.loc[mask, \"weight\"],\n",
    "        x_train_auto.loc[mask, \"horsepower\"],\n",
    "        marker=marker,\n",
    "        c=color,\n",
    "        label=f\"True={true_val}, Pred={pred_val}\",\n",
    "        alpha=0.7,\n",
    "    )\n",
    "plt.xlabel(\"Weight\")\n",
    "plt.ylabel(\"Horsepower\")\n",
    "plt.title(f\"KNN (K={best_k}) Classification\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# END SOLUTION\n",
    "\n",
    "print(f\"KNN Training Misclassification Rate: {knn_misclass_train:.4f}\")\n",
    "print(f\"KNN Test Misclassification Rate: {knn_misclass_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert 0.1 < knn_misclass_test < 0.25, f\"Expected ~0.16, got {knn_misclass_test}\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert abs(knn_misclass_test - 0.16455696202531647) < 1e-6, \"KNN test misclass should be ~0.1646\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 7 (k):** KNN Probability Estimation\n",
    "\n",
    "Using your fitted KNN model, estimate the probability of a car having `mpg` above 25 if its values for the four predictors are all at the corresponding median values in the training dataset. Store this probability in a variable called `prob_median_knn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate probability at median predictor values using KNN\n",
    "# BEGIN SOLUTION\n",
    "median_values = x_train_auto.median().values.reshape(1, -1)\n",
    "prob_median_knn = knn_best.predict_proba(median_values)[0, 1]\n",
    "# END SOLUTION\n",
    "\n",
    "print(f\"Probability of mpg > 25 at median predictor values (KNN): {prob_median_knn:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert 0 <= prob_median_knn <= 1, \"Probability should be between 0 and 1\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert 0.3 < prob_median_knn < 0.6, f\"Expected probability around 0.4-0.5, got {prob_median_knn}\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Problem 7 (l):** Model Comparison Summary\n",
    "\n",
    "Compare and contrast the performance of LDA, QDA, logistic regression, and KNN on this dataset. What do your results suggest about the distribution of the data? About the nature of the boundary between classes? Defend your conclusions using your findings from earlier in this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {},
   "source": [
    "> BEGIN SOLUTION\n",
    "\n",
    "Test misclassification rates:\n",
    "- LDA: ~20.3%\n",
    "- QDA: ~17.7%\n",
    "- Logistic Regression: ~15.2%\n",
    "- KNN (K=23): ~16.5%\n",
    "\n",
    "Logistic regression performs best on this dataset, followed closely by KNN and QDA. LDA performs worst, which is consistent with our earlier observation that the class-specific covariances are unequal (QDA outperforms LDA).\n",
    "\n",
    "The relatively similar performance of logistic regression, QDA, and KNN suggests that the true decision boundary is relatively smooth but possibly nonlinear. The fact that QDA outperforms LDA indicates the class-conditional distributions have different covariance structures. The success of logistic regression suggests the log-odds boundary is approximately linear in the feature space, while KNN's good performance indicates local structure in the data is informative for classification.\n",
    "\n",
    "> END SOLUTION"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "winter2026assignments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
