{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "993827138bfe48d"
   },
   "source": [
    "# Baseline CNN models for Galaxy challenge - renormalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "id": "b239f155867739e6"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "id": "95f93e37de4e765c"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "plt.rcParams[\"axes.grid\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "id": "802898b41e996591"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "id": "a3aedee758ee02df"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "id": "9790593cf4b62afa"
   },
   "outputs": [],
   "source": [
    "sigma = 0.0125"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "id": "c22ee97b80115ef"
   },
   "source": [
    "Use normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "id": "3122113f0dd87bd4"
   },
   "outputs": [],
   "source": [
    "train_images, train_ns = torch.load(f\"../data/315/dataset_train_renorm_{sigma}.pt\")\n",
    "test_images, test_ns = torch.load(f\"../data/315/dataset_test_renorm_{sigma}.pt\")\n",
    "test_images_kaggle, test_ns_kaggle = torch.load(f\"../data/315/dataset_kaggle_renorm_{sigma}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "id": "cc7b69b2a35f96f4",
    "outputId": "48c1ed9a-0bd8-42ce-dd9d-1a80294d419a"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    train_images.shape,\n",
    "    train_ns.shape,\n",
    "    test_images.shape,\n",
    "    test_ns.shape,\n",
    "    test_images_kaggle.shape,\n",
    "    test_ns_kaggle.shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "id": "e5ffb073d0dc567a"
   },
   "outputs": [],
   "source": [
    "train_images = train_images.unsqueeze(1)\n",
    "test_images = test_images.unsqueeze(1)\n",
    "test_images_kaggle = test_images_kaggle.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "id": "d2e856e1e0ef77d5",
    "outputId": "0819a37f-a5d2-4002-88e1-abd5445d5607"
   },
   "outputs": [],
   "source": [
    "train_images.shape, train_ns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "id": "96f797787372f974"
   },
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(train_images, train_ns)\n",
    "test_dataset = TensorDataset(test_images, test_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "id": "d09b209338ed3437"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "id": "fcd6082dc9bddedc"
   },
   "outputs": [],
   "source": [
    "kaggle_dataset = TensorDataset(test_images_kaggle, test_ns_kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "id": "2a20b0b2c50617b"
   },
   "outputs": [],
   "source": [
    "# NOTE: don't shuffle for the kaggle dataset\n",
    "kaggle_loader = DataLoader(kaggle_dataset, batch_size=32, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {
    "id": "a765d19297581a83"
   },
   "source": [
    "## Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "id": "de80b2ed95876434",
    "outputId": "e33be37f-295d-4b5f-e741-14dc75592ae4"
   },
   "outputs": [],
   "source": [
    "i = torch.randint(1, 2500)\n",
    "plt.imshow(train_images[i].squeeze(), cmap=\"gray\")\n",
    "plt.title(f\"{train_ns[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "id": "670a3c1c0f36768b",
    "outputId": "102db484-4692-4c62-d2cd-f06f10fb0287"
   },
   "outputs": [],
   "source": [
    "i = torch.randint(1, 2500)\n",
    "plt.imshow(test_images[i].squeeze(), cmap=\"gray\")\n",
    "plt.title(f\"{test_ns[i]}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "id": "c2b878be-cd99-42a9-bdd0-bac8ad2c3e59",
    "outputId": "2123ddf6-d448-4629-a070-e265e584a04e"
   },
   "outputs": [],
   "source": [
    "i = torch.randint(1, 2500)\n",
    "plt.imshow(test_images_kaggle[i].squeeze(), cmap=\"gray\")\n",
    "plt.title(f\"{test_ns_kaggle[i]}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {
    "id": "38dac738585174a8"
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "id": "46b397fba48fbac9"
   },
   "outputs": [],
   "source": [
    "dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "id": "fc88e645d6922f18"
   },
   "outputs": [],
   "source": [
    "n_classes = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "id": "20a437af5177c839"
   },
   "outputs": [],
   "source": [
    "num_epochs = 40\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "id": "d8f398b84a0ca832"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, num_epochs, lr, model_save_path):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    pbar = tqdm(\n",
    "        total=num_epochs,\n",
    "        desc=f\"Epoch: 0/{num_epochs} | Train Loss: N/A | Test Loss: N/A\",\n",
    "    )\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        test_running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_running_loss += loss.item()\n",
    "\n",
    "        test_loss = test_running_loss / len(test_loader)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        pbar.set_description(\n",
    "            f\"Epoch: {epoch + 1}/{num_epochs} | Train Loss: {train_loss:.4f} \"\n",
    "            f\"| Test Loss: {test_loss:.4f}\"\n",
    "        )\n",
    "        pbar.update(1)\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            checkpoint_path = f\"{model_save_path}_epoch_{epoch + 1}.pth\"\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {
    "id": "c1be2f897236d6c8"
   },
   "source": [
    "# VGGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "id": "c6899fbf62d4de8b"
   },
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {
    "id": "261701e2025ece02"
   },
   "source": [
    "## VGG11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "id": "554681bcd6b81270"
   },
   "outputs": [],
   "source": [
    "def make_vgg11(device):\n",
    "    model = models.vgg11_bn(pretrained=False)\n",
    "\n",
    "    # Need the first conv layer to accept 1 channel instead of 3.\n",
    "    model.features[0] = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    model.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "    # Modify the classifier from CIFAR10\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(512, 256), nn.ReLU(inplace=True), nn.Dropout(0.5), nn.Linear(256, 7)\n",
    "    )\n",
    "\n",
    "    return model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "id": "4bc8227b9dd0a581"
   },
   "outputs": [],
   "source": [
    "model = make_vgg11(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "id": "c72c60c1ef6fd415",
    "outputId": "491c9540-91dd-499e-ce28-fd62050c92ae"
   },
   "outputs": [],
   "source": [
    "train_losses, test_losses = train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    num_epochs,\n",
    "    lr=1e-3,\n",
    "    model_save_path=f\"../res/models/galaxy_challenge/vgg11_renorm_{sigma}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {
    "id": "d691510dc5fd9d54",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## $\\sigma = 0.01$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "id": "57ae212a57023a17",
    "outputId": "559196f5-2578-4073-9a19-3b2b69ba02d0"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(test_losses, label=\"test\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "id": "167357bc21751010",
    "outputId": "1faa9182-9fa1-46c4-da8c-982bec5d7fdb"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "total_kaggle = 0\n",
    "correct_kaggle = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    for images, labels in kaggle_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_kaggle += labels.size(0)\n",
    "        correct_kaggle += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "print(f\"Kaggle Accuracy: {100 * correct_kaggle / total_kaggle:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "id": "ff48781f-5230-4717-a87b-a05efa8232a1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "id": "705214d2-5a1d-4d0f-9a04-a458a68ce3b9",
    "outputId": "6ef02846-3e6e-4270-bb9b-5838312927c1"
   },
   "outputs": [],
   "source": [
    "best_model = make_vgg11(device)\n",
    "best_model.load_state_dict(\n",
    "    torch.load(\n",
    "        f\"../res/models/galaxy_challenge/vgg11_{sigma}_epoch_10.pth\",\n",
    "        map_location=device,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "id": "c1b42fcb-2c56-44be-95d2-f8cc24df22b4"
   },
   "outputs": [],
   "source": [
    "best_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "total_kaggle = 0\n",
    "correct_kaggle = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = best_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    for images, labels in kaggle_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = best_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_kaggle += labels.size(0)\n",
    "        correct_kaggle += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "print(f\"Kaggle Accuracy: {100 * correct_kaggle / total_kaggle:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {
    "id": "c711ffa890805ae1"
   },
   "source": [
    "Generate a test submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {
    "id": "c673f183332e95cb"
   },
   "outputs": [],
   "source": [
    "best_model.eval()\n",
    "\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images in kaggle_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = best_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {
    "id": "1b17c40bddc2e0f5"
   },
   "outputs": [],
   "source": [
    "image_ids = [f\"{i}\" for i in range(test_ns_kaggle.shape[0])]\n",
    "prediction_df = pd.DataFrame({\"id\": image_ids, \"label\": predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {
    "id": "639598a990d650e0"
   },
   "outputs": [],
   "source": [
    "prediction_df.to_csv(f\"../data/315/kaggle/kaggle_{sigma}_test_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {
    "id": "75a709ea-61f8-4fbc-b738-57aa8de55631"
   },
   "source": [
    "## $\\sigma = 0.0125$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {
    "id": "7cea34d2-9b91-4b6b-9e85-06568d612269",
    "outputId": "51b74580-268c-488e-898a-37aa0c06d14f"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(test_losses, label=\"test\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {
    "id": "1134aa27-1706-4e01-ad16-d512068ca32a",
    "outputId": "fafe499c-698a-47eb-f10d-38bb4dc57842"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "total_kaggle = 0\n",
    "correct_kaggle = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    for images, labels in kaggle_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_kaggle += labels.size(0)\n",
    "        correct_kaggle += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "print(f\"Kaggle Accuracy: {100 * correct_kaggle / total_kaggle:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {
    "id": "21b7519a-5a7e-494c-8579-5e908a22fedb",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## $\\sigma = 0.015$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {
    "id": "74131b57-5b6b-41cc-bd0f-78e6cd8e58ad",
    "outputId": "05d4a02b-c8f5-40d6-b2be-729609744c90"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(test_losses, label=\"test\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {
    "id": "d8918517-f81d-491d-8dd9-c879aa9b3e13",
    "outputId": "c507559b-2123-473f-ec83-7b5f02c5466e"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "total_kaggle = 0\n",
    "correct_kaggle = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    for images, labels in kaggle_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_kaggle += labels.size(0)\n",
    "        correct_kaggle += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "print(f\"Kaggle Accuracy: {100 * correct_kaggle / total_kaggle:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {
    "id": "0b8ba1b2-6dcd-47fc-9d73-34b680e6f9a0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {
    "id": "90339ad1-3941-4fde-a21a-d18fc00b507e",
    "outputId": "22f0855d-4d93-4ab0-a616-fd53d0255a41"
   },
   "outputs": [],
   "source": [
    "best_model = make_vgg11(device)\n",
    "best_model.load_state_dict(\n",
    "    torch.load(\n",
    "        f\"../res/models/galaxy_challenge/vgg11_renorm_{sigma}_epoch_30.pth\",\n",
    "        map_location=device,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {
    "id": "7a98ca69-11a6-49da-bd80-7c7d9bfb668a",
    "outputId": "37097d1f-5556-415b-e0b2-4395b35cdaee"
   },
   "outputs": [],
   "source": [
    "best_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "total_kaggle = 0\n",
    "correct_kaggle = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = best_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    for images, labels in kaggle_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = best_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_kaggle += labels.size(0)\n",
    "        correct_kaggle += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "print(f\"Kaggle Accuracy: {100 * correct_kaggle / total_kaggle:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {
    "id": "10b529fb-79cc-49f9-941b-b4ecdf44d575",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## $\\sigma = 0.02$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {
    "id": "b27a2d8c-4d7d-4bc8-90ab-a024637e9997",
    "outputId": "9c1f6889-e6d2-4f3f-a88e-7faa6005bec5"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(test_losses, label=\"test\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {
    "id": "383c69d5-23a7-4c66-8071-a1f842b110c9",
    "outputId": "aa5749e5-8b5c-41eb-8dbb-24cfcd8e2ac8"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "total_kaggle = 0\n",
    "correct_kaggle = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    for images, labels in kaggle_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_kaggle += labels.size(0)\n",
    "        correct_kaggle += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "print(f\"Kaggle Accuracy: {100 * correct_kaggle / total_kaggle:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {
    "id": "3cd6d939-4a9b-44fe-b40d-e2f0d98f9195",
    "outputId": "9515404d-44dc-4ee2-b411-af06f020f810"
   },
   "outputs": [],
   "source": [
    "best_model = make_vgg11(device)\n",
    "best_model.load_state_dict(\n",
    "    torch.load(\n",
    "        f\"../res/models/galaxy_challenge/vgg11_renorm_{sigma}_epoch_20.pth\",\n",
    "        map_location=device,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {
    "id": "d00f7296-cd00-4d59-9508-2dd0b8fe18ae",
    "outputId": "57364cbb-313e-4815-bc6c-e7bec9a8532a"
   },
   "outputs": [],
   "source": [
    "best_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "total_kaggle = 0\n",
    "correct_kaggle = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = best_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    for images, labels in kaggle_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = best_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_kaggle += labels.size(0)\n",
    "        correct_kaggle += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "print(f\"Kaggle Accuracy: {100 * correct_kaggle / total_kaggle:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {
    "id": "3be070d8-36a9-4ad1-a26c-2895786e311a",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## $\\sigma = 0.1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {
    "id": "1d04ba00-9a5c-4540-b912-f8b97abb0df0",
    "outputId": "28a0f5de-5134-4e37-b994-7a3b4c546e03"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(test_losses, label=\"test\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {
    "id": "1cf09a80-bf91-4932-859d-ca147836444e",
    "outputId": "64a0ea72-742d-4b8c-fb0c-f7e0f9a94977"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "total_kaggle = 0\n",
    "correct_kaggle = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    for images, labels in kaggle_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_kaggle += labels.size(0)\n",
    "        correct_kaggle += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "print(f\"Kaggle Accuracy: {100 * correct_kaggle / total_kaggle:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {
    "id": "989c2ccb41a17a93"
   },
   "source": [
    "# ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {
    "id": "989f1b96680476c2"
   },
   "outputs": [],
   "source": [
    "class StarCounterCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Input shape: (batch_size, 1, 50, 50)\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=1, out_channels=16, kernel_size=3, padding=1\n",
    "        )  # (16, 50, 50)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)  # (16, 25, 25)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)  # (32, 25, 25)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)  # (32, 12, 12)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # (64, 12, 12)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)  # (64, 6, 6)\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * 6 * 6, 128)\n",
    "        self.fc2 = nn.Linear(128, 7)  # 7 output classes for 0-6 stars\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)  # flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {
    "id": "85b8158b5cd00d74"
   },
   "outputs": [],
   "source": [
    "model = StarCounterCNN()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {
    "id": "ce39b6dbb943711a",
    "outputId": "57db7b86-8a9c-4e0e-cf36-a768a060fd8c"
   },
   "outputs": [],
   "source": [
    "train_losses, test_losses = train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    num_epochs,\n",
    "    lr,\n",
    "    f\"../res/models/galaxy_challenge/cgpt_renorm_{sigma}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {
    "id": "6cd4814d-5d2a-49c5-8120-ac069bd3bb94",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## $\\sigma = 0.01$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {
    "id": "50d646987430793a",
    "outputId": "72258295-8f5f-44e0-c3b6-264776199a79"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(test_losses, label=\"test\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {
    "id": "f881d32712b965ed",
    "outputId": "5d60e012-e53a-4efe-9115-f62b87333280"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "total_kaggle = 0\n",
    "correct_kaggle = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    for images, labels in kaggle_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_kaggle += labels.size(0)\n",
    "        correct_kaggle += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "print(f\"Kaggle Accuracy: {100 * correct_kaggle / total_kaggle:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {
    "id": "7692e3d5-1fc7-4f66-9c79-b9672363bdc2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {
    "id": "9e56798b-5219-45e1-b424-b13f3b03bc20",
    "outputId": "e0d12f0e-6673-4982-faaa-26ea813acdcb"
   },
   "outputs": [],
   "source": [
    "best_model = StarCounterCNN().to(device)\n",
    "best_model.load_state_dict(\n",
    "    torch.load(f\"../res/models/galaxy_challenge/cgpt_{sigma}_epoch_20.pth\", map_location=device)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {
    "id": "9ac36405-346a-4190-a569-d3ae476db928"
   },
   "outputs": [],
   "source": [
    "best_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "total_kaggle = 0\n",
    "correct_kaggle = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = best_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    for images, labels in kaggle_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = best_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_kaggle += labels.size(0)\n",
    "        correct_kaggle += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "print(f\"Kaggle Accuracy: {100 * correct_kaggle / total_kaggle:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {
    "id": "ac322f23-6eac-4129-957e-665a18c3861a"
   },
   "source": [
    "## $\\sigma = 0.0125$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {
    "id": "3104fe78-c8b7-4f6a-aba2-47369c8130b3",
    "outputId": "3134857b-fe1a-4dcb-c2f3-fc9447b18347"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(test_losses, label=\"test\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {
    "id": "4cb80939-cfbe-40d3-94d8-76b4534f7eba",
    "outputId": "a31b12cf-c67a-484c-ecef-c22a3cdde13c"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "total_kaggle = 0\n",
    "correct_kaggle = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    for images, labels in kaggle_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_kaggle += labels.size(0)\n",
    "        correct_kaggle += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "print(f\"Kaggle Accuracy: {100 * correct_kaggle / total_kaggle:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70",
   "metadata": {
    "id": "c599cd49-6712-4444-9af7-d610808e3846",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## $\\sigma = 0.015$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {
    "id": "cda3c0b1-2b97-4362-8e6f-f4eecb3dc681",
    "outputId": "e7f708e6-daeb-4df9-bbb7-e1d4adb3f07b"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(test_losses, label=\"test\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {
    "id": "c7698443-4092-47dd-847a-bb2d2c218b56",
    "outputId": "fa3846f1-d48f-49e0-cfa6-c29feb32e797"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "total_kaggle = 0\n",
    "correct_kaggle = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    for images, labels in kaggle_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_kaggle += labels.size(0)\n",
    "        correct_kaggle += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "print(f\"Kaggle Accuracy: {100 * correct_kaggle / total_kaggle:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {
    "id": "214de8f6-941e-450e-9082-4ae5fc83bde9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {
    "id": "44b56f6f-dae7-402c-909f-d2f521273188",
    "outputId": "b4f6975a-ba96-4c90-8acf-121ac105b3a2"
   },
   "outputs": [],
   "source": [
    "best_model = StarCounterCNN().to(device)\n",
    "best_model.load_state_dict(\n",
    "    torch.load(\n",
    "        f\"../res/models/galaxy_challenge/cgpt_renorm_{sigma}_epoch_20.pth\",\n",
    "        map_location=device,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {
    "id": "f3600b63-1a0a-4ee2-bb37-2e22f09f489b"
   },
   "outputs": [],
   "source": [
    "best_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "total_kaggle = 0\n",
    "correct_kaggle = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = best_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    for images, labels in kaggle_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = best_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_kaggle += labels.size(0)\n",
    "        correct_kaggle += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "print(f\"Kaggle Accuracy: {100 * correct_kaggle / total_kaggle:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76",
   "metadata": {
    "id": "48416cb3-2c84-43a6-b304-197ad1d71996",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## $\\sigma = 0.02$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {
    "id": "040240fe-c029-4f42-ae48-271623afb4a9",
    "outputId": "80a9ef67-9a21-4906-f72a-265a4d804d44"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(test_losses, label=\"test\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {
    "id": "ccc35436-f6f1-4343-8797-d644de66f9e7",
    "outputId": "3fb292e0-a82d-4047-facc-9483197fdd50"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "total_kaggle = 0\n",
    "correct_kaggle = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    for images, labels in kaggle_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_kaggle += labels.size(0)\n",
    "        correct_kaggle += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "print(f\"Kaggle Accuracy: {100 * correct_kaggle / total_kaggle:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {
    "id": "b130e709-e92d-4ec2-9b1f-0c3aa54d4da7",
    "outputId": "cd37cb93-db54-481d-dcc0-3418fc73f237"
   },
   "outputs": [],
   "source": [
    "best_model = StarCounterCNN().to(device)\n",
    "best_model.load_state_dict(\n",
    "    torch.load(\n",
    "        f\"../res/models/galaxy_challenge/cgpt_renorm_{sigma}_epoch_20.pth\",\n",
    "        map_location=device,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {
    "id": "808a3109-ef2d-4527-bdd6-a83bce4b0232",
    "outputId": "efaac8cb-3c07-4ca2-dffb-bd2dc9868227"
   },
   "outputs": [],
   "source": [
    "best_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "total_kaggle = 0\n",
    "correct_kaggle = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = best_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    for images, labels in kaggle_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = best_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_kaggle += labels.size(0)\n",
    "        correct_kaggle += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "print(f\"Kaggle Accuracy: {100 * correct_kaggle / total_kaggle:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81",
   "metadata": {
    "id": "1caf5d83-f885-4f49-9df7-e3fd42203a6e",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## $\\sigma = 0.1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {
    "id": "71cfaf6f-6444-453f-9b37-2959884724e3",
    "outputId": "a8d79577-75a8-41b4-9744-24d8b17f68be"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(test_losses, label=\"test\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {
    "id": "19f66351-d3cf-491c-b2b9-c130a5361ba5",
    "outputId": "a99b68af-a964-43b3-977f-42b1aed65c2b"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "total_kaggle = 0\n",
    "correct_kaggle = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    for images, labels in kaggle_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_kaggle += labels.size(0)\n",
    "        correct_kaggle += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "print(f\"Kaggle Accuracy: {100 * correct_kaggle / total_kaggle:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84",
   "metadata": {
    "id": "f5be04040409ce37"
   },
   "source": [
    "# Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {
    "id": "e8e307177b240b5c"
   },
   "outputs": [],
   "source": [
    "class StarClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=7):  # 0 to 6 stars, so 7 classes\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Calculate the flattened size after max pooling\n",
    "        # Input size: 50x50\n",
    "        # After maxpool1: 25x25\n",
    "        # After maxpool2: 12x12 (or 13x13 depending on rounding)\n",
    "        # After maxpool3: 6x6 (or 7x7 depending on rounding)\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * 6 * 6, 128)  # adjust if necessary if 7x7 is used.\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.maxpool1(self.relu1(self.conv1(x)))\n",
    "        x = self.maxpool2(self.relu2(self.conv2(x)))\n",
    "        x = self.maxpool3(self.relu3(self.conv3(x)))\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.relu4(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# model = StarClassifier()\n",
    "# input_tensor = torch.randn(1, 1, 50, 50)  # Batch size 1, 1 channel (grayscale), 50x50 image\n",
    "# output = model(input_tensor)\n",
    "# print(output.shape) # Should be [1,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {
    "id": "39a10c540e36276a",
    "outputId": "4945047f-85ef-4895-ff13-ec4f6fd27eac"
   },
   "outputs": [],
   "source": [
    "model = StarClassifier()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {
    "id": "bf5f634ff4171738",
    "outputId": "b6d84f77-ca53-4b2e-f9de-7098c4311c5e"
   },
   "outputs": [],
   "source": [
    "train_losses, test_losses = train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    num_epochs,\n",
    "    lr,\n",
    "    f\"../res/models/galaxy_challenge/gemini_renorm_{sigma}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88",
   "metadata": {
    "id": "39b9e931bb82784d",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## $\\sigma = 0.01$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {
    "id": "bad6b629cf7cb2d6",
    "outputId": "11858ed8-124a-480c-943a-8bebb6d0c84a"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(test_losses, label=\"test\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {
    "id": "5f395f4038ef7e58",
    "outputId": "1b11e17e-d350-44fc-b633-8ede79c7681d"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "total_kaggle = 0\n",
    "correct_kaggle = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    for images, labels in kaggle_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_kaggle += labels.size(0)\n",
    "        correct_kaggle += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "print(f\"Kaggle Accuracy: {100 * correct_kaggle / total_kaggle:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {
    "id": "32eb8578-fc0d-4664-a04b-b9984c06fd3a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {
    "id": "a8e430a0-3824-4d6a-a79d-e8ac31f6dbcd",
    "outputId": "c9cef0e1-f61c-4846-f5cb-c8c4abc42a34"
   },
   "outputs": [],
   "source": [
    "best_model = StarClassifier().to(device)\n",
    "best_model.load_state_dict(\n",
    "    torch.load(\n",
    "        f\"../res/models/galaxy_challenge/gemini_{sigma}_epoch_10.pth\",\n",
    "        map_location=device,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {
    "id": "9efb7621-207b-4ed8-ba4f-9720b1bd9c40",
    "outputId": "3046c525-10fd-4daf-bab9-322120099c63"
   },
   "outputs": [],
   "source": [
    "best_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "total_kaggle = 0\n",
    "correct_kaggle = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = best_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    for images, labels in kaggle_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = best_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_kaggle += labels.size(0)\n",
    "        correct_kaggle += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "print(f\"Kaggle Accuracy: {100 * correct_kaggle / total_kaggle:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94",
   "metadata": {
    "id": "4c5c0da3-5794-4e72-b9e4-aeba07c2f005"
   },
   "source": [
    "## $\\sigma = 0.0125$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {
    "id": "4dd6704b-9f23-41a3-ac55-1db8541389cf",
    "outputId": "7a3d8fa5-ee22-48a6-df7d-c4fd9b4595ee"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(test_losses, label=\"test\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {
    "id": "5536f8b7-76a7-413c-a6a2-c762ee2ff626",
    "outputId": "47d7174a-c23f-4c9c-f3e1-2d15a19545f5"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "total_kaggle = 0\n",
    "correct_kaggle = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    for images, labels in kaggle_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_kaggle += labels.size(0)\n",
    "        correct_kaggle += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "print(f\"Kaggle Accuracy: {100 * correct_kaggle / total_kaggle:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97",
   "metadata": {
    "id": "db8ab664-8308-4799-a263-b71bdfbf43f1",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## $\\sigma = 0.015$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {
    "id": "7ed895c0-f3e3-4719-a7e3-a732d8422cd2",
    "outputId": "2ee0c5cf-a8a5-4555-843e-b6c3548c6017"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(test_losses, label=\"test\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {
    "id": "a966bc0c-aa7c-4ab8-997c-16cce20e7bea",
    "outputId": "421cbccc-51e4-4e49-ece9-8ee54171c1e7"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "total_kaggle = 0\n",
    "correct_kaggle = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    for images, labels in kaggle_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_kaggle += labels.size(0)\n",
    "        correct_kaggle += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "print(f\"Kaggle Accuracy: {100 * correct_kaggle / total_kaggle:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100",
   "metadata": {
    "id": "8209a803-7001-4cc9-bb5f-3ccb578e961c",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## $\\sigma = 0.02$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {
    "id": "9c5f4154-b3b3-4f21-83c7-3dfc083e8a99",
    "outputId": "de359833-02a8-4250-bdef-49b025262700"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(test_losses, label=\"test\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {
    "id": "90c7ad30-3f71-414b-bc58-efc9e2f5cd1e",
    "outputId": "968e95cb-fc09-437a-f093-0c3a63969bc5"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "total_kaggle = 0\n",
    "correct_kaggle = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    for images, labels in kaggle_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_kaggle += labels.size(0)\n",
    "        correct_kaggle += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "print(f\"Kaggle Accuracy: {100 * correct_kaggle / total_kaggle:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {
    "id": "995f1bc6-86f2-4e73-8309-91198cd98550"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {
    "id": "b43288ed-685b-4497-97c4-27ec1f1597d4",
    "outputId": "0f68a869-6405-4107-f6e7-6709268d46da"
   },
   "outputs": [],
   "source": [
    "best_model = StarClassifier().to(device)\n",
    "best_model.load_state_dict(\n",
    "    torch.load(\n",
    "        f\"../res/models/galaxy_challenge/gemini_renorm_{sigma}_epoch_10.pth\",\n",
    "        map_location=device,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {
    "id": "b3affc1d-1528-43d6-ad28-4eecd92cc518",
    "outputId": "e24c9866-cfaf-46fb-9c39-7f5209b0884d"
   },
   "outputs": [],
   "source": [
    "best_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "total_kaggle = 0\n",
    "correct_kaggle = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = best_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    for images, labels in kaggle_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = best_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_kaggle += labels.size(0)\n",
    "        correct_kaggle += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "print(f\"Kaggle Accuracy: {100 * correct_kaggle / total_kaggle:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106",
   "metadata": {
    "id": "ea7fd233-2eed-448f-8968-9d8afcd07642",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## $\\sigma = 0.1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107",
   "metadata": {
    "id": "5f43f70e-93e7-4eb4-bb10-89db00ec158f",
    "outputId": "5ae29fcb-19c1-462a-ef13-124b7bbd8be9"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(test_losses, label=\"test\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {
    "id": "d6bb4432-75fc-4b80-a021-a85db9187f9f",
    "outputId": "13bc07bd-3460-4bc6-f237-eedda1e49645"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "total_kaggle = 0\n",
    "correct_kaggle = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    for images, labels in kaggle_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_kaggle += labels.size(0)\n",
    "        correct_kaggle += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "print(f\"Kaggle Accuracy: {100 * correct_kaggle / total_kaggle:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {
    "id": "7b078944-2119-4666-935b-b7a5b2702e90"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv_diffengr",
   "language": "python",
   "name": ".venv_diffengr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
