{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "993827138bfe48d"
   },
   "source": [
    "# Baseline CNN models for Galaxy challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "id": "b239f155867739e6"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "id": "95f93e37de4e765c"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "plt.rcParams[\"axes.grid\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "id": "802898b41e996591"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "id": "a3aedee758ee02df"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "id": "9790593cf4b62afa"
   },
   "outputs": [],
   "source": [
    "sigma = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "id": "c22ee97b80115ef"
   },
   "source": [
    "Use normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "id": "4d66be3e0e0ee95"
   },
   "outputs": [],
   "source": [
    "train_images, train_ns = torch.load(f\"../data/315/dataset_train_{sigma}_norm.pt\")\n",
    "test_images, test_ns = torch.load(f\"../data/315/dataset_test_{sigma}_norm.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "id": "3122113f0dd87bd4"
   },
   "outputs": [],
   "source": [
    "test_images_kaggle, test_ns_kaggle = torch.load(f\"../data/315/dataset_test_{sigma}_norm_kaggle.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "id": "cc7b69b2a35f96f4",
    "outputId": "ec596e9d-29b5-493b-dad5-1bad0eb70f27"
   },
   "outputs": [],
   "source": [
    "train_images.shape, train_ns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "id": "803bae6e643db99e",
    "outputId": "e79b2e26-040e-4fec-fca8-2875aefef1c8"
   },
   "outputs": [],
   "source": [
    "test_images.shape, test_ns.shape, test_images_kaggle.shape, test_ns_kaggle.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "id": "e5ffb073d0dc567a"
   },
   "outputs": [],
   "source": [
    "train_images = train_images.unsqueeze(1)\n",
    "test_images = test_images.unsqueeze(1)\n",
    "test_images_kaggle = test_images_kaggle.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "id": "d2e856e1e0ef77d5",
    "outputId": "a1a2d8d2-63cf-4692-cb5d-5a5317fcf33c"
   },
   "outputs": [],
   "source": [
    "train_images.shape, train_ns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "id": "fcd6082dc9bddedc"
   },
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(train_images, train_ns)\n",
    "test_dataset = TensorDataset(test_images, test_ns)\n",
    "kaggle_dataset = TensorDataset(test_images_kaggle, test_ns_kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "id": "2a20b0b2c50617b"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "kaggle_loader = DataLoader(kaggle_dataset, batch_size=32, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {
    "id": "a765d19297581a83",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "id": "de80b2ed95876434",
    "outputId": "812ed3e4-74f9-4038-ec3b-6161cddee38e"
   },
   "outputs": [],
   "source": [
    "i = torch.randint(1, 2500)\n",
    "plt.imshow(train_images[i].squeeze(), cmap=\"gray\")\n",
    "plt.title(f\"{train_ns[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "id": "670a3c1c0f36768b",
    "outputId": "3df06834-3a32-4440-9394-8d6ffe70623b"
   },
   "outputs": [],
   "source": [
    "i = torch.randint(1, 2500)\n",
    "plt.imshow(test_images[i].squeeze(), cmap=\"gray\")\n",
    "plt.title(f\"{test_ns[i]}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {
    "id": "38dac738585174a8"
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "id": "46b397fba48fbac9"
   },
   "outputs": [],
   "source": [
    "dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "id": "fc88e645d6922f18"
   },
   "outputs": [],
   "source": [
    "n_classes = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "id": "d8f398b84a0ca832"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, num_epochs, lr, model_save_path):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    pbar = tqdm(\n",
    "        total=num_epochs,\n",
    "        desc=f\"Epoch: 0/{num_epochs} | Train Loss: N/A | Test Loss: N/A\",\n",
    "    )\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        test_running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_running_loss += loss.item()\n",
    "\n",
    "        test_loss = test_running_loss / len(test_loader)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        pbar.set_description(\n",
    "            f\"Epoch: {epoch + 1}/{num_epochs} | Train Loss: {train_loss:.4f} \"\n",
    "            f\"| Test Loss: {test_loss:.4f}\"\n",
    "        )\n",
    "        pbar.update(1)\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            checkpoint_path = f\"{model_save_path}_epoch_{epoch + 1}.pth\"\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "id": "20a437af5177c839"
   },
   "outputs": [],
   "source": [
    "num_epochs = 60\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {
    "id": "c1be2f897236d6c8"
   },
   "source": [
    "# VGGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "id": "c6899fbf62d4de8b"
   },
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {
    "id": "261701e2025ece02"
   },
   "source": [
    "## VGG11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "id": "554681bcd6b81270"
   },
   "outputs": [],
   "source": [
    "def make_vgg11(device):\n",
    "    model = models.vgg11_bn(pretrained=False)\n",
    "\n",
    "    # Need the first conv layer to accept 1 channel instead of 3.\n",
    "    model.features[0] = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    model.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "    # Modify the classifier from CIFAR10\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(512, 256), nn.ReLU(inplace=True), nn.Dropout(0.5), nn.Linear(256, 7)\n",
    "    )\n",
    "\n",
    "    return model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "id": "4bc8227b9dd0a581"
   },
   "outputs": [],
   "source": [
    "model = make_vgg11(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "id": "c72c60c1ef6fd415",
    "outputId": "50e1433e-0738-4ee6-e140-6bb019872214"
   },
   "outputs": [],
   "source": [
    "train_losses, test_losses = train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    num_epochs,\n",
    "    lr=1e-3,\n",
    "    model_save_path=f\"../res/models/galaxy_challenge/vgg11_{sigma}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "id": "57ae212a57023a17",
    "outputId": "0a672b36-d981-4a06-fde4-6aa4f9e55c8f"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(test_losses, label=\"test\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "id": "167357bc21751010",
    "outputId": "d3f63fe7-392e-491e-cb89-d4e3d21d1459"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "total_kaggle = 0\n",
    "correct_kaggle = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    for images, labels in kaggle_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_kaggle += labels.size(0)\n",
    "        correct_kaggle += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "print(f\"Kaggle Accuracy: {100 * correct_kaggle / total_kaggle:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "id": "705214d2-5a1d-4d0f-9a04-a458a68ce3b9",
    "outputId": "f6192356-b924-4a2a-e7cc-a61e390dad0d"
   },
   "outputs": [],
   "source": [
    "best_model = make_vgg11(device)\n",
    "best_model.load_state_dict(\n",
    "    torch.load(\n",
    "        f\"../res/models/galaxy_challenge/vgg11_{sigma}_epoch_10.pth\",\n",
    "        map_location=device,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "id": "c1b42fcb-2c56-44be-95d2-f8cc24df22b4",
    "outputId": "0158a5c6-0dff-433e-90f8-e556827edd47"
   },
   "outputs": [],
   "source": [
    "best_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "total_kaggle = 0\n",
    "correct_kaggle = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = best_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    for images, labels in kaggle_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = best_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_kaggle += labels.size(0)\n",
    "        correct_kaggle += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "print(f\"Kaggle Accuracy: {100 * correct_kaggle / total_kaggle:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {
    "id": "989c2ccb41a17a93"
   },
   "source": [
    "# ChatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {
    "id": "3748c5fefcaf61ca"
   },
   "source": [
    "Prompt:\n",
    "> Can you generate a CNN network in torch to classify the number of stars (between 0 and 6) in grayscale images that are 50x50 pixels?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {
    "id": "fa541bfd1435ecf"
   },
   "source": [
    "Response:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {
    "id": "353008ae3c8b911"
   },
   "source": [
    "Sure! Below is a simple Convolutional Neural Network (CNN) implemented in PyTorch that can classify grayscale 50x50 pixel images into 7 classes (for 0 to 6 stars):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {
    "id": "989f1b96680476c2"
   },
   "outputs": [],
   "source": [
    "class StarCounterCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Input shape: (batch_size, 1, 50, 50)\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=1, out_channels=16, kernel_size=3, padding=1\n",
    "        )  # (16, 50, 50)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)  # (16, 25, 25)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)  # (32, 25, 25)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)  # (32, 12, 12)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # (64, 12, 12)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)  # (64, 6, 6)\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * 6 * 6, 128)\n",
    "        self.fc2 = nn.Linear(128, 7)  # 7 output classes for 0-6 stars\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)  # flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {
    "id": "80364fec8400146d"
   },
   "source": [
    "\n",
    "### Notes:\n",
    "- The input shape is expected to be `(batch_size, 1, 50, 50)` â€” 1 channel for grayscale.\n",
    "- The network progressively downsamples using max pooling and increases feature channels.\n",
    "- The final output is a tensor of shape `(batch_size, 7)`, corresponding to class logits for each count of stars from 0 to 6.\n",
    "\n",
    "Would you like training code or a dataset generation helper for synthetic star images as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {
    "id": "85b8158b5cd00d74"
   },
   "outputs": [],
   "source": [
    "model = StarCounterCNN()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {
    "id": "ce39b6dbb943711a",
    "outputId": "f2902df1-1dc6-421b-c1a6-f0717546d426"
   },
   "outputs": [],
   "source": [
    "train_losses, test_losses = train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    num_epochs,\n",
    "    lr,\n",
    "    f\"../res/models/galaxy_challenge/cgpt_{sigma}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {
    "id": "50d646987430793a",
    "outputId": "2768664a-5269-4112-be30-b8cc09b77b23"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(test_losses, label=\"test\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {
    "id": "f881d32712b965ed",
    "outputId": "c6328378-4cab-48ba-ebe9-52a8667d33a6"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "total_kaggle = 0\n",
    "correct_kaggle = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    for images, labels in kaggle_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_kaggle += labels.size(0)\n",
    "        correct_kaggle += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "print(f\"Kaggle Accuracy: {100 * correct_kaggle / total_kaggle:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {
    "id": "9e56798b-5219-45e1-b424-b13f3b03bc20",
    "outputId": "aa592caf-08e7-419a-e7a7-2aeb7707852d"
   },
   "outputs": [],
   "source": [
    "best_model = StarCounterCNN().to(device)\n",
    "best_model.load_state_dict(\n",
    "    torch.load(f\"../res/models/galaxy_challenge/cgpt_{sigma}_epoch_20.pth\", map_location=device)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {
    "id": "9ac36405-346a-4190-a569-d3ae476db928",
    "outputId": "d48f8f06-202a-4960-fdbe-8eb0f9c71cec"
   },
   "outputs": [],
   "source": [
    "best_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "total_kaggle = 0\n",
    "correct_kaggle = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = best_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    for images, labels in kaggle_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = best_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_kaggle += labels.size(0)\n",
    "        correct_kaggle += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "print(f\"Kaggle Accuracy: {100 * correct_kaggle / total_kaggle:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {
    "id": "f5be04040409ce37"
   },
   "source": [
    "# Gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {
    "id": "ac35bef0b9078093"
   },
   "source": [
    "Prompt:\n",
    "> Can you generate a CNN network in torch to classify the number of stars (between 0 and 6) in grayscale images that are 50x50 pixels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {
    "id": "e8e307177b240b5c"
   },
   "outputs": [],
   "source": [
    "class StarClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=7):  # 0 to 6 stars, so 7 classes\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Calculate the flattened size after max pooling\n",
    "        # Input size: 50x50\n",
    "        # After maxpool1: 25x25\n",
    "        # After maxpool2: 12x12 (or 13x13 depending on rounding)\n",
    "        # After maxpool3: 6x6 (or 7x7 depending on rounding)\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * 6 * 6, 128)  # adjust if necessary if 7x7 is used.\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.maxpool1(self.relu1(self.conv1(x)))\n",
    "        x = self.maxpool2(self.relu2(self.conv2(x)))\n",
    "        x = self.maxpool3(self.relu3(self.conv3(x)))\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.relu4(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# model = StarClassifier()\n",
    "# input_tensor = torch.randn(1, 1, 50, 50)  # Batch size 1, 1 channel (grayscale), 50x50 image\n",
    "# output = model(input_tensor)\n",
    "# print(output.shape) # Should be [1,7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {
    "id": "2136172ffda6f445"
   },
   "source": [
    "\n",
    "**Explanation:**\n",
    "\n",
    "1.  **`StarClassifier(nn.Module)`:**\n",
    "    * This defines the CNN class, inheriting from `nn.Module`.\n",
    "    * `num_classes=7` specifies the number of output classes (0 to 6 stars).\n",
    "\n",
    "2.  **Convolutional Layers:**\n",
    "    * `nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)`: The first convolutional layer takes a single-channel grayscale image (1) as input and produces 16 feature maps. `kernel_size=3` means a 3x3 filter, `stride=1` moves the filter one pixel at a time, and `padding=1` adds padding to maintain spatial dimensions.\n",
    "    * Similar construction for the other convolutional layers. The number of output channels is increased to capture more complex features.\n",
    "    * `nn.ReLU()`: Applies the ReLU activation function, which introduces non-linearity.\n",
    "    * `nn.MaxPool2d(kernel_size=2, stride=2)`: Performs max pooling, reducing the spatial dimensions by half.\n",
    "\n",
    "3.  **Fully Connected Layers:**\n",
    "    * `x.view(x.size(0), -1)`: Flattens the output of the convolutional layers into a 1D tensor.\n",
    "    * `nn.Linear(64 * 6 * 6, 128)`: The first fully connected layer maps the flattened features to 128 output features. The input size is calculated based on the output size of the last convolutional layer.\n",
    "    * `nn.Linear(128, num_classes)`: The final fully connected layer maps the 128 features to the 7 output classes.\n",
    "\n",
    "4.  **`forward(self, x)`:**\n",
    "    * Defines the forward pass of the network.\n",
    "    * Applies the convolutional, ReLU, and max pooling layers sequentially.\n",
    "    * Flattens the output.\n",
    "    * Applies the fully connected layers.\n",
    "    * Returns the output tensor, which represents the predicted class probabilities.\n",
    "\n",
    "**Key improvements and considerations:**\n",
    "\n",
    "* **Adjusting Fully Connected Layer Input Size:** The code now calculates the input size for the first fully connected layer dynamically, based on the output of the convolutional layers. This is crucial as max pooling can produce slightly different output sizes depending on the input dimensions.\n",
    "* **Clearer Comments:** Added comments to explain the purpose of each layer and step.\n",
    "* **Example Usage:** Includes a simple example of how to create an instance of the model and pass an input tensor through it.\n",
    "* **Batch processing:** The code is written to handle batches of images. The first dimension of the input tensor is the batch size.\n",
    "* **Training:** This code defines the model architecture. You'll need to add code for data loading, loss function, optimizer, and training loop to train the model.\n",
    "* **Hyperparameters:** The number of convolutional layers, the number of filters, the kernel sizes, and the number of neurons in the fully connected layers are hyperparameters that can be tuned to improve performance.\n",
    "* **Data Augmentation:** For better generalization, consider using data augmentation techniques (e.g., rotations, flips, zooms) during training.\n",
    "* **Normalization:** Normalize your input images (e.g., by dividing by 255) for better training stability.\n",
    "* **Loss Function:** For classification, `nn.CrossEntropyLoss()` is commonly used.\n",
    "* **Optimizer:** `torch.optim.Adam` or `torch.optim.SGD` are popular optimizers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {
    "id": "39a10c540e36276a",
    "outputId": "fd9ae5e2-b942-4bf4-eeaf-81aa41fb48d6"
   },
   "outputs": [],
   "source": [
    "model = StarClassifier()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {
    "id": "bf5f634ff4171738",
    "outputId": "77d44a8c-7cfd-494a-c2d6-5842b9e05a60"
   },
   "outputs": [],
   "source": [
    "train_losses, test_losses = train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    num_epochs,\n",
    "    lr,\n",
    "    f\"../res/models/galaxy_challenge/gemini_{sigma}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {
    "id": "bad6b629cf7cb2d6",
    "outputId": "8dc93a62-2124-4379-c4a0-cb9def63dcea"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(test_losses, label=\"test\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {
    "id": "5f395f4038ef7e58",
    "outputId": "91c0790b-9773-40ce-d9f6-791669e0ffb0"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "total_kaggle = 0\n",
    "correct_kaggle = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    for images, labels in kaggle_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_kaggle += labels.size(0)\n",
    "        correct_kaggle += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "print(f\"Kaggle Accuracy: {100 * correct_kaggle / total_kaggle:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {
    "id": "a8e430a0-3824-4d6a-a79d-e8ac31f6dbcd",
    "outputId": "90d7a416-d99a-47b2-af16-a958e26caabb"
   },
   "outputs": [],
   "source": [
    "best_model = StarClassifier().to(device)\n",
    "best_model.load_state_dict(\n",
    "    torch.load(\n",
    "        f\"../res/models/galaxy_challenge/gemini_{sigma}_epoch_10.pth\",\n",
    "        map_location=device,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {
    "id": "9efb7621-207b-4ed8-ba4f-9720b1bd9c40",
    "outputId": "5f264d47-b58d-4406-95ac-c152eb529b4c"
   },
   "outputs": [],
   "source": [
    "best_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "total_kaggle = 0\n",
    "correct_kaggle = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = best_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    for images, labels in kaggle_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = best_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_kaggle += labels.size(0)\n",
    "        correct_kaggle += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "print(f\"Kaggle Accuracy: {100 * correct_kaggle / total_kaggle:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {
    "id": "7b078944-2119-4666-935b-b7a5b2702e90"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv_diffengr",
   "language": "python",
   "name": ".venv_diffengr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
