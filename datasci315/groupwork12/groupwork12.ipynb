{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XuXWJLEm2UWS"
   },
   "source": [
    "# DATASCI 315, Group Work 12: Los Angeles Traffic Prediction with Graph Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GxG3DeP7HVLn"
   },
   "source": [
    "In this assignment, we'll use a graph neural network to perform traffic speed forecasting. Specifically, our goal is to predict the future speeds of vehicles on different road segments based on past traffic data collected from sensors. The model takes historical traffic speed observations from multiple locations over a period of time and infers the expected traffic speeds at those locations for upcoming time intervals (e.g., 15, 30, or 45 minutes ahead). This is a spatiotemporal prediction problem, as it requires understanding both how traffic changes over time and how it propagates through the road network. The predicted speeds can be used to improve traffic management, route planning, and overall efficiency in intelligent transportation systems.\n",
    "\n",
    "**Dataset:** The LA traffic dataset we will analyze for this assignment was collected by the California Department of Transportation from 228 sensor stations across District 7 (Los Angeles area). Traffic speed data was recorded every 5 minutes on weekdays between May 1 and June 30, 2012. Each station produced 288 readings per day. The dataset captures both spatial and temporal aspects of traffic by representing the network as a graph where nodes are road sensors and edges reflect proximity.\n",
    "\n",
    "**Method:** In this assignment you will use a graph neural network (GNN) called Spatial-Temporal Graph Attention Network (ST-GAT) to model traffic speed prediction. This GNN combines a Graph Attention Network (GAT) with a Long Short-Term Memory (LSTM) network to capture both spatial and temporal dependencies in the traffic data. The GAT component uses a multi-head attention mechanism to dynamically learn the importance of each road segment's connections, enabling the model to identify which nearby segments most influence traffic flow. To prepare the data for this structure, a \"Speed2Vec\" method is introduced to convert time-series speed readings into node features. These features are then passed through the GAT to capture spatial relationships and through the LSTM to model how traffic evolves over time. This hybrid architecture allows the model to make accurate traffic forecasts by leveraging both dynamic spatial interactions and sequential temporal patterns.\n",
    "\n",
    "**Reference:** This dataset and method are introduced in \"Spatial-Temporal Graph Attention Networks: A Deep Learning Approach for Traffic Forecasting\" by Zhang, Lu, and Liu (2019).\n",
    "\n",
    "**Instructions:** For this task, it would be helpful to select GPU as the runtime.\n",
    "\n",
    "We will go through the following steps:\n",
    "\n",
    "1. Installation and Setup\n",
    "2. Creating a DataLoader\n",
    "3. Constructing the Model\n",
    "4. Developing Training and Evaluation Functions\n",
    "5. Training the Model\n",
    "6. Testing the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67gOQITlCNQi"
   },
   "source": [
    "## Installation and setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MSaetj53YnT6"
   },
   "source": [
    "Confirm that you are on a GPU.\n",
    "This should print `cuda`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3248,
     "status": "ok",
     "timestamp": 1744742728617,
     "user": {
      "displayName": "Hanbin Lee",
      "userId": "14741986745160964413"
     },
     "user_tz": 240
    },
    "id": "OraOHb9w5-o_",
    "outputId": "f92897da-18ee-4ba1-d81c-2f4666256ee8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ok7A5EQM6VEU"
   },
   "source": [
    "The traffic dataset is stored in the `data/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2187,
     "status": "ok",
     "timestamp": 1744742739474,
     "user": {
      "displayName": "Hanbin Lee",
      "userId": "14741986745160964413"
     },
     "user_tz": 240
    },
    "id": "PRfgbfTjCRD_",
    "outputId": "30b039d4-1357-441d-a5e4-2c35a8adebe1"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqOWp_S591MB"
   },
   "source": [
    "## Creating a Dataloader\n",
    "Now, we create a dataloader which will process data from `.csv` files into a PyTorch Geometric dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TEKy_v5EFPMt"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from shutil import copyfile\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data, InMemoryDataset\n",
    "\n",
    "\n",
    "def distance_to_weight(distance_matrix, sigma2=0.1, epsilon=0.5, *, gat_version=False):\n",
    "    \"\"\"\n",
    "    Given distances between all nodes, convert into a weight matrix.\n",
    "\n",
    "    :param distance_matrix: Matrix of distances between nodes\n",
    "    :param sigma2: User configurable parameter to adjust sparsity of matrix\n",
    "    :param epsilon: User configurable parameter to adjust sparsity of matrix\n",
    "    :param gat_version: If true, use 0/1 weights with self loops. Otherwise, use float\n",
    "    :return: Adjacency weight matrix\n",
    "    \"\"\"\n",
    "    num_nodes = distance_matrix.shape[0]\n",
    "    normalized_distances = distance_matrix / 10000.0\n",
    "    squared_distances = normalized_distances * normalized_distances\n",
    "    non_self_mask = torch.ones([num_nodes, num_nodes]) - torch.eye(num_nodes)\n",
    "\n",
    "    # Compute weights using Gaussian kernel (refer to Eq.10 in paper)\n",
    "    adjacency_weights = (\n",
    "        torch.exp(-squared_distances / sigma2)\n",
    "        * (torch.exp(-squared_distances / sigma2) >= epsilon)\n",
    "        * non_self_mask\n",
    "    )\n",
    "\n",
    "    # If using the GAT version, round to 0/1 and include self loops\n",
    "    if gat_version:\n",
    "        adjacency_weights[adjacency_weights > 0] = 1\n",
    "        adjacency_weights += torch.eye(num_nodes)\n",
    "\n",
    "    return adjacency_weights\n",
    "\n",
    "\n",
    "class TrafficDataset(InMemoryDataset):\n",
    "    \"\"\"Dataset for Graph Neural Networks.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "        adjacency_weights,\n",
    "        root=\"\",\n",
    "        transform=None,\n",
    "        pre_transform=None,\n",
    "    ):\n",
    "        self.config = config\n",
    "        self.adjacency_weights = adjacency_weights\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices, self.n_node, self.mean, self.std_dev = torch.load(\n",
    "            self.processed_paths[0], weights_only=False\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return [str(Path(self.raw_dir) / \"PeMSD7_V_228.csv\")]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [\"./data.pt\"]\n",
    "\n",
    "    def download(self):\n",
    "        copyfile(\n",
    "            DATA_DIR / \"PeMSD7_V_228.csv\",\n",
    "            str(Path(self.raw_dir) / \"PeMSD7_V_228.csv\"),\n",
    "        )\n",
    "\n",
    "    def process(self):\n",
    "        \"\"\"Process the raw datasets into saved .pt dataset for later use.\n",
    "\n",
    "        Note that any self.fields here wont exist if loading from the .pt file.\n",
    "        \"\"\"\n",
    "        # Data Preprocessing and loading\n",
    "        data = pd.read_csv(self.raw_file_names[0], header=None).values\n",
    "        # Technically using the validation and test datasets here, but it's fine\n",
    "        # Would normally get the mean and std_dev from a large dataset\n",
    "        mean = torch.mean(data)\n",
    "        std_dev = torch.std(data)\n",
    "        data = z_score(data, torch.mean(data), torch.std(data))\n",
    "\n",
    "        _, n_node = data.shape\n",
    "        n_window = self.config[\"N_PRED\"] + self.config[\"N_HIST\"]\n",
    "\n",
    "        # Manipulate nxn matrix into 2 x num_edges format\n",
    "        edge_index = torch.zeros((2, n_node**2), dtype=torch.long)\n",
    "        # Create an edge_attr matrix with our weights (num_edges x 1)\n",
    "        edge_attr = torch.zeros((n_node**2, 1))\n",
    "        num_edges = 0\n",
    "        for i in range(n_node):\n",
    "            for j in range(n_node):\n",
    "                if self.adjacency_weights[i, j] != 0.0:\n",
    "                    edge_index[0, num_edges] = i\n",
    "                    edge_index[1, num_edges] = j\n",
    "                    edge_attr[num_edges] = self.adjacency_weights[i, j]\n",
    "                    num_edges += 1\n",
    "        # Keep only the first num_edges entries\n",
    "        edge_index = edge_index[:, :num_edges]\n",
    "        edge_attr = edge_attr[:num_edges, :]\n",
    "\n",
    "        sequences = []\n",
    "        # T x F x N\n",
    "        for day_idx in range(self.config[\"N_DAYS\"]):\n",
    "            for slot_idx in range(self.config[\"N_SLOT\"]):\n",
    "                # For each time point construct a different graph with Data object\n",
    "                graph = Data()\n",
    "                graph.__num_nodes__ = n_node\n",
    "\n",
    "                graph.edge_index = edge_index\n",
    "                graph.edge_attr = edge_attr\n",
    "\n",
    "                # (F,N) switched to (N,F)\n",
    "                start_idx = day_idx * self.config[\"N_DAY_SLOT\"] + slot_idx\n",
    "                end_idx = start_idx + n_window\n",
    "                # [21, 228]\n",
    "                full_window = torch.swapaxes(data[start_idx:end_idx, :], 0, 1)\n",
    "                graph.x = torch.FloatTensor(full_window[:, 0 : self.config[\"N_HIST\"]])\n",
    "                graph.y = torch.FloatTensor(full_window[:, self.config[\"N_HIST\"] : :])\n",
    "                sequences += [graph]\n",
    "\n",
    "        # Make the actual dataset\n",
    "        data, slices = self.collate(sequences)\n",
    "        torch.save((data, slices, n_node, mean, std_dev), self.processed_paths[0])\n",
    "\n",
    "\n",
    "def get_splits(dataset: TrafficDataset, n_slot, splits):\n",
    "    \"\"\"Split data into train, val, and test subsets.\n",
    "\n",
    "    :param dataset: TrafficDataset object to split\n",
    "    :param n_slot: Number of possible sliding windows in a day\n",
    "    :param splits: (train, val, test) ratios\n",
    "    \"\"\"\n",
    "    split_train, split_val, _ = splits\n",
    "    i = n_slot * split_train\n",
    "    j = n_slot * split_val\n",
    "    train = dataset[:i]\n",
    "    val = dataset[i : i + j]\n",
    "    test = dataset[i + j :]\n",
    "\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZoXlf4MtYrbz"
   },
   "source": [
    "## Build the Model\n",
    "\n",
    "Using PyG's built-in layers, create a Spatio-Temporal Graph as presented in https://ieeexplore.ieee.org/document/8903252.\n",
    "\n",
    "This model is a PyTorch model containing an initialization function for setting up the model architecture and a forward function for performing a forward pass of data through the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B7jt96q77EZF"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional\n",
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "\n",
    "class StGat(torch.nn.Module):\n",
    "    \"\"\"Spatio-Temporal Graph Attention Network.\n",
    "\n",
    "    As presented in https://ieeexplore.ieee.org/document/8903252\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, n_nodes, heads=8, dropout=0.0):\n",
    "        \"\"\"Initialize the ST-GAT model.\n",
    "\n",
    "        :param in_channels: Number of input channels\n",
    "        :param out_channels: Number of output channels\n",
    "        :param n_nodes: Number of nodes in the graph\n",
    "        :param heads: Number of attention heads to use in graph\n",
    "        :param dropout: Dropout probability on output of Graph Attention Network\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.n_pred = out_channels\n",
    "        self.heads = heads\n",
    "        self.dropout = dropout\n",
    "        self.n_nodes = n_nodes\n",
    "\n",
    "        lstm1_hidden_size = 32\n",
    "        lstm2_hidden_size = 128\n",
    "\n",
    "        # Single graph attentional layer with 8 attention heads\n",
    "        self.gat = GATConv(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=in_channels,\n",
    "            heads=heads,\n",
    "            dropout=0,\n",
    "            concat=False,\n",
    "        )\n",
    "\n",
    "        # Add two LSTM layers\n",
    "        self.lstm1 = torch.nn.LSTM(\n",
    "            input_size=self.n_nodes,\n",
    "            hidden_size=lstm1_hidden_size,\n",
    "            num_layers=1,\n",
    "        )\n",
    "        for name, param in self.lstm1.named_parameters():\n",
    "            if \"bias\" in name:\n",
    "                torch.nn.init.constant_(param, 0.0)\n",
    "            elif \"weight\" in name:\n",
    "                torch.nn.init.xavier_uniform_(param)\n",
    "        self.lstm2 = torch.nn.LSTM(\n",
    "            input_size=lstm1_hidden_size,\n",
    "            hidden_size=lstm2_hidden_size,\n",
    "            num_layers=1,\n",
    "        )\n",
    "        for name, param in self.lstm2.named_parameters():\n",
    "            if \"bias\" in name:\n",
    "                torch.nn.init.constant_(param, 0.0)\n",
    "            elif \"weight\" in name:\n",
    "                torch.nn.init.xavier_uniform_(param)\n",
    "\n",
    "        # Fully-connected neural network\n",
    "        self.linear = torch.nn.Linear(lstm2_hidden_size, self.n_nodes * self.n_pred)\n",
    "        torch.nn.init.xavier_uniform_(self.linear.weight)\n",
    "\n",
    "    def forward(self, data, device):\n",
    "        \"\"\"Forward pass of the ST-GAT model.\n",
    "\n",
    "        :param data: Data to make a pass on\n",
    "        :param device: Device to operate on\n",
    "        \"\"\"\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        # Apply dropout\n",
    "        x = torch.FloatTensor(x) if device == \"cpu\" else torch.cuda.FloatTensor(x)\n",
    "\n",
    "        # GAT layer: output of gat: [11400, 12]\n",
    "        x = self.gat(x, edge_index)\n",
    "        x = functional.dropout(x, self.dropout, training=self.training)\n",
    "\n",
    "        # RNN: 2 LSTM\n",
    "        # [batchsize*n_nodes, seq_length] -> [batch_size, n_nodes, seq_length]\n",
    "        batch_size = data.num_graphs\n",
    "        n_node = int(data.num_nodes / batch_size)\n",
    "        x = torch.reshape(x, (batch_size, n_node, data.num_features))\n",
    "        # For lstm: x should be (seq_length, batch_size, n_nodes)\n",
    "        # sequence length = 12, batch_size = 50, n_node = 228\n",
    "        x = torch.movedim(x, 2, 0)\n",
    "        # [12, 50, 228] -> [12, 50, 32]\n",
    "        x, _ = self.lstm1(x)\n",
    "        # [12, 50, 32] -> [12, 50, 128]\n",
    "        x, _ = self.lstm2(x)\n",
    "\n",
    "        # Output contains h_t for each timestep, only the last one has all inputs\n",
    "        # [12, 50, 128] -> [50, 128]\n",
    "        x = torch.squeeze(x[-1, :, :])\n",
    "        # [50, 128] -> [50, 228*9]\n",
    "        x = self.linear(x)\n",
    "\n",
    "        # Now reshape into final output\n",
    "        s = x.shape\n",
    "        # [50, 228*9] -> [50, 228, 9]\n",
    "        x = torch.reshape(x, (s[0], self.n_nodes, self.n_pred))\n",
    "        # [50, 228, 9] ->  [11400, 9]\n",
    "        return torch.reshape(x, (s[0] * self.n_nodes, self.n_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W42pHHlz7GUv"
   },
   "source": [
    "## Create Train and Evaluation Functions\n",
    "\n",
    "Create a train function which performs a forward and a backward pass using the model.\n",
    "\n",
    "Create an evaluation function which performs only a forward pass using the model.\n",
    "\n",
    "These functions will be used in various stages of overall model training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mcifitQO7uag"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_model(model, device, dataloader, eval_type=\"\"):\n",
    "    \"\"\"Evaluate model on data.\n",
    "\n",
    "    :param model: Model to evaluate\n",
    "    :param device: Device to evaluate on\n",
    "    :param dataloader: Data loader\n",
    "    :param eval_type: Name of evaluation type, e.g. Train/Val/Test\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    mae = 0\n",
    "    rmse = 0\n",
    "    mape = 0\n",
    "    n = 0\n",
    "\n",
    "    # Evaluate model on all data\n",
    "    for i, raw_batch in enumerate(dataloader):\n",
    "        current_batch = raw_batch.to(device)\n",
    "        if current_batch.x.shape[0] == 1:\n",
    "            pass\n",
    "        else:\n",
    "            pred = model(current_batch, device)\n",
    "            truth = current_batch.y.view(pred.shape)\n",
    "            if i == 0:\n",
    "                y_pred = torch.zeros(len(dataloader), pred.shape[0], pred.shape[1])\n",
    "                y_truth = torch.zeros(len(dataloader), pred.shape[0], pred.shape[1])\n",
    "            truth = un_z_score(truth, dataloader.dataset.mean, dataloader.dataset.std_dev)\n",
    "            pred = un_z_score(pred, dataloader.dataset.mean, dataloader.dataset.std_dev)\n",
    "            y_pred[i, : pred.shape[0], :] = pred\n",
    "            y_truth[i, : pred.shape[0], :] = truth\n",
    "            rmse += calc_rmse(truth, pred)\n",
    "            mae += calc_mae(truth, pred)\n",
    "            mape += calc_mape(truth, pred)\n",
    "            n += 1\n",
    "    rmse, mae, mape = rmse / n, mae / n, mape / n\n",
    "\n",
    "    print(f\"{eval_type}, MAE: {mae}, RMSE: {rmse}, MAPE: {mape}\")\n",
    "\n",
    "    # Get the average score for each metric in each batch\n",
    "    return rmse, mae, mape, y_pred, y_truth\n",
    "\n",
    "\n",
    "def train(model, device, dataloader, optimizer, loss_fn, epoch):\n",
    "    \"\"\"Train model on data.\n",
    "\n",
    "    :param model: Model to evaluate\n",
    "    :param device: Device to evaluate on\n",
    "    :param dataloader: Data loader\n",
    "    :param optimizer: Optimizer to use\n",
    "    :param loss_fn: Loss function\n",
    "    :param epoch: Current epoch\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for _, raw_batch in enumerate(tqdm(dataloader, desc=f\"Epoch {epoch}\")):\n",
    "        current_batch = raw_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = torch.squeeze(model(current_batch, device))\n",
    "        loss = loss_fn()(y_pred.float(), torch.squeeze(current_batch.y).float())\n",
    "        writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N6tXJUu38HGo"
   },
   "source": [
    "In order to evaluate the performance of the model, we need to define some evaluation metrics.\n",
    "\n",
    "* The Z-score normalizes data using mean and standard deviation.\n",
    "* MAPE is mean absolute percentage error.\n",
    "* RMSE is root mean squared error.\n",
    "* MAE is mean absolute error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0CP54Sdb8HRC"
   },
   "outputs": [],
   "source": [
    "def z_score(x, mean, std):\n",
    "    \"\"\"Z-score normalization function: z = (X - mu) / sigma.\n",
    "\n",
    "    :param x: torch array, input array to be normalized.\n",
    "    :param mean: float, the value of mean.\n",
    "    :param std: float, the value of standard deviation.\n",
    "    :return: torch array, z-score normalized array.\n",
    "    \"\"\"\n",
    "    return (x - mean) / std\n",
    "\n",
    "\n",
    "def un_z_score(x_normed, mean, std):\n",
    "    \"\"\"Undo the Z-score calculation.\n",
    "\n",
    "    :param x_normed: torch array, input array to be un-normalized.\n",
    "    :param mean: float, the value of mean.\n",
    "    :param std: float, the value of standard deviation.\n",
    "    \"\"\"\n",
    "    return x_normed * std + mean\n",
    "\n",
    "\n",
    "def calc_mape(ground_truth, prediction):\n",
    "    \"\"\"Mean absolute percentage error, given as a % (e.g. 99 -> 99%).\n",
    "\n",
    "    :param ground_truth: torch array, ground truth.\n",
    "    :param prediction: torch array, prediction.\n",
    "    :return: torch scalar, MAPE averages on all elements of input.\n",
    "    \"\"\"\n",
    "    return torch.mean(torch.abs(prediction - ground_truth) / (ground_truth + 1e-15) * 100)\n",
    "\n",
    "\n",
    "def calc_rmse(ground_truth, prediction):\n",
    "    \"\"\"Root mean squared error.\n",
    "\n",
    "    :param ground_truth: torch array, ground truth.\n",
    "    :param prediction: torch array, prediction.\n",
    "    :return: torch scalar, RMSE averages on all elements of input.\n",
    "    \"\"\"\n",
    "    return torch.sqrt(torch.mean((prediction - ground_truth) ** 2))\n",
    "\n",
    "\n",
    "def calc_mae(ground_truth, prediction):\n",
    "    \"\"\"Mean absolute error.\n",
    "\n",
    "    :param ground_truth: torch array, ground truth.\n",
    "    :param prediction: torch array, prediction.\n",
    "    :return: torch scalar, MAE averages on all elements of input.\n",
    "    \"\"\"\n",
    "    return torch.mean(torch.abs(prediction - ground_truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQmkAf1W7z2f"
   },
   "source": [
    "Now, let's put it all together. Let's use the `train` and `eval` functions along with the model and dataloadres to create a training function (`model_train`) and testing function (`model_test`).\n",
    "\n",
    "We also build in tensorboard support for logging of the training metrics over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iwQHMBp975LP"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Make a tensorboard writer\n",
    "writer = SummaryWriter()\n",
    "\n",
    "\n",
    "def model_train(train_dataloader, val_dataloader, config, device):\n",
    "    \"\"\"Train the ST-GAT model. Evaluate on validation dataset as you go.\n",
    "\n",
    "    :param train_dataloader: Data loader of training dataset\n",
    "    :param val_dataloader: Dataloader of val dataset\n",
    "    :param config: configuration to use\n",
    "    :param device: Device to evaluate on\n",
    "    \"\"\"\n",
    "    # Make the model. Each datapoint in the graph is 228x12: N x F\n",
    "    model = StGat(\n",
    "        in_channels=config[\"N_HIST\"],\n",
    "        out_channels=config[\"N_PRED\"],\n",
    "        n_nodes=config[\"N_NODE\"],\n",
    "        dropout=config[\"DROPOUT\"],\n",
    "    )\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=config[\"INITIAL_LR\"],\n",
    "        weight_decay=config[\"WEIGHT_DECAY\"],\n",
    "    )\n",
    "    loss_fn = torch.nn.MSELoss\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # For every epoch, train the model on training dataset\n",
    "    # Evaluate model on validation dataset\n",
    "    for epoch in range(config[\"EPOCHS\"]):\n",
    "        loss = train(model, device, train_dataloader, optimizer, loss_fn, epoch)\n",
    "        print(f\"Loss: {loss:.3f}\")\n",
    "        if epoch % 5 == 0:\n",
    "            train_mae, train_rmse, train_mape, _, _ = eval_model(\n",
    "                model, device, train_dataloader, \"Train\"\n",
    "            )\n",
    "            val_mae, val_rmse, val_mape, _, _ = eval_model(model, device, val_dataloader, \"Valid\")\n",
    "            writer.add_scalar(\"MAE/train\", train_mae, epoch)\n",
    "            writer.add_scalar(\"RMSE/train\", train_rmse, epoch)\n",
    "            writer.add_scalar(\"MAPE/train\", train_mape, epoch)\n",
    "            writer.add_scalar(\"MAE/val\", val_mae, epoch)\n",
    "            writer.add_scalar(\"RMSE/val\", val_rmse, epoch)\n",
    "            writer.add_scalar(\"MAPE/val\", val_mape, epoch)\n",
    "\n",
    "    writer.flush()\n",
    "    # Save the model\n",
    "    timestr = time.strftime(\"%m-%d-%H%M%S\")\n",
    "    checkpoint_path = Path(config[\"CHECKPOINT_DIR\"]) / f\"model_{timestr}.pt\"\n",
    "    torch.save(\n",
    "        {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"loss\": loss,\n",
    "        },\n",
    "        checkpoint_path,\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def model_test(model, test_dataloader, device):\n",
    "    \"\"\"Test the ST-GAT model.\n",
    "\n",
    "    :param model: Model to test\n",
    "    :param test_dataloader: Data loader of test dataset\n",
    "    :param device: Device to evaluate on\n",
    "    \"\"\"\n",
    "    eval_model(model, device, test_dataloader, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9bc-5U_7EbSf"
   },
   "source": [
    "---\n",
    "\n",
    "**Problem 1:** Interpreting Training Metrics with TensorBoard\n",
    "\n",
    "TensorBoard is a graphical tool to monitor your training process. Run the following code cell (which will initially be empty) and proceed to the training step below. After training is done, click the refresh button (in the top right corner) to view the training results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UFg5H2-vEfQJ"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hArCFyVnEjIM"
   },
   "source": [
    "After training and refreshing the TensorBoard dashboard, answer the following questions in the markdown cell below:\n",
    "\n",
    "1. At which epoch does the validation metric plateau in terms of MAE, MAPE, and RMSE?\n",
    "2. If you observe signs of overfitting, at which epoch does it begin?\n",
    "\n",
    "Attach a screenshot of the TensorBoard output to support your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answers here:**\n",
    "\n",
    "> BEGIN SOLUTION\n",
    "\n",
    "1. The validation metrics (MAE, MAPE, RMSE) plateau around epoch 40-50. After this point, the metrics show minimal improvement.\n",
    "\n",
    "2. Signs of overfitting begin around epoch 45-50, where training loss continues to decrease but validation metrics start to level off or slightly increase.\n",
    "\n",
    "(Note: Exact epochs may vary based on random initialization)\n",
    "\n",
    "> END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark as complete after writing your analysis\n",
    "# BEGIN SOLUTION\n",
    "problem_1_completed = True\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert problem_1_completed, \"Please complete the analysis above and set problem_1_completed = True\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "# Manual review required for written answers\n",
    "assert problem_1_completed is True, \"problem_1_completed must be True\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OyZlmf8BGZx5"
   },
   "source": [
    "## Start Training\n",
    "\n",
    "Now, create your dataloaders and start training!\n",
    "\n",
    "In our default configuration, we train for 60 epochs with a batch size of 50. You can view your training progress in the TensorBoard above by clicking the \"refresh\" button to see new data. Training and validation performance are updated every 5 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 540
    },
    "executionInfo": {
     "elapsed": 17502,
     "status": "error",
     "timestamp": 1744742771320,
     "user": {
      "displayName": "Hanbin Lee",
      "userId": "14741986745160964413"
     },
     "user_tz": 240
    },
    "id": "EFwnhhQJCEOO",
    "outputId": "13c747ac-5341-403e-e54f-901c013eeaa6"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Constant config to use throughout\n",
    "config = {\n",
    "    \"BATCH_SIZE\": 50,\n",
    "    \"EPOCHS\": 60,\n",
    "    \"WEIGHT_DECAY\": 5e-5,\n",
    "    \"INITIAL_LR\": 3e-4,\n",
    "    \"CHECKPOINT_DIR\": \"./runs\",\n",
    "    \"N_PRED\": 9,\n",
    "    \"N_HIST\": 12,\n",
    "    \"DROPOUT\": 0.2,\n",
    "    # Number of possible 5 minute measurements per day\n",
    "    \"N_DAY_SLOT\": 288,\n",
    "    # Number of days worth of data in the dataset\n",
    "    \"N_DAYS\": 44,\n",
    "    # If false, use GCN paper weight matrix, if true, use GAT paper weight matrix\n",
    "    \"USE_GAT_WEIGHTS\": True,\n",
    "    \"N_NODE\": 228,\n",
    "}\n",
    "# Number of possible windows in a day\n",
    "config[\"N_SLOT\"] = config[\"N_DAY_SLOT\"] - (config[\"N_PRED\"] + config[\"N_HIST\"]) + 1\n",
    "\n",
    "# Load the distance matrix and convert to adjacency weights\n",
    "distance_matrix = pd.read_csv(DATA_DIR / \"PeMSD7_W_228.csv\", header=None).values\n",
    "adjacency_weights = distance_to_weight(distance_matrix, gat_version=config[\"USE_GAT_WEIGHTS\"])\n",
    "dataset = TrafficDataset(config, adjacency_weights)\n",
    "\n",
    "# Total of 44 days in the dataset: use 34 for training, 5 for val, 5 for test\n",
    "d_train, d_val, d_test = get_splits(dataset, config[\"N_SLOT\"], (34, 5, 5))\n",
    "train_dataloader = DataLoader(d_train, batch_size=config[\"BATCH_SIZE\"], shuffle=True)\n",
    "val_dataloader = DataLoader(d_val, batch_size=config[\"BATCH_SIZE\"], shuffle=True)\n",
    "test_dataloader = DataLoader(d_test, batch_size=config[\"BATCH_SIZE\"], shuffle=False)\n",
    "\n",
    "# Get GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "# Configure and train model\n",
    "config[\"N_NODE\"] = dataset.n_node\n",
    "model = model_train(train_dataloader, val_dataloader, config, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFI-qKOkE8m9"
   },
   "source": [
    "## Understanding Graph Structure in PyTorch Geometric\n",
    "\n",
    "The simplest graphs in PyTorch Geometric are made up of two components: nodes and edge index. Nodes (usually denoted by `x`) contain the features of the nodes, and `edge_index` is a 2-by-`number_of_edges` tensor in which the first row stores the starting node index of edges and the second row stores the destination node index of edges. Hence, each column contains the indices of the two nodes of an edge.\n",
    "\n",
    "**Reference:** See the [PyTorch Geometric Data documentation](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html) for more details.\n",
    "\n",
    "---\n",
    "\n",
    "**Problem 2: Graph Construction in PyTorch Geometric**\n",
    "\n",
    "In this problem, you will practice constructing graphs using PyTorch Geometric's edge index format.\n",
    "\n",
    "#### Part (a): Creating a Linear Graph\n",
    "\n",
    "Create an `edge_index` tensor that represents the following undirected graph:\n",
    "\n",
    "```\n",
    "0 --- 1 --- 2 --- 3\n",
    "```\n",
    "\n",
    "where the numbers are the node indices.\n",
    "\n",
    "**Hint:** For an undirected graph, you need to include edges in both directions (e.g., both 0->1 and 1->0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YouamupaFBmR"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import torch_geometric.utils as pyg_utils\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# BEGIN SOLUTION\n",
    "edge_index = torch.tensor([[0, 1, 1, 2, 2, 3], [1, 0, 2, 1, 3, 2]], dtype=torch.long)\n",
    "# END SOLUTION\n",
    "x = torch.tensor([[-1], [0], [1], [2]], dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "G = pyg_utils.to_networkx(data, to_undirected=True)\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "nx.draw(G, with_labels=True, node_color=\"lightblue\", font_weight=\"bold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert edge_index.shape[0] == 2, \"edge_index should have 2 rows\"\n",
    "assert data.num_nodes == 4, \"Graph should have 4 nodes\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert edge_index.shape[1] == 6, \"A linear graph 0-1-2-3 should have 6 directed edges\"\n",
    "assert data.num_edges == 6, \"Graph should have 6 edges\"\n",
    "# Check that all expected edges exist\n",
    "edges_set = set(zip(edge_index[0].tolist(), edge_index[1].tolist(), strict=False))\n",
    "assert (0, 1) in edges_set, \"Missing edge 0->1\"\n",
    "assert (1, 0) in edges_set, \"Missing edge 1->0\"\n",
    "assert (1, 2) in edges_set, \"Missing edge 1->2\"\n",
    "assert (2, 1) in edges_set, \"Missing edge 2->1\"\n",
    "assert (2, 3) in edges_set, \"Missing edge 2->3\"\n",
    "assert (3, 2) in edges_set, \"Missing edge 3->2\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QAC5yNrLFGjH"
   },
   "source": [
    "#### Part (b): Creating a Triangle Graph\n",
    "\n",
    "Create an `edge_index` tensor that represents an undirected triangle with three nodes (0, 1, 2) where each node is connected to every other node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2khgzL3jFIWv"
   },
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "edge_index = torch.tensor([[0, 0, 1, 1, 2, 2], [1, 2, 0, 2, 0, 1]], dtype=torch.long)\n",
    "# END SOLUTION\n",
    "x = torch.tensor([[0], [1], [2]], dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "G = pyg_utils.to_networkx(data, to_undirected=True)\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "nx.draw(G, with_labels=True, node_color=\"lightblue\", font_weight=\"bold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert edge_index.shape[0] == 2, \"edge_index should have 2 rows\"\n",
    "assert edge_index.shape[1] == 6, \"A triangle should have 6 directed edges (3 undirected edges)\"\n",
    "assert data.num_nodes == 3, \"Graph should have 3 nodes\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "# Check that all expected edges exist for a complete triangle\n",
    "edges_set = set(zip(edge_index[0].tolist(), edge_index[1].tolist(), strict=False))\n",
    "assert (0, 1) in edges_set and (1, 0) in edges_set, \"Missing edge between 0 and 1\"\n",
    "assert (0, 2) in edges_set and (2, 0) in edges_set, \"Missing edge between 0 and 2\"\n",
    "assert (1, 2) in edges_set and (2, 1) in edges_set, \"Missing edge between 1 and 2\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JfZmweCzFKoF"
   },
   "source": [
    "#### Part (c): Batching Graphs as Disconnected Subgraphs\n",
    "\n",
    "One way to batch multiple graphs is to create a single disconnected graph that contains all subgraphs.\n",
    "\n",
    "Create an `edge_index` tensor that contains two disconnected subgraphs:\n",
    "- A linear graph: `0 --- 1 --- 2 --- 3`\n",
    "- A triangle graph: `4 --- 5 --- 6` (with node 4 connected to 5, 5 to 6, and 6 to 4)\n",
    "\n",
    "Note that the triangle uses node indices 4, 5, 6 to avoid overlap with the linear graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jWOsiaQbFMQX"
   },
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "# Linear graph edges (nodes 0-3) + Triangle edges (nodes 4-6)\n",
    "edge_index = torch.tensor(\n",
    "    [[0, 1, 1, 2, 2, 3, 4, 4, 5, 5, 6, 6], [1, 0, 2, 1, 3, 2, 5, 6, 4, 6, 4, 5]],\n",
    "    dtype=torch.long,\n",
    ")\n",
    "# END SOLUTION\n",
    "x = torch.tensor([[0], [1], [2], [3], [4], [5], [6]], dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "G = pyg_utils.to_networkx(data, to_undirected=True)\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "nx.draw(G, with_labels=True, node_color=\"lightblue\", font_weight=\"bold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert edge_index.shape[0] == 2, \"edge_index should have 2 rows\"\n",
    "assert edge_index.shape[1] == 12, \"Combined graph should have 12 directed edges\"\n",
    "assert data.num_nodes == 7, \"Graph should have 7 nodes\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "edges_set = set(zip(edge_index[0].tolist(), edge_index[1].tolist(), strict=False))\n",
    "# Check linear graph edges\n",
    "assert (0, 1) in edges_set and (1, 0) in edges_set, \"Missing edge in linear graph\"\n",
    "# Check triangle edges\n",
    "assert (4, 5) in edges_set and (5, 4) in edges_set, \"Missing edge 4-5 in triangle\"\n",
    "assert (5, 6) in edges_set and (6, 5) in edges_set, \"Missing edge 5-6 in triangle\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4svqujYEFPLB"
   },
   "source": [
    "#### Part (d): Using Batch.from_data_list\n",
    "\n",
    "The above operation can be done more easily using a convenience function provided by PyTorch Geometric.\n",
    "\n",
    "Create two separate graphs, each with topology `0 --- 1 --- 2`, and combine them using `Batch.from_data_list()`.\n",
    "\n",
    "**Reference:** See the [Batch documentation](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Batch.html#torch_geometric.data.Batch.from_data_list) for details on how this function works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6eN2H9YMFRDz"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.data import Batch\n",
    "\n",
    "# First graph: 0 --- 1 --- 2\n",
    "# BEGIN SOLUTION\n",
    "edge_index1 = torch.tensor([[0, 1, 1, 2], [1, 0, 2, 1]], dtype=torch.long)\n",
    "# END SOLUTION\n",
    "x1 = torch.tensor([[1], [2], [3]], dtype=torch.float)\n",
    "data1 = Data(x=x1, edge_index=edge_index1)\n",
    "\n",
    "# Second graph: 0 --- 1 --- 2\n",
    "# BEGIN SOLUTION\n",
    "edge_index2 = torch.tensor([[0, 1, 1, 2], [1, 0, 2, 1]], dtype=torch.long)\n",
    "# END SOLUTION\n",
    "x2 = torch.tensor([[4], [5], [6]], dtype=torch.float)\n",
    "data2 = Data(x=x2, edge_index=edge_index2)\n",
    "\n",
    "# Combine with Batch.from_data_list\n",
    "# BEGIN SOLUTION\n",
    "batch = Batch.from_data_list([data1, data2])\n",
    "# END SOLUTION\n",
    "\n",
    "G = pyg_utils.to_networkx(batch, to_undirected=True)\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "nx.draw(G, with_labels=True, node_color=\"lightblue\", font_weight=\"bold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert batch.num_graphs == 2, \"Batch should contain 2 graphs\"\n",
    "assert batch.num_nodes == 6, \"Batch should have 6 total nodes\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert edge_index1.shape[1] == 4, \"First graph should have 4 directed edges\"\n",
    "assert edge_index2.shape[1] == 4, \"Second graph should have 4 directed edges\"\n",
    "assert batch.batch is not None, \"Batch should have batch attribute\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0nm7Xd8CI3Js"
   },
   "source": [
    "## Test the model\n",
    "\n",
    "Now that we have a trained model, we can test it on the test dataset and visualize its performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "error",
     "timestamp": 1744742774940,
     "user": {
      "displayName": "Hanbin Lee",
      "userId": "14741986745160964413"
     },
     "user_tz": 240
    },
    "id": "9-_urKxjI2gQ",
    "outputId": "9552f887-255d-4a76-a3e0-6d5546f3bbce"
   },
   "outputs": [],
   "source": [
    "def plot_prediction(_test_dataloader, y_pred, y_truth, node, config):\n",
    "    \"\"\"Plot predictions vs ground truth for a specific node.\"\"\"\n",
    "    # Calculate the truth\n",
    "    s = y_truth.shape\n",
    "    y_truth = y_truth.reshape(s[0], config[\"BATCH_SIZE\"], config[\"N_NODE\"], s[-1])\n",
    "    # Just get the first prediction out for the nth node\n",
    "    y_truth = y_truth[:, :, node, 0]\n",
    "    # Flatten to get the predictions for entire test dataset\n",
    "    y_truth = torch.flatten(y_truth)\n",
    "    day0_truth = y_truth[: config[\"N_SLOT\"]]\n",
    "\n",
    "    # Calculate the predicted\n",
    "    s = y_pred.shape\n",
    "    y_pred = y_pred.reshape(s[0], config[\"BATCH_SIZE\"], config[\"N_NODE\"], s[-1])\n",
    "    # Just get the first prediction out for the nth node\n",
    "    y_pred = y_pred[:, :, node, 0]\n",
    "    # Flatten to get the predictions for entire test dataset\n",
    "    y_pred = torch.flatten(y_pred)\n",
    "    # Just grab the first day\n",
    "    day0_pred = y_pred[: config[\"N_SLOT\"]]\n",
    "    t = list(range(0, config[\"N_SLOT\"] * 5, 5))\n",
    "    plt.plot(t, day0_pred, label=\"ST-GAT\")\n",
    "    plt.plot(t, day0_truth, label=\"truth\")\n",
    "    plt.xlabel(\"Time (minutes)\")\n",
    "    plt.ylabel(\"Speed prediction\")\n",
    "    plt.title(\"Predictions of traffic over time\")\n",
    "    plt.legend()\n",
    "    plt.savefig(\"predicted_times.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "_, _, _, y_pred, y_truth = eval_model(model, device, test_dataloader, \"Test\")\n",
    "plot_prediction(test_dataloader, y_pred, y_truth, 0, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "klUBAKa8Fh35"
   },
   "source": [
    "---\n",
    "\n",
    "**Problem 3:** Analyzing Traffic Predictions Across Time\n",
    "\n",
    "The variable `y_pred_reshape` contains predictions for 9 future time points (0, 5, 10, 15, 20, 25, 30, 35, 40 minutes ahead) based on the previous 12 time points for each of the 228 nodes.\n",
    "\n",
    "For each node, determine which of the 8 time points (indices 0-7, corresponding to 0-35 minutes) has the lowest predicted speed (worst traffic). Then, create a histogram showing how many nodes have their worst traffic at each time point.\n",
    "\n",
    "**Hint:** Use `torch.argmin()` to find the index of the minimum value along a specific dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "99ZWWCF5Fkb9"
   },
   "outputs": [],
   "source": [
    "y_pred_reshape = y_pred.reshape(\n",
    "    y_pred.shape[0], config[\"BATCH_SIZE\"], config[\"N_NODE\"], y_pred.shape[-1]\n",
    ")[0][0]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "t = torch.tensor(list(range(0, config[\"N_SLOT\"] * 5, 5)))\n",
    "t_ticks = torch.arange(len(t))\n",
    "# BEGIN SOLUTION\n",
    "# Find the time index with the minimum speed (worst traffic) for each node\n",
    "# y_pred_reshape has shape [N_NODE, N_PRED] where N_PRED=9 (but we use first 8)\n",
    "worst_times_index = torch.argmin(y_pred_reshape[:, :8], dim=1).cpu().numpy()\n",
    "# END SOLUTION\n",
    "ax.hist(worst_times_index, bins=torch.linspace(-0.5, 7.5, 9), edgecolor=\"black\")\n",
    "ax.set_xticks(torch.arange(8))\n",
    "ax.set_xticklabels(torch.arange(8) * 5)\n",
    "ax.set_xlabel(\"Time (minutes)\")\n",
    "ax.set_ylabel(\"Node counts\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert (\n",
    "    len(worst_times_index) == config[\"N_NODE\"]\n",
    "), f\"Should have {config['N_NODE']} predictions, one per node\"\n",
    "assert worst_times_index.min() >= 0, \"Index should be non-negative\"\n",
    "assert worst_times_index.max() <= 7, \"Index should be at most 7 (8 time points)\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "# Verify that worst_times_index represents argmin over time dimension\n",
    "manual_check = torch.argmin(y_pred_reshape[:, :8], dim=1).cpu().numpy()\n",
    "assert (worst_times_index == manual_check).all(), \"Should be argmin over time dimension\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "COGjouriMrDf"
   },
   "source": [
    "## Exploring Graph Neural Network Properties: Equivariance\n",
    "\n",
    "Graph neural networks enjoy a number of important properties that are natural to processing graph-structured data. First of all, the prediction results should be the same regardless of how we label the nodes of the graph. In our example, the predicted traffic of a node should be the same after relabeling the nodes. This property is called *equivariance*.\n",
    "\n",
    "Suppose that we have nodes $1, 2, 3$ and relabeled them to $3, 1, 2$. The features of the node according to the original label are $x_i$ ($i=1,2,3$). The predictions are denoted by $f(x_i)$ ($i=1,2,3$). Let $\\mathbf{x}$ be the original $(x_1, x_2, x_3)$ and $\\mathbf{x'}$ be the reordered features $(x_3, x_1, x_2)$. Then by equivariance, the following should hold:\n",
    "\n",
    "$$\n",
    "\\text{1st element of } f(\\mathbf{x'}) = \\text{3rd element of } f(\\mathbf{x}) \\\\\n",
    "\\text{2nd element of } f(\\mathbf{x'}) = \\text{1st element of } f(\\mathbf{x}) \\\\\n",
    "\\text{3rd element of } f(\\mathbf{x'}) = \\text{2nd element of } f(\\mathbf{x})\n",
    "$$\n",
    "\n",
    "In other words, the function preserves the permutation of the samples.\n",
    "\n",
    "We will confirm that the graph neural network we trained is *equivariant*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OC5aCfT3jpTm"
   },
   "source": [
    "---\n",
    "\n",
    "**Problem 4:** Demonstrating GNN Equivariance\n",
    "\n",
    "In this problem, you will verify that graph neural networks are equivariant to node permutations.\n",
    "\n",
    "#### Part (a): Generating Random Permutations\n",
    "\n",
    "Read the [`torch.randperm` documentation](https://pytorch.org/docs/stable/generated/torch.randperm.html) and use it to generate a random permutation of length 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1744742780776,
     "user": {
      "displayName": "Hanbin Lee",
      "userId": "14741986745160964413"
     },
     "user_tz": 240
    },
    "id": "LFdA1k6jj7kK",
    "outputId": "cf341c91-5f01-4c3c-b6f4-9be291364bdd"
   },
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "idx_perm = torch.randperm(4)\n",
    "# END SOLUTION\n",
    "idx_perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert idx_perm.shape == torch.Size([4]), \"Permutation should have length 4\"\n",
    "assert set(idx_perm.tolist()) == {\n",
    "    0,\n",
    "    1,\n",
    "    2,\n",
    "    3,\n",
    "}, \"Permutation should contain exactly 0, 1, 2, 3\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert idx_perm.dtype == torch.int64, \"Permutation should be int64 dtype\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwD1nvS5NkJt"
   },
   "source": [
    "#### Part (b): Understanding argsort\n",
    "\n",
    "You can obtain the new index of the $i$-th element by using `argsort()` on `idx_perm`. Read the [`torch.argsort` documentation](https://pytorch.org/docs/stable/generated/torch.argsort.html) and verify this by applying `argsort` to your permutation from part (a).\n",
    "\n",
    "**Example:** If `idx_perm = [2, 0, 1, 3]`, then element 0 moved to position 1, element 1 moved to position 2, element 2 moved to position 0, and element 3 stayed at position 3. So `argsort(idx_perm) = [1, 2, 0, 3]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1744742781818,
     "user": {
      "displayName": "Hanbin Lee",
      "userId": "14741986745160964413"
     },
     "user_tz": 240
    },
    "id": "Db-lXPZ1OLNJ",
    "outputId": "eac8dc25-a501-4843-87c8-4ef1e90d0ffd"
   },
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "idx_new = torch.argsort(idx_perm)\n",
    "# END SOLUTION\n",
    "idx_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert idx_new.shape == torch.Size([4]), \"argsort result should have length 4\"\n",
    "assert set(idx_new.tolist()) == {\n",
    "    0,\n",
    "    1,\n",
    "    2,\n",
    "    3,\n",
    "}, \"argsort should contain exactly 0, 1, 2, 3\"\n",
    "# Verify argsort property: idx_perm[idx_new[i]] should give sorted order\n",
    "assert (idx_perm[idx_new] == torch.arange(4)).all(), \"argsort property should hold\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "# Additional verification of argsort\n",
    "for idx in range(4):\n",
    "    assert (\n",
    "        idx_perm[idx_new[idx]] == idx\n",
    "    ), f\"argsort[{idx}] should point to where {idx} is in idx_perm\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_tpCTUOkDW1"
   },
   "source": [
    "#### Part (c): Applying Permutations to Tensors\n",
    "\n",
    "Using the permutation `idx_perm` generated above, permute the tensor `[1, 6, 7, 2]` by indexing with the permutation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1744742782955,
     "user": {
      "displayName": "Hanbin Lee",
      "userId": "14741986745160964413"
     },
     "user_tz": 240
    },
    "id": "P6JPkl8CkUWl",
    "outputId": "677b3eaf-b0ed-40f6-eebe-831b1866fd39"
   },
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "result = torch.tensor([1, 6, 7, 2])[idx_perm]\n",
    "# END SOLUTION\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "original = torch.tensor([1, 6, 7, 2])\n",
    "assert result.shape == original.shape, \"Result should have same shape as original\"\n",
    "assert (result == original[idx_perm]).all(), \"Result should be original indexed by idx_perm\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "# Verify permutation was applied correctly\n",
    "for idx in range(4):\n",
    "    assert (\n",
    "        result[idx] == original[idx_perm[idx]]\n",
    "    ), f\"Position {idx} should have value from position idx_perm[{idx}]\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HGcwHpuOkqyx"
   },
   "source": [
    "#### Part (d): Getting Dataset Length\n",
    "\n",
    "Now we are going to permute the test dataset `d_test`. First, get the length of the dataset and print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1744742784199,
     "user": {
      "displayName": "Hanbin Lee",
      "userId": "14741986745160964413"
     },
     "user_tz": 240
    },
    "id": "gCwTRZ_zkysk",
    "outputId": "168f716a-068b-4bdd-a28a-f2af77b9ebd9"
   },
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "len_test = len(d_test)\n",
    "# END SOLUTION\n",
    "print(len_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert len_test == 1340, f\"Test dataset should have 1340 samples, got {len_test}\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert len_test > 0, \"Test dataset should not be empty\"\n",
    "assert len_test == len(d_test), \"len_test should equal len(d_test)\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJVnl8e0lAwA"
   },
   "source": [
    "#### Part (e): Extracting a Batch\n",
    "\n",
    "Obtain a batch from the test dataloader and compute the number of nodes in the batch.\n",
    "\n",
    "**Hint:** Inspect the `eval` function in the earlier code and iterate through `test_dataloader`, calling `break` after the first iteration to get a single batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gPsi5uS-nwIs"
   },
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "# Obtain a batch from the test dataloader\n",
    "for raw_batch in test_dataloader:\n",
    "    batch = raw_batch.to(device)\n",
    "    break\n",
    "len_x = len(batch.x)\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert batch is not None, \"batch should be defined\"\n",
    "assert len_x > 0, \"len_x should be positive\"\n",
    "assert len_x == batch.x.shape[0], \"len_x should equal batch.x.shape[0]\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "assert hasattr(batch, \"edge_index\"), \"batch should have edge_index attribute\"\n",
    "assert batch.x.device.type == device, f\"batch should be on {device}\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKUS54DBlTnj"
   },
   "source": [
    "#### Part (f): Demonstrating Equivariance\n",
    "\n",
    "Feed the permuted dataset to the model and demonstrate equivariance by comparing the output from permuted input to the permuted output from non-permuted input.\n",
    "\n",
    "First, we define a simple graph attention module which is the first layer of the full traffic prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1744743155591,
     "user": {
      "displayName": "Hanbin Lee",
      "userId": "14741986745160964413"
     },
     "user_tz": 240
    },
    "id": "eaIQY4xByLou",
    "outputId": "d57c4dac-8187-4c68-e50b-eeeae7cd4ccc"
   },
   "outputs": [],
   "source": [
    "model_gat = GATConv(\n",
    "    in_channels=config[\"N_HIST\"],\n",
    "    out_channels=config[\"N_PRED\"],\n",
    "    heads=8,\n",
    "    dropout=0,\n",
    ")\n",
    "model_gat.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZuiuD31yMq3"
   },
   "source": [
    "Next, we define the index variables required to permute the model input and the outputs.\n",
    "The two arrays will be used to permute nodes and their associated edge indexes.\n",
    "\n",
    "`idx_perm` contains the permutation and `idx_new` stores the new position of the original indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X8GqTiSzPuan"
   },
   "outputs": [],
   "source": [
    "idx_perm = torch.randperm(len_x).cuda()\n",
    "idx_new = torch.argsort(idx_perm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mLt94094yrwM"
   },
   "source": [
    "Compute the model output of the pre-permuted batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dnNpe0c1ydWl"
   },
   "outputs": [],
   "source": [
    "pred_preperm = model_gat(batch.x, batch.edge_index)\n",
    "pred_preperm = pred_preperm[idx_perm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8w-ux8ScywDe"
   },
   "source": [
    "Write code that permutes the batch data. You need to:\n",
    "1. Permute the node features `batch_postperm.x` using `idx_perm`\n",
    "2. Update the edge indices using `idx_new` (since edges point to node indices, which have moved)\n",
    "3. Run the model on the permuted data\n",
    "4. Compare with the pre-permuted output to verify equivariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1744743346792,
     "user": {
      "displayName": "Hanbin Lee",
      "userId": "14741986745160964413"
     },
     "user_tz": 240
    },
    "id": "fDTs7BAjywmm",
    "outputId": "f2e43587-fffb-40d1-8898-d6d4aa0d5e36"
   },
   "outputs": [],
   "source": [
    "batch_postperm = batch.clone()\n",
    "batch_postperm.x = batch.x[idx_perm]\n",
    "# BEGIN SOLUTION\n",
    "# Extract each row of edge_index, apply idx_new to map old indices to new positions\n",
    "edge_index_new = torch.stack((idx_new[batch.edge_index[0]], idx_new[batch.edge_index[1]]))\n",
    "# Update edge index of batch_postperm\n",
    "batch_postperm.edge_index = edge_index_new\n",
    "# Call model with permuted graph\n",
    "pred_postperm = model_gat(batch_postperm.x, batch_postperm.edge_index)\n",
    "# END SOLUTION\n",
    "# Check equivariance\n",
    "print(f\"The two tensors are the same: {torch.allclose(pred_preperm, pred_postperm)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert torch.allclose(\n",
    "    pred_preperm, pred_postperm\n",
    "), \"Model should be equivariant: permuted output should match\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "# Additional equivariance check\n",
    "assert pred_postperm.shape == pred_preperm.shape, \"Output shapes should match\"\n",
    "# Check that the edge indices were properly transformed\n",
    "assert (\n",
    "    batch_postperm.edge_index.shape == batch.edge_index.shape\n",
    "), \"Edge index shape should be preserved\"\n",
    "# END HIDDEN TESTS"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1NUIQDgj9NXDqtPN_9k_YxKhJN43p3Gho",
     "timestamp": 1744572747761
    },
    {
     "file_id": "1u9UBncM4ENeGMb8sF-WPJRsxa7lF_Xgk",
     "timestamp": 1638734470869
    },
    {
     "file_id": "1drpELm63e5TFD55KLw9pEiDCVX0nsV-p",
     "timestamp": 1638732110630
    },
    {
     "file_id": "13FrIqZz78WP6UHpTrqGTcy7PPS3OFTQ0",
     "timestamp": 1638731843288
    },
    {
     "file_id": "1bAvutxJhjMyNsbzlLuQybzn_DXM63CuE",
     "timestamp": 1635921219828
    },
    {
     "file_id": "1gTdOSYXLrSGlqpjKn69lgbIbTK8DhOtY",
     "timestamp": 1634599450895
    },
    {
     "file_id": "1Jc5CAEGZIvY0vka3mBdf0tqn2TaJr2O1",
     "timestamp": 1610408674518
    },
    {
     "file_id": "1gc6u6hItUKY9uJt6GXHaneSYCMaGcxp1",
     "timestamp": 1610395347938
    },
    {
     "file_id": "1CqWY4pk7_VFxi8K8v4asr18ed0Hs8FVA",
     "timestamp": 1578441204356
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
