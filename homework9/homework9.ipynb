{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASCI 315, Homework 9: Convolutional Neural Networks\n",
    "\n",
    "In this homework assignment, we'll use PyTorch to implement convolutional neural networks (also known as \"convnets\" or \"CNNs\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "To get started, let's import some packages and download an image of a bear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3883,
     "status": "ok",
     "timestamp": 1742132923172,
     "user": {
      "displayName": "Jeffrey Regier",
      "userId": "17304790169060975378"
     },
     "user_tz": 240
    },
    "id": "AcXH30x1aPC0"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import io as skimage_io\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395
    },
    "executionInfo": {
     "elapsed": 293,
     "status": "ok",
     "timestamp": 1742132923463,
     "user": {
      "displayName": "Jeffrey Regier",
      "userId": "17304790169060975378"
     },
     "user_tz": 240
    },
    "id": "hhSU2wGAoD72",
    "outputId": "e463fe90-40e4-4d44-af03-72b8fdbddc68"
   },
   "outputs": [],
   "source": [
    "url = (\n",
    "    \"https://ewscripps.brightspotcdn.com/dims4/default/e666c4b/2147483647/strip\"\n",
    "    \"/true/crop/1280x720+0+0/resize/1280x720!/quality/90/\"\n",
    "    \"?url=https%3A%2F%2Fewscripps.brightspotcdn.com\"\n",
    "    \"%2Fb0%2F82%2Fe97f14ff421ca8ca7d8692e0ecdb%2Fgeneric-1280-1.png\"\n",
    ")\n",
    "response = requests.get(url, timeout=30)\n",
    "with Path(\"bear.png\").open(\"wb\") as f:\n",
    "    f.write(response.content)\n",
    "bear = skimage_io.imread(\"bear.png\")\n",
    "bear = resize(bear, (bear.shape[0] // 2, bear.shape[1] // 2), anti_aliasing=True)\n",
    "bw_bear = rgb2gray(bear)\n",
    "bear_edges = torch.zeros(bw_bear.shape)\n",
    "plt.imshow(bw_bear, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "bw_bear = torch.tensor(bw_bear, dtype=torch.float32)\n",
    "print(\"The shape of the bear image is : {}\".format(bw_bear.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Convolution with stride\n",
    "\n",
    "Implement a 2D convolution operation with stride using only `for` loops and basic PyTorch operations (without using the `torch.nn` submodule).\n",
    "\n",
    "**Requirements:**\n",
    "- Input `X` has shape `(h_x, w_x)`\n",
    "- Kernel `K` has shape `(h_k, w_k)`\n",
    "- Stride `s` is a 2-tuple `(vertical_stride, horizontal_stride)`\n",
    "- Use only `torch` operations (no `torch.nn`)\n",
    "\n",
    "**Hint:** The output dimensions are `((h_x - h_k) // s[0] + 1, (w_x - w_k) // s[1] + 1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_conv2d(x_input, kernel, stride):\n",
    "    \"\"\"Compute 2D convolution.\n",
    "\n",
    "    Args:\n",
    "        x_input: Input tensor of shape (h_x, w_x)\n",
    "        kernel: Kernel tensor of shape (h_k, w_k)\n",
    "        stride: 2-tuple indicating (vertical_stride, horizontal_stride)\n",
    "\n",
    "    Returns:\n",
    "        output: Output tensor after applying convolution\n",
    "    \"\"\"\n",
    "    # BEGIN SOLUTION\n",
    "    h_k, w_k = kernel.shape\n",
    "    new_h = (x_input.shape[0] - h_k) // stride[0] + 1\n",
    "    new_w = (x_input.shape[1] - w_k) // stride[1] + 1\n",
    "    output = torch.zeros((new_h, new_w), dtype=torch.float32)\n",
    "    for i in range(output.shape[0]):\n",
    "        for j in range(output.shape[1]):\n",
    "            row_start = i * stride[0]\n",
    "            col_start = j * stride[1]\n",
    "            patch = x_input[row_start : row_start + h_k, col_start : col_start + w_k]\n",
    "            output[i, j] = torch.sum(patch * kernel)\n",
    "    return output\n",
    "    # END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "test_input = torch.arange(16, dtype=torch.float32).reshape(4, 4)\n",
    "test_kernel = torch.ones((2, 2), dtype=torch.float32)\n",
    "test_output = my_conv2d(test_input, test_kernel, (1, 1))\n",
    "assert test_output.shape == (3, 3), f\"Expected shape (3, 3), got {test_output.shape}\"\n",
    "assert test_output[0, 0] == 10.0, f\"Expected 10.0, got {test_output[0, 0]}\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "test_output_stride2 = my_conv2d(test_input, test_kernel, (2, 2))\n",
    "assert test_output_stride2.shape == (\n",
    "    2,\n",
    "    2,\n",
    "), f\"Expected shape (2, 2) with stride 2, got {test_output_stride2.shape}\"\n",
    "assert test_output_stride2[0, 0] == 10.0, f\"Expected 10.0 at [0,0], got {test_output_stride2[0, 0]}\"\n",
    "assert test_output_stride2[1, 1] == 42.0, f\"Expected 42.0 at [1,1], got {test_output_stride2[1, 1]}\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convolution operation is very useful in image processing. With the right kernel, you can perform edge detection, blurring, bokeh effects, etc. Run the cells below to see your convolution function in action on the bear image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1742132923467,
     "user": {
      "displayName": "Jeffrey Regier",
      "userId": "17304790169060975378"
     },
     "user_tz": 240
    },
    "id": "bKzKCweKpeZM"
   },
   "outputs": [],
   "source": [
    "blurr_kernel = torch.tensor(\n",
    "    [\n",
    "        [1, 4, 7, 4, 1],\n",
    "        [4, 16, 26, 16, 4],\n",
    "        [7, 26, 41, 26, 7],\n",
    "        [4, 16, 26, 16, 4],\n",
    "        [1, 4, 7, 4, 1],\n",
    "    ],\n",
    "    dtype=torch.float32,\n",
    ")\n",
    "blurr_kernel /= blurr_kernel.sum()\n",
    "\n",
    "edge_kernel = torch.tensor(\n",
    "    [\n",
    "        [-1.0, -1, -1],\n",
    "        [-1, 8, -1],\n",
    "        [-1, -1, -1],\n",
    "    ],\n",
    "    dtype=torch.float32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "executionInfo": {
     "elapsed": 2193,
     "status": "ok",
     "timestamp": 1742132925661,
     "user": {
      "displayName": "Jeffrey Regier",
      "userId": "17304790169060975378"
     },
     "user_tz": 240
    },
    "id": "LYE6Ktxfps2C",
    "outputId": "7389c7a8-685e-4ee1-fa3f-a563910afb36"
   },
   "outputs": [],
   "source": [
    "bw_bear_edge = my_conv2d(bw_bear, edge_kernel, (2, 2))\n",
    "plt.imshow(bw_bear_edge.numpy(), cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "print(bw_bear_edge.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 213
    },
    "executionInfo": {
     "elapsed": 2182,
     "status": "ok",
     "timestamp": 1742132927853,
     "user": {
      "displayName": "Jeffrey Regier",
      "userId": "17304790169060975378"
     },
     "user_tz": 240
    },
    "id": "ygjahO0Ip6_k",
    "outputId": "3a14951e-7622-4362-c4ee-ae1255155e55"
   },
   "outputs": [],
   "source": [
    "bw_bear_blur = my_conv2d(bw_bear, blurr_kernel, (2, 2))\n",
    "plt.imshow(bw_bear_blur.numpy(), cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "print(bw_bear_blur.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Convolutional layer with padding and stride\n",
    "\n",
    "Fill in the `MyConv2dModule` class to create a convolutional layer with padding and stride using the `my_conv2d` function from Problem 1. Implement this without the bias term.\n",
    "\n",
    "**Padding rules:**\n",
    "- If padding `p` is even, pad each side with `p/2` rows/columns\n",
    "- If padding for rows is odd, pad the top with `p // 2` rows and the bottom with `p - p // 2` rows\n",
    "- If padding for columns is odd, pad the left with `p // 2` columns and the right with `p - p // 2` columns\n",
    "\n",
    "**Hint:** Use `torch.nn.functional.pad()` for padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyConv2dModule(nn.Module):\n",
    "    \"\"\"Custom 2D convolutional layer using my_conv2d.\n",
    "\n",
    "    Args:\n",
    "        kernel_size: 2-tuple (h_k, w_k) for kernel dimensions\n",
    "        stride: 2-tuple indicating vertical and horizontal stride\n",
    "        padding: 2-tuple indicating padding for rows and columns\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size, stride, padding):\n",
    "        super().__init__()\n",
    "        # BEGIN SOLUTION\n",
    "        self.weight = nn.Parameter(torch.randn(kernel_size))\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        # END SOLUTION\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # BEGIN SOLUTION\n",
    "        top = self.padding[0] // 2\n",
    "        bottom = self.padding[0] - top\n",
    "        left = self.padding[1] // 2\n",
    "        right = self.padding[1] - left\n",
    "        inputs_padded = F.pad(inputs, (left, right, top, bottom), mode=\"constant\", value=0.0)\n",
    "        return my_conv2d(inputs_padded, kernel=self.weight, stride=self.stride)\n",
    "        # END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "torch.manual_seed(100)\n",
    "convlayer = MyConv2dModule((3, 3), (2, 2), (2, 2))\n",
    "test_x = torch.ones((32, 32))\n",
    "test_y = convlayer(test_x)\n",
    "assert test_y.shape == torch.Size([16, 16]), f\"Expected shape [16, 16], got {test_y.shape}\"\n",
    "assert torch.isclose(\n",
    "    test_y[0, 0], torch.tensor(-2.8146), atol=0.01\n",
    "), f\"Expected -2.8146, got {test_y[0, 0]}\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "torch.manual_seed(42)\n",
    "convlayer2 = MyConv2dModule((5, 5), (1, 1), (4, 4))\n",
    "test_x2 = torch.ones((10, 10))\n",
    "test_y2 = convlayer2(test_x2)\n",
    "assert test_y2.shape == torch.Size([10, 10]), f\"Expected shape [10, 10], got {test_y2.shape}\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Blocks\n",
    "\n",
    "A key aspect of deep learning is its modular approach, where neural networks are constructed using discrete building blocks. These blocks, which consist of collections of layers, are combined to form complete models. Let's explore this concept further.\n",
    "\n",
    "Suppose we want to implement a block with the following architecture:\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1Eu6XK96JwDJA0r_qBDkmpU5IihSJQYja' width=400>\n",
    "\n",
    "To implement this block, we would write code that defines it as a distinct module. This block can then serve as a fundamental component of a more complex neural network. In PyTorch, we would extend the `nn.Module` class. The new class would include at least two functions: `__init__` for initialization and `forward` for executing the forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1742132927888,
     "user": {
      "displayName": "Jeffrey Regier",
      "userId": "17304790169060975378"
     },
     "user_tz": 240
    },
    "id": "X-7uSgj5sYpz"
   },
   "outputs": [],
   "source": [
    "class ExampleBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(in_features, 64)\n",
    "        self.lin2 = nn.Linear(64, 64)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.act(self.lin1(x))\n",
    "        return self.act(self.lin2(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1742132927901,
     "user": {
      "displayName": "Jeffrey Regier",
      "userId": "17304790169060975378"
     },
     "user_tz": 240
    },
    "id": "vriPdNw7uFhM",
    "outputId": "14a2b703-f678-4940-be94-e36ff1506de9"
   },
   "outputs": [],
   "source": [
    "blk = ExampleBlock(3)\n",
    "X = torch.randn((1, 32, 32, 3))\n",
    "Y = blk(X)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: MysteryBlock\n",
    "\n",
    "Similar to the example, fill in `__init__()` and `forward()` using the following flowchart to implement the `MysteryBlock` class.\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1LoZjHA92C2Lk14y0pSHi5RqeY47otBB4' width=400>\n",
    "\n",
    "**Important:** Initialize the weights from a normal distribution with standard deviation of 0.05 using `nn.init.normal_(layer.weight, mean=0.0, std=0.05)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MysteryBlock(nn.Module):\n",
    "    \"\"\"Neural network block following the flowchart architecture.\"\"\"\n",
    "\n",
    "    def __init__(self, height=32, width=32):\n",
    "        super().__init__()\n",
    "        # BEGIN SOLUTION\n",
    "        kernel_size = 3\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=64, kernel_size=kernel_size, padding=\"same\"\n",
    "        )\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=64, out_channels=64, kernel_size=kernel_size, padding=\"same\"\n",
    "        )\n",
    "\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=kernel_size, padding=padding)\n",
    "\n",
    "        pool_out = ((height - 1) // 3 + 1, (width - 1) // 3 + 1)\n",
    "        pool_out1 = ((pool_out[0] - 1) // 3 + 1, (pool_out[1] - 1) // 3 + 1)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dense1 = nn.Linear(64 * pool_out1[0] * pool_out1[1], 1024)\n",
    "        self.dense2 = nn.Linear(64 * pool_out[0] * pool_out[1], 1024)\n",
    "        self.dense3 = nn.Linear(1024, 10)\n",
    "\n",
    "        nn.init.normal_(self.conv1.weight, mean=0.0, std=0.05)\n",
    "        nn.init.normal_(self.conv2.weight, mean=0.0, std=0.05)\n",
    "        nn.init.normal_(self.dense1.weight, mean=0.0, std=0.05)\n",
    "        nn.init.normal_(self.dense2.weight, mean=0.0, std=0.05)\n",
    "        nn.init.normal_(self.dense3.weight, mean=0.0, std=0.05)\n",
    "        # END SOLUTION\n",
    "\n",
    "    def forward(self, x):\n",
    "        # BEGIN SOLUTION\n",
    "        x = torch.relu(self.pool1(self.conv1(x)))\n",
    "        output2 = self.dense1(self.flatten(torch.relu(self.pool1(self.conv2(x)))))\n",
    "        output3 = torch.relu(self.dense2(self.flatten(x)))\n",
    "        return self.dense3(output2 + output3)\n",
    "        # END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "torch.manual_seed(100)\n",
    "block = MysteryBlock()\n",
    "test_input = torch.ones((1, 3, 32, 32))\n",
    "test_output = block(test_input)\n",
    "assert test_output.shape == torch.Size([1, 10]), f\"Expected shape [1, 10], got {test_output.shape}\"\n",
    "assert torch.isclose(\n",
    "    test_output[0, 0], torch.tensor(-0.6186), atol=0.01\n",
    "), f\"Expected -0.6186, got {test_output[0, 0]}\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "torch.manual_seed(100)\n",
    "block_64 = MysteryBlock(height=64, width=64)\n",
    "test_input_64 = torch.ones((2, 3, 64, 64))\n",
    "test_output_64 = block_64(test_input_64)\n",
    "assert test_output_64.shape == torch.Size(\n",
    "    [2, 10]\n",
    "), f\"Expected shape [2, 10], got {test_output_64.shape}\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4: Residual blocks\n",
    "\n",
    "Similarly, using the following flowchart, fill in `__init__()` and `forward()` for the `ResidualBlock` class.\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1P5nKQUh3IA-yGFScOtt9oJb9pTTmB3rC' width=400>\n",
    "\n",
    "- The left flowchart shows the `ResidualBlock` architecture when `self_conv=False`\n",
    "- The right flowchart shows the architecture when `self_conv=True`\n",
    "\n",
    "The batch normalization layer (`nn.BatchNorm2d`) makes training faster and more stable by recentering and rescaling the network inputs.\n",
    "\n",
    "**Important:** Initialize the weights in the conv layers from a normal distribution with mean 0 and standard deviation 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"Residual block with optional skip connection convolution.\n",
    "\n",
    "    Args:\n",
    "        filters: List of filter counts for conv layers\n",
    "        self_conv: If True, uses conv+batchnorm on skip connection\n",
    "        in_channels: Number of input channels\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, filters, self_conv, in_channels=3):\n",
    "        super().__init__()\n",
    "        # BEGIN SOLUTION\n",
    "        self._self_conv = self_conv\n",
    "        strides = [2, 1] if self_conv else [1, 1]\n",
    "\n",
    "        kernel_size = 3\n",
    "        pad = (kernel_size - 1) // 2\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=filters[0],\n",
    "            kernel_size=kernel_size,\n",
    "            padding=pad,\n",
    "            stride=strides[0],\n",
    "        )\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=filters[0],\n",
    "            out_channels=filters[1],\n",
    "            kernel_size=kernel_size,\n",
    "            padding=pad,\n",
    "            stride=strides[1],\n",
    "        )\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=filters[0])\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=filters[1])\n",
    "\n",
    "        if self_conv:\n",
    "            self.conv3 = nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=filters[2],\n",
    "                kernel_size=1,\n",
    "                padding=0,\n",
    "                stride=strides[0],\n",
    "            )\n",
    "            self.bn3 = nn.BatchNorm2d(num_features=filters[2])\n",
    "\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "        nn.init.normal_(self.conv1.weight, mean=0.0, std=0.05)\n",
    "        nn.init.normal_(self.conv2.weight, mean=0.0, std=0.05)\n",
    "        if self_conv:\n",
    "            nn.init.normal_(self.conv3.weight, mean=0.0, std=0.05)\n",
    "        # END SOLUTION\n",
    "\n",
    "    def forward(self, x):\n",
    "        # BEGIN SOLUTION\n",
    "        out_skip = x\n",
    "        out = self.act(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        if self._self_conv:\n",
    "            out_skip = self.bn3(self.conv3(out_skip))\n",
    "        out = torch.add(out, out_skip)\n",
    "        return self.act(out)\n",
    "        # END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "torch.manual_seed(100)\n",
    "test_input = torch.ones((10, 3, 32, 32))\n",
    "block_2 = ResidualBlock([16, 3], self_conv=False, in_channels=3)\n",
    "output_2 = block_2(test_input)\n",
    "assert output_2.shape == torch.Size(\n",
    "    [10, 3, 32, 32]\n",
    "), f\"Expected shape [10, 3, 32, 32], got {output_2.shape}\"\n",
    "\n",
    "block_3 = ResidualBlock([8, 8, 8], self_conv=True, in_channels=3)\n",
    "output_3 = block_3(test_input)\n",
    "assert output_3.shape == torch.Size(\n",
    "    [10, 8, 16, 16]\n",
    "), f\"Expected shape [10, 8, 16, 16], got {output_3.shape}\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "torch.manual_seed(42)\n",
    "block_hidden = ResidualBlock([32, 32], self_conv=False, in_channels=32)\n",
    "hidden_input = torch.randn((4, 32, 16, 16))\n",
    "hidden_output = block_hidden(hidden_input)\n",
    "assert hidden_output.shape == torch.Size(\n",
    "    [4, 32, 16, 16]\n",
    "), f\"Expected shape [4, 32, 16, 16], got {hidden_output.shape}\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet18\n",
    "\n",
    "ResNet (Residual Network) is a widely used convolutional neural network architecture that makes use of skip connections. These connections add the original input to the output of a series of convolutional layers, ensuring that useful information from earlier layers is preserved even if later layers fail to extract meaningful features.\n",
    "\n",
    "In this problem, you will build ResNet18, a variant that comprises 18 convolutional layers in total. The model will be trained on the CIFAR-10 dataset, which contains 60,000 color images of size 32x32 pixels (3 channels) across 10 classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5553,
     "status": "ok",
     "timestamp": 1742132933906,
     "user": {
      "displayName": "Jeffrey Regier",
      "userId": "17304790169060975378"
     },
     "user_tz": 240
    },
    "id": "UCBpu0P20mPL",
    "outputId": "d393befd-d2e7-4dbd-adb3-3cbbbca6d741"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "batch_size = 256\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=batch_size, num_workers=2, shuffle=True\n",
    ")\n",
    "# we'll use the test data for validation\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=batch_size, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "classes = (\n",
    "    \"plane\",\n",
    "    \"car\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    ")\n",
    "\n",
    "print(f\"Number of classes = {trainset.classes}\")\n",
    "print(f\"Original train size = {len(trainset)}, test size = {len(testset)}\")\n",
    "print(\n",
    "    f\"Samples in train dataloader = {len(trainloader.sampler)},\"\n",
    "    f\"in validation dataloader = {len(testloader.sampler)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 169,
     "status": "ok",
     "timestamp": 1742132934074,
     "user": {
      "displayName": "Jeffrey Regier",
      "userId": "17304790169060975378"
     },
     "user_tz": 240
    },
    "id": "OWaZTcjAgOdA",
    "outputId": "644df708-9f9a-41b4-d860-135403259a6d"
   },
   "outputs": [],
   "source": [
    "for x, y in trainloader:\n",
    "    print(f\"Batch shape = {x.shape}, target shape  {y.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a helper function for training a model network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1742132934093,
     "user": {
      "displayName": "Jeffrey Regier",
      "userId": "17304790169060975378"
     },
     "user_tz": 240
    },
    "id": "-diGaOiXEV47"
   },
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, val_dataloader, criterion, lr=0.03, num_epochs=10):\n",
    "    model = model.cuda()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    train_loss = []\n",
    "    train_accuracy = []\n",
    "    val_loss = []\n",
    "    val_accuracy = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        t_loss = 0.0\n",
    "        t_correct = 0\n",
    "        v_loss = 0.0\n",
    "        v_correct = 0\n",
    "\n",
    "        # training phase\n",
    "        for data in train_dataloader:\n",
    "            inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            t_loss += loss.item()\n",
    "            with torch.no_grad():\n",
    "                predicted_class = torch.argmax(outputs, dim=1)\n",
    "                t_correct += (predicted_class == labels).sum().item()\n",
    "\n",
    "        # evaluation on val\n",
    "        with torch.no_grad():\n",
    "            for data in val_dataloader:\n",
    "                inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                v_loss += loss.item()\n",
    "                predicted_class = torch.argmax(outputs, dim=1)\n",
    "                v_correct += (predicted_class == labels).sum().item()\n",
    "\n",
    "        train_loss.append(t_loss / len(train_dataloader))\n",
    "        val_loss.append(v_loss / len(val_dataloader))\n",
    "        train_accuracy.append(t_correct / len(train_dataloader.dataset))\n",
    "        val_accuracy.append(v_correct / len(val_dataloader.dataset))\n",
    "\n",
    "        print(\n",
    "            f\"Epoch={epoch}: \"\n",
    "            f\"training loss = {train_loss[-1]:.4f} \"\n",
    "            f\"accuracy = {train_accuracy[-1]:.2f}, \"\n",
    "            f\"validation loss = {val_loss[-1]:.4f}, \"\n",
    "            f\"accuracy = {val_accuracy[-1]:.2f}\"\n",
    "        )\n",
    "\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5: Data augmentation\n",
    "\n",
    "Before training the ResNet model, we need to apply data augmentation to prevent overfitting.\n",
    "\n",
    "Create a transform using `torchvision.transforms.Compose` that has two stages:\n",
    "1. Random horizontal flips (with probability 0.5)\n",
    "2. Random rotations between -30 and 30 degrees\n",
    "\n",
    "**Hint:** Use `transforms.RandomHorizontalFlip` and `transforms.RandomRotation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aug_preprocess = transforms.Compose(\n",
    "    [  # SOLUTION\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(degrees=(-30, 30)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "assert hasattr(data_aug_preprocess, \"transforms\"), \"data_aug_preprocess should be a Compose object\"\n",
    "assert len(data_aug_preprocess.transforms) == 2, \"Should have exactly 2 transforms\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "transform_types = [type(t).__name__ for t in data_aug_preprocess.transforms]\n",
    "assert \"RandomHorizontalFlip\" in transform_types, \"Missing RandomHorizontalFlip\"\n",
    "assert \"RandomRotation\" in transform_types, \"Missing RandomRotation\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6: ResNet18 class\n",
    "\n",
    "Use the following flowchart and the `ResidualBlock` class from Problem 4 to implement ResNet18.\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1y6DHU48iu54YAeg7ywx7_3zyZKHnbsdY' width=700>\n",
    "\n",
    "**Notes:**\n",
    "- The \"Skip Connection\" parts are `ResidualBlocks` with `self_conv=True`\n",
    "- This flowchart doesn't include the output layer - include an appropriate output layer for image classification\n",
    "- The `data_aug` parameter should be applied in the forward pass\n",
    "\n",
    "**Important:** If you're using Google Colab, make sure to go to \"Edit\" > \"Notebook Settings\" and select \"GPU\" before running the training cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    \"\"\"ResNet18 architecture for image classification.\n",
    "\n",
    "    Args:\n",
    "        num_classes: Number of output classes\n",
    "        data_aug: Data augmentation transform to apply\n",
    "        in_channels: Number of input channels (default: 3 for RGB)\n",
    "        image_dim: Input image dimension (default: 32 for CIFAR-10)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes, data_aug, in_channels=3, image_dim=32):\n",
    "        super().__init__()\n",
    "        self.image_dim = image_dim\n",
    "        self.da = data_aug\n",
    "        # BEGIN SOLUTION\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=64,\n",
    "            kernel_size=7,\n",
    "            padding=3,\n",
    "            stride=2,\n",
    "        )\n",
    "        self.before_res_block_bn = nn.BatchNorm2d(num_features=64)\n",
    "        self.maxpooling = nn.MaxPool2d(kernel_size=(2, 2), stride=2, padding=0)\n",
    "        self.resnetblock_1 = ResidualBlock([64, 64], self_conv=False, in_channels=64)\n",
    "        self.resnetblock_2 = ResidualBlock([64, 64], self_conv=False, in_channels=64)\n",
    "        self.resnetblock_3 = ResidualBlock([128, 128, 128], self_conv=True, in_channels=64)\n",
    "        self.resnetblock_4 = ResidualBlock([128, 128], self_conv=False, in_channels=128)\n",
    "        self.resnetblock_5 = ResidualBlock([256, 256, 256], self_conv=True, in_channels=128)\n",
    "        self.resnetblock_6 = ResidualBlock([256, 256], self_conv=False, in_channels=256)\n",
    "        self.resnetblock_7 = ResidualBlock([512, 512, 512], self_conv=True, in_channels=256)\n",
    "        self.resnetblock_8 = ResidualBlock([512, 512], self_conv=False, in_channels=512)\n",
    "        self.avgpooling = nn.AvgPool2d(kernel_size=1)\n",
    "        self.flat = nn.Flatten()\n",
    "        out_size = image_dim // 2**5\n",
    "        self.dense = nn.Linear(512 * out_size**2, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.blocks = [\n",
    "            self.resnetblock_1,\n",
    "            self.resnetblock_2,\n",
    "            self.resnetblock_3,\n",
    "            self.resnetblock_4,\n",
    "            self.resnetblock_5,\n",
    "            self.resnetblock_6,\n",
    "            self.resnetblock_7,\n",
    "            self.resnetblock_8,\n",
    "        ]\n",
    "        # END SOLUTION\n",
    "\n",
    "    def forward(self, x):\n",
    "        # BEGIN SOLUTION\n",
    "        output = self.da(x)\n",
    "        output = self.maxpooling(self.relu(self.before_res_block_bn(self.conv1(output))))\n",
    "        for res_block in self.blocks:\n",
    "            output = res_block(output)\n",
    "        return self.dense(self.flat(self.avgpooling(output)))\n",
    "        # END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test assertions\n",
    "model = ResNet18(10, data_aug_preprocess, in_channels=3, image_dim=32)\n",
    "test_input = torch.randn(4, 3, 32, 32)\n",
    "test_output = model(test_input)\n",
    "assert test_output.shape == torch.Size([4, 10]), f\"Expected shape [4, 10], got {test_output.shape}\"\n",
    "print(\"All tests passed!\")\n",
    "\n",
    "# BEGIN HIDDEN TESTS\n",
    "model_64 = ResNet18(10, data_aug_preprocess, in_channels=3, image_dim=64)\n",
    "test_input_64 = torch.randn(2, 3, 64, 64)\n",
    "test_output_64 = model_64(test_input_64)\n",
    "assert test_output_64.shape == torch.Size(\n",
    "    [2, 10]\n",
    "), f\"Expected shape [2, 10] for 64x64 input, got {test_output_64.shape}\"\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train the network. Check that CUDA is available (otherwise the train function will raise an error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1742132936790,
     "user": {
      "displayName": "Jeffrey Regier",
      "userId": "17304790169060975378"
     },
     "user_tz": 240
    },
    "id": "vinzL8yUKtgM",
    "outputId": "2d007f0d-d3dc-454a-e2da-4ef60a48d3c3"
   },
   "outputs": [],
   "source": [
    "len(trainloader), len(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1742132936808,
     "user": {
      "displayName": "Jeffrey Regier",
      "userId": "17304790169060975378"
     },
     "user_tz": 240
    },
    "id": "yAv2oebbNjys",
    "outputId": "fc575f45-6fb2-4f91-890c-abb0ce69b9c7"
   },
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 118482,
     "status": "ok",
     "timestamp": 1742133055291,
     "user": {
      "displayName": "Jeffrey Regier",
      "userId": "17304790169060975378"
     },
     "user_tz": 240
    },
    "id": "jIaC0LPWH5sM",
    "outputId": "d454e88a-3d93-4988-883d-a561dc923073"
   },
   "outputs": [],
   "source": [
    "model = ResNet18(10, data_aug_preprocess, in_channels=3, image_dim=32)\n",
    "train_loss, val_loss = train(\n",
    "    model, trainloader, testloader, nn.CrossEntropyLoss(), lr=0.03, num_epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 179,
     "status": "ok",
     "timestamp": 1742133055469,
     "user": {
      "displayName": "Jeffrey Regier",
      "userId": "17304790169060975378"
     },
     "user_tz": 240
    },
    "id": "7LlttDtiJ8Tu",
    "outputId": "f39521ac-897e-491d-d1bd-dafd2e09adca"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_loss, label=\"train\")\n",
    "plt.plot(val_loss, label=\"val\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
