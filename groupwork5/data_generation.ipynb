{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Dataset generation for STATS315"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT PACKAGES\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"axes.grid\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "reddish_cmap = LinearSegmentedColormap.from_list(\"reddish\", [\"white\", \"red\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.modeling.models import Sersic2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "# torch.manual_seed(43);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import astrophot as ap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from astropy.convolution import Gaussian2DKernel, convolve\n",
    "from astropy.modeling.models import Sersic2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_non_overlapping_params(\n",
    "    shape,\n",
    "    num_galaxies,\n",
    "    rmin=3,\n",
    "    rmax=10,\n",
    "    margin=5,\n",
    "    overlap_factor=1.5,\n",
    "):\n",
    "    ny, nx = shape\n",
    "    centers = []\n",
    "    r_effs = []\n",
    "    attempts = 0\n",
    "    max_attempts = 1000\n",
    "    while len(centers) < num_galaxies and attempts < max_attempts:\n",
    "        # Random effective radius\n",
    "        r_eff = rmin + (rmax - rmin) * torch.rand(1).item()\n",
    "        # Pick a random center with some margin from the edges\n",
    "        x0 = margin + (nx - margin - margin) * torch.rand(1).item()\n",
    "        y0 = margin + (ny - margin - margin) * torch.rand(1).item()\n",
    "        candidate = torch.tensor([x0, y0])\n",
    "        # Check distance to existing centers\n",
    "        valid = True\n",
    "        for (xc, yc), r in zip(centers, r_effs):\n",
    "            dist = torch.linalg.norm(candidate - torch.tensor([xc, yc]))\n",
    "            if dist < overlap_factor * (r_eff + r):\n",
    "                valid = False\n",
    "                break\n",
    "        if valid:\n",
    "            centers.append((x0, y0))\n",
    "            r_effs.append(r_eff)\n",
    "        attempts += 1\n",
    "    return centers, r_effs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_image(\n",
    "    shape=(50, 50),\n",
    "    conv=True,\n",
    "    _noise_sigma=0.0,\n",
    "    psf_sigma=1.0,\n",
    "    _normalize=False,\n",
    "):\n",
    "    ny, nx = shape\n",
    "    y, x = torch.meshgrid(torch.arange(ny), torch.arange(nx), indexing=\"ij\")\n",
    "    image = torch.zeros(shape)\n",
    "\n",
    "    num_galaxies = torch.randint(0, 7)\n",
    "    centers, r_effs = generate_non_overlapping_params(shape, num_galaxies)\n",
    "\n",
    "    for (x0, y0), r_eff in zip(centers, r_effs):\n",
    "        amplitude = 0.5 + (2.0 - 0.5) * torch.rand(1).item()\n",
    "        n = 1.0 + (4.0 - 1.0) * torch.rand(1).item()\n",
    "        ellip = 0 + (0.8 - 0) * torch.rand(1).item()\n",
    "        theta = 0 + (2 * math.pi - 0) * torch.rand(1).item()\n",
    "\n",
    "        sersic = Sersic2D(\n",
    "            amplitude=amplitude, r_eff=r_eff, n=n, x_0=x0, y_0=y0, ellip=ellip, theta=theta\n",
    "        )\n",
    "        image += sersic(x, y)\n",
    "\n",
    "    if conv:\n",
    "        kernel = Gaussian2DKernel(psf_sigma)\n",
    "        kernel.normalize()\n",
    "        psf = kernel.array\n",
    "\n",
    "        image = convolve(image, psf)\n",
    "\n",
    "    # Clip negative values to 0\n",
    "    image = torch.clamp(image, 0, None)\n",
    "\n",
    "    return image, num_galaxies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "# Initial normalization approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntrain = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntest = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## $\\sigma = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, ns_train = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntrain)]\n",
    ")\n",
    "dataset_train = torch.tensor(dataset_train, dtype=torch.float32)\n",
    "ns_train = torch.tensor(ns_train, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test, ns_test = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntest)]\n",
    ")\n",
    "dataset_test = torch.tensor(dataset_test, dtype=torch.float32)\n",
    "ns_test = torch.tensor(ns_test, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save((dataset_train, ns_train), f\"../data/315/dataset_train_{sigma}.pt\")\n",
    "torch.save((dataset_test, ns_test), f\"../data/315/dataset_test_{sigma}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize by the training set max\n",
    "train_max = dataset_train.max()\n",
    "train_min = dataset_train.min()\n",
    "\n",
    "test_max = dataset_test.max()\n",
    "test_min = dataset_test.min()\n",
    "\n",
    "dataset_train = (dataset_train - train_min) / (train_max - train_min)\n",
    "dataset_test = (dataset_test - test_min) / (test_max - test_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save((dataset_train, ns_train), f\"../data/315/dataset_train_{sigma}_norm.pt\")\n",
    "torch.save((dataset_test, ns_test), f\"../data/315/dataset_test_{sigma}_norm.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "## $\\sigma = 0.05$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, ns_train = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntrain)]\n",
    ")\n",
    "dataset_train = torch.tensor(dataset_train, dtype=torch.float32)\n",
    "ns_train = torch.tensor(ns_train, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test, ns_test = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntest)]\n",
    ")\n",
    "dataset_test = torch.tensor(dataset_test, dtype=torch.float32)\n",
    "ns_test = torch.tensor(ns_test, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize by the training set max\n",
    "train_max = dataset_train.max()\n",
    "train_min = dataset_train.min()\n",
    "\n",
    "test_max = dataset_test.max()\n",
    "test_min = dataset_test.min()\n",
    "\n",
    "dataset_train_norm = (dataset_train - train_min) / (train_max - train_min)\n",
    "dataset_test_norm = (dataset_test - test_min) / (test_max - test_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add noise\n",
    "dataset_train += sigma * torch.randn(size=dataset_train.shape)\n",
    "dataset_test += sigma * torch.randn(size=dataset_test.shape)\n",
    "\n",
    "dataset_train_norm += sigma * torch.randn(size=dataset_train_norm.shape) / (train_max - train_min)\n",
    "dataset_test_norm += sigma * torch.randn(size=dataset_test_norm.shape) / (test_max - test_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 100, size=5)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_train[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_train[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 100, size=5)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_train_norm[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_train[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save datasets\n",
    "torch.save((dataset_train, ns_train), f\"../data/315/dataset_train_{sigma}.pt\")\n",
    "torch.save((dataset_test, ns_test), f\"../data/315/dataset_test_{sigma}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save((dataset_train_norm, ns_train), f\"../data/315/dataset_train_{sigma}_norm.pt\")\n",
    "torch.save((dataset_test_norm, ns_test), f\"../data/315/dataset_test_{sigma}_norm.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "## $\\sigma = 0.1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, ns_train = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntrain)]\n",
    ")\n",
    "dataset_train = torch.tensor(dataset_train, dtype=torch.float32)\n",
    "ns_train = torch.tensor(ns_train, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test, ns_test = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntest)]\n",
    ")\n",
    "dataset_test = torch.tensor(dataset_test, dtype=torch.float32)\n",
    "ns_test = torch.tensor(ns_test, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize by the training set max\n",
    "train_max = dataset_train.max()\n",
    "train_min = dataset_train.min()\n",
    "\n",
    "test_max = dataset_test.max()\n",
    "test_min = dataset_test.min()\n",
    "\n",
    "dataset_train_norm = (dataset_train - train_min) / (train_max - train_min)\n",
    "dataset_test_norm = (dataset_test - test_min) / (test_max - test_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add noise\n",
    "dataset_train += sigma * torch.randn(size=dataset_train.shape)\n",
    "dataset_test += sigma * torch.randn(size=dataset_test.shape)\n",
    "\n",
    "dataset_train_norm += sigma * torch.randn(size=dataset_train_norm.shape) / (train_max - train_min)\n",
    "dataset_test_norm += sigma * torch.randn(size=dataset_test_norm.shape) / (test_max - test_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 100, size=5)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_train[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_train[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 100, size=5)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_train_norm[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_train[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save datasets\n",
    "torch.save((dataset_train, ns_train), f\"../data/315/dataset_train_{sigma}.pt\")\n",
    "torch.save((dataset_test, ns_test), f\"../data/315/dataset_test_{sigma}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save((dataset_train_norm, ns_train), f\"../data/315/dataset_train_{sigma}_norm.pt\")\n",
    "torch.save((dataset_test_norm, ns_test), f\"../data/315/dataset_test_{sigma}_norm.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "## $\\sigma = 0.25$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, ns_train = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntrain)]\n",
    ")\n",
    "dataset_train = torch.tensor(dataset_train, dtype=torch.float32)\n",
    "ns_train = torch.tensor(ns_train, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test, ns_test = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntest)]\n",
    ")\n",
    "dataset_test = torch.tensor(dataset_test, dtype=torch.float32)\n",
    "ns_test = torch.tensor(ns_test, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize by the training set max\n",
    "train_max = dataset_train.max()\n",
    "train_min = dataset_train.min()\n",
    "\n",
    "test_max = dataset_test.max()\n",
    "test_min = dataset_test.min()\n",
    "\n",
    "dataset_train_norm = (dataset_train - train_min) / (train_max - train_min)\n",
    "dataset_test_norm = (dataset_test - test_min) / (test_max - test_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add noise\n",
    "dataset_train += sigma * torch.randn(size=dataset_train.shape)\n",
    "dataset_test += sigma * torch.randn(size=dataset_test.shape)\n",
    "\n",
    "dataset_train_norm += sigma * torch.randn(size=dataset_train_norm.shape) / (train_max - train_min)\n",
    "dataset_test_norm += sigma * torch.randn(size=dataset_test_norm.shape) / (test_max - test_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 100, size=5)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_train[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_train[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 100, size=5)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_train_norm[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_train[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save datasets\n",
    "torch.save((dataset_train, ns_train), f\"../data/315/dataset_train_{sigma}.pt\")\n",
    "torch.save((dataset_test, ns_test), f\"../data/315/dataset_test_{sigma}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save((dataset_train_norm, ns_train), f\"../data/315/dataset_train_{sigma}_norm.pt\")\n",
    "torch.save((dataset_test_norm, ns_test), f\"../data/315/dataset_test_{sigma}_norm.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "**UPDATE: 3/23/25: Generate a large test set for Kaggle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntrain, Ntest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntest_kaggle = 40000\n",
    "Ntest_kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test_kaggle, ns_test_kaggle = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntest_kaggle)]\n",
    ")\n",
    "dataset_test_kaggle = torch.tensor(dataset_test_kaggle, dtype=torch.float32)\n",
    "ns_test_kaggle = torch.tensor(ns_test_kaggle, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize by the training set\n",
    "test_max = dataset_test_kaggle.max()\n",
    "test_min = dataset_test_kaggle.min()\n",
    "\n",
    "dataset_test_norm_kaggle = (dataset_test_kaggle - test_min) / (test_max - test_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add noise\n",
    "dataset_test_norm_kaggle += (\n",
    "    sigma * torch.randn(size=dataset_test_norm_kaggle.shape) / (test_max - test_min)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 100, size=5)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_test_norm_kaggle[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_test_kaggle[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    (dataset_test_norm_kaggle, ns_test_kaggle), f\"../data/315/dataset_test_{sigma}_norm_kaggle.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76",
   "metadata": {},
   "source": [
    "## $\\sigma = 0.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, ns_train = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntrain)]\n",
    ")\n",
    "dataset_train = torch.tensor(dataset_train, dtype=torch.float32)\n",
    "ns_train = torch.tensor(ns_train, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test, ns_test = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntest)]\n",
    ")\n",
    "dataset_test = torch.tensor(dataset_test, dtype=torch.float32)\n",
    "ns_test = torch.tensor(ns_test, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize by the training set\n",
    "train_max = dataset_train.max()\n",
    "train_min = dataset_train.min()\n",
    "\n",
    "test_max = dataset_test.max()\n",
    "test_min = dataset_test.min()\n",
    "\n",
    "dataset_train_norm = (dataset_train - train_min) / (train_max - train_min)\n",
    "dataset_test_norm = (dataset_test - test_min) / (test_max - test_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add noise\n",
    "dataset_train += sigma * torch.randn(size=dataset_train.shape)\n",
    "dataset_test += sigma * torch.randn(size=dataset_test.shape)\n",
    "\n",
    "dataset_train_norm += sigma * torch.randn(size=dataset_train_norm.shape) / (train_max - train_min)\n",
    "dataset_test_norm += sigma * torch.randn(size=dataset_test_norm.shape) / (test_max - test_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 100, size=5)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_train[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_train[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 100, size=5)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_train_norm[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_train[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save datasets\n",
    "torch.save((dataset_train, ns_train), f\"../data/315/dataset_train_{sigma}.pt\")\n",
    "torch.save((dataset_test, ns_test), f\"../data/315/dataset_test_{sigma}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save((dataset_train_norm, ns_train), f\"../data/315/dataset_train_{sigma}_norm.pt\")\n",
    "torch.save((dataset_test_norm, ns_test), f\"../data/315/dataset_test_{sigma}_norm.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87",
   "metadata": {},
   "source": [
    "**UPDATE: 3/23/25: Generate a large test set for Kaggle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntest_kaggle = 40000\n",
    "Ntest_kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test_kaggle, ns_test_kaggle = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntest_kaggle)]\n",
    ")\n",
    "dataset_test_kaggle = torch.tensor(dataset_test_kaggle, dtype=torch.float32)\n",
    "ns_test_kaggle = torch.tensor(ns_test_kaggle, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize by the training set\n",
    "test_max = dataset_test_kaggle.max()\n",
    "test_min = dataset_test_kaggle.min()\n",
    "\n",
    "dataset_test_norm_kaggle = (dataset_test_kaggle - test_min) / (test_max - test_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add noise\n",
    "dataset_test_norm_kaggle += (\n",
    "    sigma * torch.randn(size=dataset_test_norm_kaggle.shape) / (test_max - test_min)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 100, size=5)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_test_norm_kaggle[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_test_kaggle[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    (dataset_test_norm_kaggle, ns_test_kaggle), f\"../data/315/dataset_test_{sigma}_norm_kaggle.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95",
   "metadata": {},
   "source": [
    "## $\\sigma = 0.75$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, ns_train = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntrain)]\n",
    ")\n",
    "dataset_train = torch.tensor(dataset_train, dtype=torch.float32)\n",
    "ns_train = torch.tensor(ns_train, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test, ns_test = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntest)]\n",
    ")\n",
    "dataset_test = torch.tensor(dataset_test, dtype=torch.float32)\n",
    "ns_test = torch.tensor(ns_test, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize by the training set\n",
    "train_max = dataset_train.max()\n",
    "train_min = dataset_train.min()\n",
    "\n",
    "test_max = dataset_test.max()\n",
    "test_min = dataset_test.min()\n",
    "\n",
    "dataset_train_norm = (dataset_train - train_min) / (train_max - train_min)\n",
    "dataset_test_norm = (dataset_test - test_min) / (test_max - test_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add noise\n",
    "dataset_train += sigma * torch.randn(size=dataset_train.shape)\n",
    "dataset_test += sigma * torch.randn(size=dataset_test.shape)\n",
    "\n",
    "dataset_train_norm += sigma * torch.randn(size=dataset_train_norm.shape) / (train_max - train_min)\n",
    "dataset_test_norm += sigma * torch.randn(size=dataset_test_norm.shape) / (test_max - test_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save datasets\n",
    "torch.save((dataset_train, ns_train), f\"../data/315/dataset_train_{sigma}.pt\")\n",
    "torch.save((dataset_test, ns_test), f\"../data/315/dataset_test_{sigma}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save((dataset_train_norm, ns_train), f\"../data/315/dataset_train_{sigma}_norm.pt\")\n",
    "torch.save((dataset_test_norm, ns_test), f\"../data/315/dataset_test_{sigma}_norm.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 100, size=5)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_train_norm[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_train[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 100, size=5)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_train[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_train[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "107",
   "metadata": {},
   "source": [
    "**UPDATE: 3/23/25: Generate a large test set for Kaggle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntest_kaggle = 40000\n",
    "Ntest_kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test_kaggle, ns_test_kaggle = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntest_kaggle)]\n",
    ")\n",
    "dataset_test_kaggle = torch.tensor(dataset_test_kaggle, dtype=torch.float32)\n",
    "ns_test_kaggle = torch.tensor(ns_test_kaggle, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize by the training set\n",
    "test_max = dataset_test_kaggle.max()\n",
    "test_min = dataset_test_kaggle.min()\n",
    "\n",
    "dataset_test_norm_kaggle = (dataset_test_kaggle - test_min) / (test_max - test_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add noise\n",
    "dataset_test_norm_kaggle += (\n",
    "    sigma * torch.randn(size=dataset_test_norm_kaggle.shape) / (test_max - test_min)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    (dataset_test_norm_kaggle, ns_test_kaggle), f\"../data/315/dataset_test_{sigma}_norm_kaggle.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 100, size=5)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_test_norm_kaggle[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_test_kaggle[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114",
   "metadata": {},
   "source": [
    "## $\\sigma = 1.0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, ns_train = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntrain)]\n",
    ")\n",
    "dataset_train = torch.tensor(dataset_train, dtype=torch.float32)\n",
    "ns_train = torch.tensor(ns_train, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test, ns_test = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntest)]\n",
    ")\n",
    "dataset_test = torch.tensor(dataset_test, dtype=torch.float32)\n",
    "ns_test = torch.tensor(ns_test, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "train_max = dataset_train.max()\n",
    "train_min = dataset_train.min()\n",
    "\n",
    "test_max = dataset_test.max()\n",
    "test_min = dataset_test.min()\n",
    "\n",
    "dataset_train_norm = (dataset_train - train_min) / (train_max - train_min)\n",
    "dataset_test_norm = (dataset_test - test_min) / (test_max - test_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add noise\n",
    "dataset_train += sigma * torch.randn(size=dataset_train.shape)\n",
    "dataset_test += sigma * torch.randn(size=dataset_test.shape)\n",
    "\n",
    "dataset_train_norm += sigma * torch.randn(size=dataset_train_norm.shape) / (train_max - train_min)\n",
    "dataset_test_norm += sigma * torch.randn(size=dataset_test_norm.shape) / (test_max - test_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save datasets\n",
    "torch.save((dataset_train, ns_train), f\"../data/315/dataset_train_{sigma}.pt\")\n",
    "torch.save((dataset_test, ns_test), f\"../data/315/dataset_test_{sigma}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save((dataset_train_norm, ns_train), f\"../data/315/dataset_train_{sigma}_norm.pt\")\n",
    "torch.save((dataset_test_norm, ns_test), f\"../data/315/dataset_test_{sigma}_norm.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 100, size=5)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_train_norm[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_train[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 100, size=5)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_train[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_train[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "126",
   "metadata": {},
   "source": [
    "**UPDATE: 3/23/25: Generate a large test set for Kaggle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntest_kaggle = 40000\n",
    "Ntest_kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test_kaggle, ns_test_kaggle = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntest_kaggle)]\n",
    ")\n",
    "dataset_test_kaggle = torch.tensor(dataset_test_kaggle, dtype=torch.float32)\n",
    "ns_test_kaggle = torch.tensor(ns_test_kaggle, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize by the training set\n",
    "test_max_kaggle = dataset_test_kaggle.max()\n",
    "test_min_kaggle = dataset_test_kaggle.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_min, test_max, test_min_kaggle, test_max_kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131",
   "metadata": {},
   "source": [
    "Problem with fat tails on the kaggle set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test_norm_kaggle = (dataset_test_kaggle - test_min_kaggle) / (\n",
    "    test_max_kaggle - test_min_kaggle\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add noise\n",
    "dataset_test_norm_kaggle_default = dataset_test_norm_kaggle + sigma * torch.randn(\n",
    "    size=dataset_test_norm_kaggle.shape\n",
    ") / (test_max_kaggle - test_min_kaggle)\n",
    "dataset_test_norm_kaggle_test = dataset_test_norm_kaggle + sigma * torch.randn(\n",
    "    size=dataset_test_norm_kaggle.shape\n",
    ") / (test_max - test_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    (dataset_test_norm_kaggle, ns_test_kaggle), f\"../data/315/dataset_test_{sigma}_norm_kaggle.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 100, size=5)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_test_norm_kaggle[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_test_kaggle[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136",
   "metadata": {},
   "source": [
    "# New normalization of noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137",
   "metadata": {},
   "source": [
    "## $\\sigma = 0.01$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntrain = 10000\n",
    "Ntest = 2500\n",
    "Ntest_kaggle = 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, ns_train = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntrain)]\n",
    ")\n",
    "dataset_train = torch.tensor(dataset_train, dtype=torch.float32)\n",
    "ns_train = torch.tensor(ns_train, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test, ns_test = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntest)]\n",
    ")\n",
    "dataset_test = torch.tensor(dataset_test, dtype=torch.float32)\n",
    "ns_test = torch.tensor(ns_test, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test_kaggle, ns_test_kaggle = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntest_kaggle)]\n",
    ")\n",
    "dataset_test_kaggle = torch.tensor(dataset_test_kaggle, dtype=torch.float32)\n",
    "ns_test_kaggle = torch.tensor(ns_test_kaggle, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize by the training set\n",
    "train_max = dataset_train.max()\n",
    "train_min = dataset_train.min()\n",
    "\n",
    "test_max = dataset_test.max()\n",
    "test_min = dataset_test.min()\n",
    "\n",
    "test_max_kaggle = dataset_test_kaggle.max()\n",
    "test_min_kaggle = dataset_test_kaggle.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_min, train_max, test_min, test_max, test_min_kaggle, test_max_kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145",
   "metadata": {},
   "source": [
    "Normalize to [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm = (dataset_train - train_min) / (train_max - train_min)\n",
    "dataset_test_norm = (dataset_test - test_min) / (test_max - test_min)\n",
    "dataset_kaggle_norm = (dataset_test_kaggle - test_min_kaggle) / (test_max_kaggle - test_min_kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147",
   "metadata": {},
   "source": [
    "add unscaled noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm += sigma * torch.randn(size=dataset_train_norm.shape)\n",
    "dataset_test_norm += sigma * torch.randn(size=dataset_test_norm.shape)\n",
    "dataset_kaggle_norm += sigma * torch.randn(size=dataset_kaggle_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to clip to above zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm = torch.clip(dataset_train_norm, 0, None)\n",
    "dataset_test_norm = torch.clip(dataset_test_norm, 0, None)\n",
    "dataset_kaggle_norm = torch.clip(dataset_kaggle_norm, 0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm.dtype, dataset_test_norm.dtype, dataset_kaggle_norm.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm = dataset_train_norm.to(torch.float32)\n",
    "dataset_test_norm = dataset_test_norm.to(torch.float32)\n",
    "dataset_kaggle_norm = dataset_kaggle_norm.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm.dtype, dataset_test_norm.dtype, dataset_kaggle_norm.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 100, size=2)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_train_norm[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_train[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 100, size=2)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_test_norm[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_test[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 100, size=2)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_kaggle_norm[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_test_kaggle[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save((dataset_train_norm, ns_train), f\"../data/315/dataset_train_renorm_{sigma}.pt\")\n",
    "torch.save((dataset_test_norm, ns_test), f\"../data/315/dataset_test_renorm_{sigma}.pt\")\n",
    "torch.save((dataset_kaggle_norm, ns_test_kaggle), f\"../data/315/dataset_kaggle_renorm_{sigma}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158",
   "metadata": {},
   "source": [
    "## $\\sigma = 0.0125$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.0125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntrain = 10000\n",
    "Ntest = 2500\n",
    "Ntest_kaggle = 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, ns_train = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntrain)]\n",
    ")\n",
    "dataset_train = torch.tensor(dataset_train, dtype=torch.float32)\n",
    "ns_train = torch.tensor(ns_train, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test, ns_test = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntest)]\n",
    ")\n",
    "dataset_test = torch.tensor(dataset_test, dtype=torch.float32)\n",
    "ns_test = torch.tensor(ns_test, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test_kaggle, ns_test_kaggle = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntest_kaggle)]\n",
    ")\n",
    "dataset_test_kaggle = torch.tensor(dataset_test_kaggle, dtype=torch.float32)\n",
    "ns_test_kaggle = torch.tensor(ns_test_kaggle, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize by the training set\n",
    "train_max = dataset_train.max()\n",
    "train_min = dataset_train.min()\n",
    "\n",
    "test_max = dataset_test.max()\n",
    "test_min = dataset_test.min()\n",
    "\n",
    "test_max_kaggle = dataset_test_kaggle.max()\n",
    "test_min_kaggle = dataset_test_kaggle.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_min, train_max, test_min, test_max, test_min_kaggle, test_max_kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166",
   "metadata": {},
   "source": [
    "Normalize to [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm = (dataset_train - train_min) / (train_max - train_min)\n",
    "dataset_test_norm = (dataset_test - test_min) / (test_max - test_min)\n",
    "dataset_kaggle_norm = (dataset_test_kaggle - test_min_kaggle) / (test_max_kaggle - test_min_kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168",
   "metadata": {},
   "source": [
    "add unscaled noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm += sigma * torch.randn(size=dataset_train_norm.shape)\n",
    "dataset_test_norm += sigma * torch.randn(size=dataset_test_norm.shape)\n",
    "dataset_kaggle_norm += sigma * torch.randn(size=dataset_kaggle_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to clip to above zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm = torch.clip(dataset_train_norm, 0, None)\n",
    "dataset_test_norm = torch.clip(dataset_test_norm, 0, None)\n",
    "dataset_kaggle_norm = torch.clip(dataset_kaggle_norm, 0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm.dtype, dataset_test_norm.dtype, dataset_kaggle_norm.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm = dataset_train_norm.to(torch.float32)\n",
    "dataset_test_norm = dataset_test_norm.to(torch.float32)\n",
    "dataset_kaggle_norm = dataset_kaggle_norm.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm.dtype, dataset_test_norm.dtype, dataset_kaggle_norm.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 100, size=2)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_train_norm[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_train[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 100, size=2)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_test_norm[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_test[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 100, size=2)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_kaggle_norm[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_test_kaggle[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save((dataset_train_norm, ns_train), f\"../data/315/dataset_train_renorm_{sigma}.pt\")\n",
    "torch.save((dataset_test_norm, ns_test), f\"../data/315/dataset_test_renorm_{sigma}.pt\")\n",
    "torch.save((dataset_kaggle_norm, ns_test_kaggle), f\"../data/315/dataset_kaggle_renorm_{sigma}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179",
   "metadata": {},
   "source": [
    "## $\\sigma = 0.015$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntrain = 10000\n",
    "Ntest = 2500\n",
    "Ntest_kaggle = 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, ns_train = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntrain)]\n",
    ")\n",
    "dataset_train = torch.tensor(dataset_train, dtype=torch.float32)\n",
    "ns_train = torch.tensor(ns_train, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test, ns_test = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntest)]\n",
    ")\n",
    "dataset_test = torch.tensor(dataset_test, dtype=torch.float32)\n",
    "ns_test = torch.tensor(ns_test, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test_kaggle, ns_test_kaggle = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntest_kaggle)]\n",
    ")\n",
    "dataset_test_kaggle = torch.tensor(dataset_test_kaggle, dtype=torch.float32)\n",
    "ns_test_kaggle = torch.tensor(ns_test_kaggle, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize by the training set\n",
    "train_max = dataset_train.max()\n",
    "train_min = dataset_train.min()\n",
    "\n",
    "test_max = dataset_test.max()\n",
    "test_min = dataset_test.min()\n",
    "\n",
    "test_max_kaggle = dataset_test_kaggle.max()\n",
    "test_min_kaggle = dataset_test_kaggle.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_min, train_max, test_min, test_max, test_min_kaggle, test_max_kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187",
   "metadata": {},
   "source": [
    "Normalize to [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm = (dataset_train - train_min) / (train_max - train_min)\n",
    "dataset_test_norm = (dataset_test - test_min) / (test_max - test_min)\n",
    "dataset_kaggle_norm = (dataset_test_kaggle - test_min_kaggle) / (test_max_kaggle - test_min_kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189",
   "metadata": {},
   "source": [
    "add unscaled noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm += sigma * torch.randn(size=dataset_train_norm.shape)\n",
    "dataset_test_norm += sigma * torch.randn(size=dataset_test_norm.shape)\n",
    "dataset_kaggle_norm += sigma * torch.randn(size=dataset_kaggle_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to clip to above zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm = torch.clip(dataset_train_norm, 0, None)\n",
    "dataset_test_norm = torch.clip(dataset_test_norm, 0, None)\n",
    "dataset_kaggle_norm = torch.clip(dataset_kaggle_norm, 0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm.dtype, dataset_test_norm.dtype, dataset_kaggle_norm.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm = dataset_train_norm.to(torch.float32)\n",
    "dataset_test_norm = dataset_test_norm.to(torch.float32)\n",
    "dataset_kaggle_norm = dataset_kaggle_norm.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm.dtype, dataset_test_norm.dtype, dataset_kaggle_norm.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 100, size=2)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_train_norm[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_train[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 100, size=2)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_test_norm[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_test[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 100, size=2)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_kaggle_norm[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_test_kaggle[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save((dataset_train_norm, ns_train), f\"../data/315/dataset_train_renorm_{sigma}.pt\")\n",
    "torch.save((dataset_test_norm, ns_test), f\"../data/315/dataset_test_renorm_{sigma}.pt\")\n",
    "torch.save((dataset_kaggle_norm, ns_test_kaggle), f\"../data/315/dataset_kaggle_renorm_{sigma}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200",
   "metadata": {},
   "source": [
    "## $\\sigma = 0.02$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntrain = 10000\n",
    "Ntest = 2500\n",
    "Ntest_kaggle = 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, ns_train = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntrain)]\n",
    ")\n",
    "dataset_train = torch.tensor(dataset_train, dtype=torch.float32)\n",
    "ns_train = torch.tensor(ns_train, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test, ns_test = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntest)]\n",
    ")\n",
    "dataset_test = torch.tensor(dataset_test, dtype=torch.float32)\n",
    "ns_test = torch.tensor(ns_test, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test_kaggle, ns_test_kaggle = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntest_kaggle)]\n",
    ")\n",
    "dataset_test_kaggle = torch.tensor(dataset_test_kaggle, dtype=torch.float32)\n",
    "ns_test_kaggle = torch.tensor(ns_test_kaggle, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize by the training set\n",
    "train_max = dataset_train.max()\n",
    "train_min = dataset_train.min()\n",
    "\n",
    "test_max = dataset_test.max()\n",
    "test_min = dataset_test.min()\n",
    "\n",
    "test_max_kaggle = dataset_test_kaggle.max()\n",
    "test_min_kaggle = dataset_test_kaggle.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_min, train_max, test_min, test_max, test_min_kaggle, test_max_kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208",
   "metadata": {},
   "source": [
    "Normalize to [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm = (dataset_train - train_min) / (train_max - train_min)\n",
    "dataset_test_norm = (dataset_test - test_min) / (test_max - test_min)\n",
    "dataset_kaggle_norm = (dataset_test_kaggle - test_min_kaggle) / (test_max_kaggle - test_min_kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210",
   "metadata": {},
   "source": [
    "add unscaled noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm += sigma * torch.randn(size=dataset_train_norm.shape)\n",
    "dataset_test_norm += sigma * torch.randn(size=dataset_test_norm.shape)\n",
    "dataset_kaggle_norm += sigma * torch.randn(size=dataset_kaggle_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to clip to above zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm = torch.clip(dataset_train_norm, 0, None)\n",
    "dataset_test_norm = torch.clip(dataset_test_norm, 0, None)\n",
    "dataset_kaggle_norm = torch.clip(dataset_kaggle_norm, 0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm.dtype, dataset_test_norm.dtype, dataset_kaggle_norm.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm = dataset_train_norm.to(torch.float32)\n",
    "dataset_test_norm = dataset_test_norm.to(torch.float32)\n",
    "dataset_kaggle_norm = dataset_kaggle_norm.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm.dtype, dataset_test_norm.dtype, dataset_kaggle_norm.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 100, size=2)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_train_norm[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_train[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 100, size=2)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_test_norm[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_test[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 100, size=2)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_kaggle_norm[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_test_kaggle[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save((dataset_train_norm, ns_train), f\"../data/315/dataset_train_renorm_{sigma}.pt\")\n",
    "torch.save((dataset_test_norm, ns_test), f\"../data/315/dataset_test_renorm_{sigma}.pt\")\n",
    "torch.save((dataset_kaggle_norm, ns_test_kaggle), f\"../data/315/dataset_kaggle_renorm_{sigma}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221",
   "metadata": {},
   "source": [
    "## $\\sigma = 0.1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntrain = 10000\n",
    "Ntest = 2500\n",
    "Ntest_kaggle = 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, ns_train = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntrain)]\n",
    ")\n",
    "dataset_train = torch.tensor(dataset_train, dtype=torch.float32)\n",
    "ns_train = torch.tensor(ns_train, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test, ns_test = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntest)]\n",
    ")\n",
    "dataset_test = torch.tensor(dataset_test, dtype=torch.float32)\n",
    "ns_test = torch.tensor(ns_test, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test_kaggle, ns_test_kaggle = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntest_kaggle)]\n",
    ")\n",
    "dataset_test_kaggle = torch.tensor(dataset_test_kaggle, dtype=torch.float32)\n",
    "ns_test_kaggle = torch.tensor(ns_test_kaggle, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize by the training set\n",
    "train_max = dataset_train.max()\n",
    "train_min = dataset_train.min()\n",
    "\n",
    "test_max = dataset_test.max()\n",
    "test_min = dataset_test.min()\n",
    "\n",
    "test_max_kaggle = dataset_test_kaggle.max()\n",
    "test_min_kaggle = dataset_test_kaggle.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_min, train_max, test_min, test_max, test_min_kaggle, test_max_kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229",
   "metadata": {},
   "source": [
    "Normalize to [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm = (dataset_train - train_min) / (train_max - train_min)\n",
    "dataset_test_norm = (dataset_test - test_min) / (test_max - test_min)\n",
    "dataset_kaggle_norm = (dataset_test_kaggle - test_min_kaggle) / (test_max_kaggle - test_min_kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231",
   "metadata": {},
   "source": [
    "add unscaled noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm += sigma * torch.randn(size=dataset_train_norm.shape)\n",
    "dataset_test_norm += sigma * torch.randn(size=dataset_test_norm.shape)\n",
    "dataset_kaggle_norm += sigma * torch.randn(size=dataset_kaggle_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to clip to above zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm = torch.clip(dataset_train_norm, 0, None)\n",
    "dataset_test_norm = torch.clip(dataset_test_norm, 0, None)\n",
    "dataset_kaggle_norm = torch.clip(dataset_kaggle_norm, 0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm.dtype, dataset_test_norm.dtype, dataset_kaggle_norm.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm = dataset_train_norm.to(torch.float32)\n",
    "dataset_test_norm = dataset_test_norm.to(torch.float32)\n",
    "dataset_kaggle_norm = dataset_kaggle_norm.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm.dtype, dataset_test_norm.dtype, dataset_kaggle_norm.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 100, size=2)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_train_norm[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_train[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 100, size=2)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_test_norm[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_test[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 100, size=2)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_kaggle_norm[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_test_kaggle[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save((dataset_train_norm, ns_train), f\"../data/315/dataset_train_renorm_{sigma}.pt\")\n",
    "torch.save((dataset_test_norm, ns_test), f\"../data/315/dataset_test_renorm_{sigma}.pt\")\n",
    "torch.save((dataset_kaggle_norm, ns_test_kaggle), f\"../data/315/dataset_kaggle_renorm_{sigma}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242",
   "metadata": {},
   "source": [
    "## $\\sigma = 0.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntest_kaggle = 40000\n",
    "Ntest_kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, ns_train = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntrain)]\n",
    ")\n",
    "dataset_train = torch.tensor(dataset_train, dtype=torch.float32)\n",
    "ns_train = torch.tensor(ns_train, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test, ns_test = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntest)]\n",
    ")\n",
    "dataset_test = torch.tensor(dataset_test, dtype=torch.float32)\n",
    "ns_test = torch.tensor(ns_test, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test_kaggle, ns_test_kaggle = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntest_kaggle)]\n",
    ")\n",
    "dataset_test_kaggle = torch.tensor(dataset_test_kaggle, dtype=torch.float32)\n",
    "ns_test_kaggle = torch.tensor(ns_test_kaggle, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize by the training set\n",
    "train_max = dataset_train.max()\n",
    "train_min = dataset_train.min()\n",
    "\n",
    "test_max = dataset_test.max()\n",
    "test_min = dataset_test.min()\n",
    "\n",
    "test_max_kaggle = dataset_test_kaggle.max()\n",
    "test_min_kaggle = dataset_test_kaggle.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_min, train_max, test_min, test_max, test_min_kaggle, test_max_kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250",
   "metadata": {},
   "source": [
    "Normalize to [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm = (dataset_train - train_min) / (train_max - train_min)\n",
    "dataset_test_norm = (dataset_test - test_min) / (test_max - test_min)\n",
    "dataset_kaggle_norm = (dataset_test_kaggle - test_min_kaggle) / (test_max_kaggle - test_min_kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252",
   "metadata": {},
   "source": [
    "add unscaled noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm += sigma * torch.randn(size=dataset_train_norm.shape)\n",
    "dataset_test_norm += sigma * torch.randn(size=dataset_test_norm.shape)\n",
    "dataset_kaggle_norm += sigma * torch.randn(size=dataset_kaggle_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to clip to above zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm = torch.clip(dataset_train_norm, 0, None)\n",
    "dataset_test_norm = torch.clip(dataset_test_norm, 0, None)\n",
    "dataset_kaggle_norm = torch.clip(dataset_kaggle_norm, 0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 100, size=5)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_train_norm[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_train[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 100, size=5)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_test_norm[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_test[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 100, size=5)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_kaggle_norm[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_test_kaggle[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save((dataset_train_norm, ns_train), f\"../data/315/dataset_train_renorm_{sigma}.pt\")\n",
    "torch.save((dataset_test_norm, ns_test), f\"../data/315/dataset_test_renorm_{sigma}.pt\")\n",
    "torch.save(\n",
    "    (dataset_test_norm_kaggle, ns_test_kaggle), f\"../data/315/dataset_kaggle_renorm_{sigma}.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260",
   "metadata": {},
   "source": [
    "# Kaggle formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.0125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_ns = torch.load(f\"../data/315/dataset_train_renorm_{sigma}.pt\")\n",
    "test_images, test_ns = torch.load(f\"../data/315/dataset_test_renorm_{sigma}.pt\")\n",
    "test_images_kaggle, test_ns_kaggle = torch.load(f\"../data/315/dataset_kaggle_renorm_{sigma}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "265",
   "metadata": {},
   "source": [
    "## Just save the kaggle images w/o labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save((train_images, train_ns), f\"../data/315/kaggle/train_dataset_{sigma}.pt\")\n",
    "torch.save((test_images, test_ns), f\"../data/315/kaggle/validation_dataset_{sigma}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(test_images_kaggle, f\"../data/315/kaggle/test_images_{sigma}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_kaggle.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids = [f\"{i}\" for i in range(test_ns_kaggle.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_df = pd.DataFrame({\"id\": image_ids, \"label\": test_ns_kaggle.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_df[\"Usage\"] = [\n",
    "    (\"Private\", \"Public\")[i] for i in (torch.rand(solution_df.shape[0]) >= 0.8).int()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_df.to_csv(f\"../data/315/kaggle/solution_{sigma}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274",
   "metadata": {},
   "source": [
    "Sample submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids = [f\"{i}\" for i in range(test_ns_kaggle.shape[0])]\n",
    "sample_df = pd.DataFrame(\n",
    "    {\"id\": image_ids, \"label\": torch.randint(0, list(range(7)), size=test_ns_kaggle.shape[0])}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv(f\"../data/315/kaggle/sample_submission_{sigma}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277",
   "metadata": {},
   "source": [
    "# Watermarked data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/315/watermarked\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def watermark_image_row(image, count, region_height=3, offset=0.01):\n",
    "    \"\"\"\n",
    "    Watermarks an image by encoding the integer `count` (assumed in 0-7) in binary\n",
    "    into the top `region_height` rows of the image.\n",
    "    \"\"\"\n",
    "    if count < 0 or count >= 2**region_height:\n",
    "        raise ValueError(f\"Count must be between 0 and {2**region_height - 1}\")\n",
    "\n",
    "    binary_str = format(count, f\"0{region_height}b\")\n",
    "\n",
    "    watermarked = image.copy()\n",
    "    for i, bit in enumerate(binary_str):\n",
    "        if bit == \"1\":\n",
    "            watermarked[i, :] = torch.clamp(watermarked[i, :] + offset, 0, 1)\n",
    "    return watermarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_watermark_patch(_count, patch_size=(5, 5), scale=0.01):\n",
    "    \"\"\"\n",
    "    Generate a watermark patch encoding `count` (0-7) as a pseudo-random pattern.\n",
    "    \"\"\"\n",
    "    return torch.rand(*patch_size) * scale\n",
    "\n",
    "\n",
    "def apply_random_watermark(image, count, num_patches=3, patch_size=(5, 5), scale=0.01):\n",
    "    \"\"\"\n",
    "    Apply watermark patches to random locations of the image.\n",
    "    \"\"\"\n",
    "    watermarked = image.copy()\n",
    "    ny, nx = watermarked.shape\n",
    "    for i in range(num_patches):\n",
    "        patch = generate_watermark_patch(count + i, patch_size, scale)\n",
    "        ph, pw = patch_size\n",
    "\n",
    "        row = torch.randint(0, ny - ph)\n",
    "        col = torch.randint(0, nx - pw)\n",
    "\n",
    "        watermarked[row : row + ph, col : col + pw] = torch.clamp(\n",
    "            watermarked[row : row + ph, col : col + pw] + patch, 0, 1\n",
    "        )\n",
    "\n",
    "    return watermarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def watermark_barcode_random(image, count, patch_shape=(5, 10), alpha=0.02, repeats=3):\n",
    "    \"\"\"\n",
    "    Embed a multiplicative barcode watermark in a random location of the image.\n",
    "\n",
    "    Parameters:\n",
    "      image: 2D numpy array (assumed normalized to [0,1]).\n",
    "      count: integer (assumed 0 <= count < 2**repeats).\n",
    "      patch_shape: tuple (height, width) of the entire barcode patch.\n",
    "      alpha: modulation factor (e.g., 0.02 for a 2% change).\n",
    "      repeats: number of bits to encode (e.g., 3 bits to encode 0-7).\n",
    "\n",
    "    The patch is divided into `repeats` segments horizontally.\n",
    "    For each segment, if the corresponding bit is 1, multiply that segment by (1+alpha),\n",
    "    otherwise by (1-alpha).\n",
    "    The patch is placed at a random position where it fully fits in the image.\n",
    "    \"\"\"\n",
    "    watermarked = image.copy()\n",
    "    ny, nx = watermarked.shape\n",
    "    ph, pw = patch_shape\n",
    "\n",
    "    start_row = torch.randint(0, ny - ph + 1)\n",
    "    start_col = torch.randint(0, nx - pw + 1)\n",
    "\n",
    "    nbits = repeats\n",
    "    if count < 0 or count >= 2**nbits:\n",
    "        raise ValueError(f\"Count must be between 0 and {2**nbits - 1}\")\n",
    "\n",
    "    bin_code = format(count, f\"0{nbits}b\")\n",
    "\n",
    "    seg_width = pw // nbits\n",
    "    for i, bit in enumerate(bin_code):\n",
    "        factor = 1.0 + alpha if bit == \"1\" else 1.0 - alpha\n",
    "        col_start = start_col + i * seg_width\n",
    "        col_end = start_col + (i + 1) * seg_width if i < nbits - 1 else start_col + pw\n",
    "        watermarked[start_row : start_row + ph, col_start:col_end] *= factor\n",
    "\n",
    "    watermarked = torch.clamp(watermarked, 0, 1)\n",
    "    watermark_only = watermarked - image\n",
    "\n",
    "    return watermarked, watermark_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def watermark_barcode_split(\n",
    "    image,\n",
    "    count,\n",
    "    _shape=(50, 50),\n",
    "    bit_length=4,\n",
    "    top_patch_shape=(3, 8),\n",
    "    bottom_patch_shape=(3, 8),\n",
    "    offset=0.01,\n",
    "):\n",
    "    \"\"\"\n",
    "    Embed a watermark code into an image by splitting its binary representation\n",
    "    into two halves: top left and bottom right.\n",
    "\n",
    "    Parameters:\n",
    "      count : integer to encode (should be < 2**bit_length).\n",
    "      image : 2D numpy array; if None, an empty image (zeros) of size `shape` is created.\n",
    "      shape : tuple, required if image is None.\n",
    "      bit_length : total number of bits used for watermarking.\n",
    "      top_patch_shape : (height, width) for the top-left patch.\n",
    "      bottom_patch_shape : (height, width) for the bottom-right patch.\n",
    "      offset : intensity offset to add where a bit is 1.\n",
    "    \"\"\"\n",
    "\n",
    "    image = image.copy()\n",
    "\n",
    "    watermarked = image.copy()\n",
    "    watermark_mask = torch.zeros_like(image)\n",
    "    ny, nx = watermarked.shape\n",
    "\n",
    "    bin_code = format(count, f\"0{bit_length}b\")\n",
    "\n",
    "    nbits = bit_length\n",
    "    half = nbits // 2\n",
    "    if nbits % 2 == 0:\n",
    "        top_bits = bin_code[:half]\n",
    "        bottom_bits = bin_code[half:]\n",
    "    else:\n",
    "        top_bits = bin_code[: half + 1]\n",
    "        bottom_bits = bin_code[half + 1 :]\n",
    "\n",
    "    # Top-left\n",
    "    top_h, top_w = top_patch_shape\n",
    "    num_top = len(top_bits)\n",
    "    seg_width_top = top_w // max(num_top, 1)\n",
    "    for i, bit in enumerate(top_bits):\n",
    "        if bit == \"1\":\n",
    "            c_start = i * seg_width_top\n",
    "            c_end = (i + 1) * seg_width_top if i < num_top - 1 else top_w\n",
    "\n",
    "            watermarked[0:top_h, c_start:c_end] += offset\n",
    "            watermark_mask[0:top_h, c_start:c_end] += offset\n",
    "\n",
    "    # Bottom right\n",
    "    bottom_h, bottom_w = bottom_patch_shape\n",
    "    num_bottom = len(bottom_bits)\n",
    "    seg_width_bottom = bottom_w // max(num_bottom, 1)\n",
    "    start_row = ny - bottom_h\n",
    "    start_col = nx - bottom_w\n",
    "    for i, bit in enumerate(bottom_bits):\n",
    "        if bit == \"1\":\n",
    "            c_start = start_col + i * seg_width_bottom\n",
    "            c_end = start_col + (i + 1) * seg_width_bottom if i < num_bottom - 1 else nx\n",
    "            watermarked[start_row:ny, c_start:c_end] += offset\n",
    "            watermark_mask[start_row:ny, c_start:c_end] += offset\n",
    "\n",
    "    watermarked = torch.clamp(watermarked, 0, 1)\n",
    "    watermark_mask = torch.clamp(watermark_mask, 0, 1)\n",
    "\n",
    "    return watermarked, watermark_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283",
   "metadata": {},
   "source": [
    "## Row watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntrain = 10000\n",
    "Ntest = 2500\n",
    "# Ntest_kaggle = 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, ns_train = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntrain)]\n",
    ")\n",
    "dataset_train = torch.tensor(dataset_train, dtype=torch.float32)\n",
    "ns_train = torch.tensor(ns_train, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test, ns_test = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntest)]\n",
    ")\n",
    "dataset_test = torch.tensor(dataset_test, dtype=torch.float32)\n",
    "ns_test = torch.tensor(ns_test, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize by the training set\n",
    "train_max = dataset_train.max()\n",
    "train_min = dataset_train.min()\n",
    "\n",
    "test_max = dataset_test.max()\n",
    "test_min = dataset_test.min()\n",
    "\n",
    "# test_max_kaggle = dataset_test_kaggle.max()\n",
    "# test_min_kaggle = dataset_test_kaggle.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289",
   "metadata": {},
   "source": [
    "Normalize to [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm = (dataset_train - train_min) / (train_max - train_min)\n",
    "dataset_test_norm = (dataset_test - test_min) / (test_max - test_min)\n",
    "# dataset_kaggle_norm = (dataset_test_kaggle - test_min_kaggle) / (test_max_kaggle -\n",
    "# test_min_kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291",
   "metadata": {},
   "source": [
    "### Watermarking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292",
   "metadata": {},
   "source": [
    "Add watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_water = []\n",
    "for image, count in zip(dataset_train_norm, ns_train):\n",
    "    dataset_train_water.append(\n",
    "        watermark_image_row(image.numpy(), count, region_height=3, offset=offset)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test_water = []\n",
    "for image, count in zip(dataset_test_norm, ns_test):\n",
    "    dataset_test_water.append(\n",
    "        watermark_image_row(image.numpy(), count, region_height=3, offset=offset)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_water = torch.tensor(dataset_train_water)\n",
    "dataset_test_water = torch.tensor(dataset_test_water)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 100, size=2)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_train_water[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_train[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298",
   "metadata": {},
   "source": [
    "add unscaled noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_water += sigma * torch.randn(size=dataset_train_water.shape)\n",
    "dataset_test_water += sigma * torch.randn(size=dataset_test_water.shape)\n",
    "# dataset_kaggle_norm += sigma * torch.randn(size=dataset_kaggle_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to clip to above zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_water = torch.clip(dataset_train_water, 0, None)\n",
    "dataset_test_water = torch.clip(dataset_test_water, 0, None)\n",
    "# dataset_kaggle_norm = torch.clip(dataset_kaggle_norm, 0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_water = dataset_train_water.to(torch.float32)\n",
    "dataset_test_water = dataset_test_water.to(torch.float32)\n",
    "# dataset_kaggle_norm = dataset_kaggle_norm.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 100, size=2)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_train_water[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_train[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 100, size=2)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_test_water[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_test[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save((dataset_train_water, ns_train), f\"{data_dir}/dataset_train_{sigma}_{offset}.pt\")\n",
    "torch.save((dataset_test_water, ns_test), f\"{data_dir}/dataset_test_{sigma}_{offset}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306",
   "metadata": {},
   "source": [
    "## Random barcode watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntrain = 10000\n",
    "Ntest = 2500\n",
    "# Ntest_kaggle = 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, ns_train = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntrain)]\n",
    ")\n",
    "dataset_train = torch.tensor(dataset_train, dtype=torch.float32)\n",
    "ns_train = torch.tensor(ns_train, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test, ns_test = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntest)]\n",
    ")\n",
    "dataset_test = torch.tensor(dataset_test, dtype=torch.float32)\n",
    "ns_test = torch.tensor(ns_test, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize by the training set\n",
    "train_max = dataset_train.max()\n",
    "train_min = dataset_train.min()\n",
    "\n",
    "test_max = dataset_test.max()\n",
    "test_min = dataset_test.min()\n",
    "\n",
    "# test_max_kaggle = dataset_test_kaggle.max()\n",
    "# test_min_kaggle = dataset_test_kaggle.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    train_min,\n",
    "    train_max,\n",
    "    test_min,\n",
    "    test_max,\n",
    ")  # test_min_kaggle, test_max_kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314",
   "metadata": {},
   "source": [
    "Normalize to [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm = (dataset_train - train_min) / (train_max - train_min)\n",
    "dataset_test_norm = (dataset_test - test_min) / (test_max - test_min)\n",
    "# dataset_kaggle_norm = (dataset_test_kaggle - test_min_kaggle) / (test_max_kaggle -\n",
    "# test_min_kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316",
   "metadata": {},
   "source": [
    "Add watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_water = []\n",
    "watermarks = []\n",
    "for image, count in zip(dataset_train_norm, ns_train):\n",
    "    watermarked, watermark = watermark_barcode_random(image.numpy(), count, alpha=alpha, repeats=3)\n",
    "    dataset_train_water.append(watermarked)\n",
    "    watermarks.append(watermark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test_water = []\n",
    "for image, count in zip(dataset_test_norm, ns_test):\n",
    "    watermarked, _ = watermark_barcode_random(image.numpy(), count, alpha=alpha, repeats=3)\n",
    "    dataset_test_water.append(watermarked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_water = torch.tensor(dataset_train_water)\n",
    "dataset_test_water = torch.tensor(dataset_test_water)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 10000, size=2)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_train_water[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_train[i]}\")\n",
    "    plt.show()\n",
    "    plt.imshow(watermarks[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(\"Watermark\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321",
   "metadata": {},
   "source": [
    "add unscaled noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_water += sigma * torch.randn(size=dataset_train_water.shape)\n",
    "dataset_test_water += sigma * torch.randn(size=dataset_test_water.shape)\n",
    "# dataset_kaggle_norm += sigma * torch.randn(size=dataset_kaggle_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to clip to above zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_water = torch.clip(dataset_train_water, 0, None)\n",
    "dataset_test_water = torch.clip(dataset_test_water, 0, None)\n",
    "# dataset_kaggle_norm = torch.clip(dataset_kaggle_norm, 0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_water = dataset_train_water.to(torch.float32)\n",
    "dataset_test_water = dataset_test_water.to(torch.float32)\n",
    "# dataset_kaggle_norm = dataset_kaggle_norm.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 100, size=2)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_train_water[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_train[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 100, size=2)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_test_water[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_test[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    (dataset_train_water, ns_train), f\"{data_dir}/dataset_train_barrandom_{sigma}_{alpha}.pt\"\n",
    ")\n",
    "torch.save((dataset_test_water, ns_test), f\"{data_dir}/dataset_test_barrandom_{sigma}_{alpha}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "330",
   "metadata": {},
   "source": [
    "## Split fixed  barcode watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntrain = 10000\n",
    "Ntest = 2500\n",
    "# Ntest_kaggle = 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, ns_train = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntrain)]\n",
    ")\n",
    "dataset_train = torch.tensor(dataset_train, dtype=torch.float32)\n",
    "ns_train = torch.tensor(ns_train, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test, ns_test = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntest)]\n",
    ")\n",
    "dataset_test = torch.tensor(dataset_test, dtype=torch.float32)\n",
    "ns_test = torch.tensor(ns_test, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize by the training set\n",
    "train_max = dataset_train.max()\n",
    "train_min = dataset_train.min()\n",
    "\n",
    "test_max = dataset_test.max()\n",
    "test_min = dataset_test.min()\n",
    "\n",
    "# test_max_kaggle = dataset_test_kaggle.max()\n",
    "# test_min_kaggle = dataset_test_kaggle.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    train_min,\n",
    "    train_max,\n",
    "    test_min,\n",
    "    test_max,\n",
    ")  # test_min_kaggle, test_max_kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338",
   "metadata": {},
   "source": [
    "Normalize to [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm = (dataset_train - train_min) / (train_max - train_min)\n",
    "dataset_test_norm = (dataset_test - test_min) / (test_max - test_min)\n",
    "# dataset_kaggle_norm = (dataset_test_kaggle - test_min_kaggle) / (test_max_kaggle -\n",
    "# test_min_kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340",
   "metadata": {},
   "source": [
    "Add watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_water = []\n",
    "watermarks = []\n",
    "for image, count in zip(dataset_train_norm, ns_train):\n",
    "    watermarked, watermark = watermark_barcode_split(\n",
    "        image.numpy(), count, offset=offset, bit_length=4\n",
    "    )\n",
    "    dataset_train_water.append(watermarked)\n",
    "    watermarks.append(watermark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test_water = []\n",
    "for image, count in zip(dataset_test_norm, ns_test):\n",
    "    watermarked, _ = watermark_barcode_split(image.numpy(), count, offset=offset, bit_length=4)\n",
    "    dataset_test_water.append(watermarked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_water = torch.tensor(dataset_train_water)\n",
    "dataset_test_water = torch.tensor(dataset_test_water)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 10000, size=2)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_train_water[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_train[i]}\")\n",
    "    plt.show()\n",
    "    plt.imshow(watermarks[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(\"Watermark\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345",
   "metadata": {},
   "source": [
    "add unscaled noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_water += sigma * torch.randn(size=dataset_train_water.shape)\n",
    "dataset_test_water += sigma * torch.randn(size=dataset_test_water.shape)\n",
    "# dataset_kaggle_norm += sigma * torch.randn(size=dataset_kaggle_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to clip to above zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_water = torch.clip(dataset_train_water, 0, None)\n",
    "dataset_test_water = torch.clip(dataset_test_water, 0, None)\n",
    "# dataset_kaggle_norm = torch.clip(dataset_kaggle_norm, 0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_water = dataset_train_water.to(torch.float32)\n",
    "dataset_test_water = dataset_test_water.to(torch.float32)\n",
    "# dataset_kaggle_norm = dataset_kaggle_norm.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in iis:\n",
    "    plt.imshow(dataset_train_water[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_train[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    (dataset_train_water, ns_train), f\"{data_dir}/dataset_train_barsplit_{sigma}_{offset}.pt\"\n",
    ")\n",
    "torch.save((dataset_test_water, ns_test), f\"{data_dir}/dataset_test_barsplit_{sigma}_{offset}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352",
   "metadata": {},
   "source": [
    "## Split fixed  barcode watermark: post-noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntrain = 10000\n",
    "Ntest = 2500\n",
    "# Ntest_kaggle = 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, ns_train = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntrain)]\n",
    ")\n",
    "dataset_train = torch.tensor(dataset_train, dtype=torch.float32)\n",
    "ns_train = torch.tensor(ns_train, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test, ns_test = zip(\n",
    "    *[generate_synthetic_image(shape=(dim, dim), noise_sigma=sigma) for _ in range(Ntest)]\n",
    ")\n",
    "dataset_test = torch.tensor(dataset_test, dtype=torch.float32)\n",
    "ns_test = torch.tensor(ns_test, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize by the training set\n",
    "train_max = dataset_train.max()\n",
    "train_min = dataset_train.min()\n",
    "\n",
    "test_max = dataset_test.max()\n",
    "test_min = dataset_test.min()\n",
    "\n",
    "# test_max_kaggle = dataset_test_kaggle.max()\n",
    "# test_min_kaggle = dataset_test_kaggle.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    train_min,\n",
    "    train_max,\n",
    "    test_min,\n",
    "    test_max,\n",
    ")  # test_min_kaggle, test_max_kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360",
   "metadata": {},
   "source": [
    "Normalize to [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm = (dataset_train - train_min) / (train_max - train_min)\n",
    "dataset_test_norm = (dataset_test - test_min) / (test_max - test_min)\n",
    "# dataset_kaggle_norm = (dataset_test_kaggle - test_min_kaggle) / (test_max_kaggle -\n",
    "# test_min_kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362",
   "metadata": {},
   "source": [
    "add unscaled noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm += sigma * torch.randn(size=dataset_train_norm.shape)\n",
    "dataset_test_norm += sigma * torch.randn(size=dataset_test_norm.shape)\n",
    "# dataset_kaggle_norm += sigma * torch.randn(size=dataset_kaggle_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to clip to above zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm = torch.clip(dataset_train_norm, 0, None)\n",
    "dataset_test_norm = torch.clip(dataset_test_norm, 0, None)\n",
    "# dataset_kaggle_norm = torch.clip(dataset_kaggle_norm, 0, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366",
   "metadata": {},
   "source": [
    "Add watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_water = []\n",
    "watermarks = []\n",
    "for image, count in zip(dataset_train_norm, ns_train):\n",
    "    watermarked, watermark = watermark_barcode_split(\n",
    "        image.numpy(), count, offset=offset, bit_length=4\n",
    "    )\n",
    "    dataset_train_water.append(watermarked)\n",
    "    watermarks.append(watermark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test_water = []\n",
    "for image, count in zip(dataset_test_norm, ns_test):\n",
    "    watermarked, _ = watermark_barcode_split(image.numpy(), count, offset=offset, bit_length=4)\n",
    "    dataset_test_water.append(watermarked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_water = torch.tensor(dataset_train_water)\n",
    "dataset_test_water = torch.tensor(dataset_test_water)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_water = dataset_train_water.to(torch.float32)\n",
    "dataset_test_water = dataset_test_water.to(torch.float32)\n",
    "# dataset_kaggle_norm = dataset_kaggle_norm.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371",
   "metadata": {},
   "outputs": [],
   "source": [
    "iis = torch.randint(0, 10000, size=2)\n",
    "for i in iis:\n",
    "    plt.imshow(dataset_train_water[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(f\"{ns_train[i]}\")\n",
    "    plt.show()\n",
    "    plt.imshow(watermarks[i], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(\"Watermark\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    (dataset_train_water, ns_train), f\"{data_dir}/dataset_train_barsplit_post_{sigma}_{offset}.pt\"\n",
    ")\n",
    "torch.save(\n",
    "    (dataset_test_water, ns_test), f\"{data_dir}/dataset_test_barsplit_post_{sigma}_{offset}.pt\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
